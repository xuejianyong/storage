Articles
https://doi.org/10.1038/s41593-021-00821-9

Rotational dynamics reduce interference between
sensory and memory representations
Alexandra Libby   1 and Timothy J. Buschman   1,2 ✉
Cognition depends on integrating sensory percepts with the memory of recent stimuli. However, the distributed nature of neural coding can lead to interference between sensory and memory representations. Here, we show that the brain mitigates such interference by rotating sensory representations into orthogonal memory representations over time. To study how sensory inputs and memories are represented, we recorded neurons from the auditory cortex of mice as they implicitly learned sequences of sounds. We found that the neural population represented sensory inputs and the memory of recent stimuli in two orthogonal dimensions. The transformation of sensory information into a memory was facilitated by a combination of ‘stable’ neurons, which maintained their selectivity over time, and ‘switching’ neurons, which inverted their selectivity over time. Together, these neural responses rotated the population representation, transforming sensory inputs into memory. Theoretical modeling showed that this rotational dynamic is an efficient mechanism for generating orthogonal representations, thereby protecting memories from sensory interference.

Maintaining the short-term memory of recent stimuli is critical to cognition. Memories provide the context needed for perception and decision-making1,2 and are particularly important for learning to predict the future. Predictions are based on expectations, allowing one to use the current context to predict which stimulus is likely to occur next. Expectations reflect previously learned statistical regularities between stimuli (that is, A, B is usually followed by C). These are learned by forming associations through time between the memory of recent stimuli (A and B) and the representation of current sensory inputs (C). Once learned, these associations facilitate predictions (that is, expecting C when you see A and B), which improves sensory processing3,4 and facilitates decisions by allowing them to be made earlier5–7.
While maintaining both sensory and memory information can facilitate cognition, it is unknown how the brain maintains both representations without interference. Previous work has shown that neural networks have a limited capacity, unable to accurately encode multiple stimuli8 or maintain multiple short-term memories9,10. The limited capacity of neural networks is thought to be due to interference that arises when simultaneously encoding sensory and memory representations in the same population of neurons. Theoretical work has shown that interference can be reduced by orthogonalizing representations11–13, possibly by having neurons with nonlinear or random selectivity14. However, it remains unclear whether, or how, such orthogonalization occurs in the brain. To address this, we investigated the mechanisms used by the brain to avoid interference between sensory and memory representations.
To study interference between sensory and memory representations, we used an implicit sequence-learning paradigm to build associations between sensory stimuli15,16. As we detail below, this facilitated predictions of upcoming stimuli and created interference between the short-term memory of recent stimuli and the sensory representation of new stimuli. We show that the brain mitigates this interference by dynamically rotating sensory representations into an orthogonal memory representation. This rotation was supported by dynamics in the selectivity of individual neurons. Indeed, we found

populations of ‘stable’ neurons, which maintained their selectivity over time, and ‘switching’ neurons, which inverted their selectivity from the sensory to memory time periods. The combination of these dynamics facilitated the rotation of the population representation, allowing the same network of neurons to efficiently represent both sensory information and short-term memories.
Results To study how sensory and short-term memory representations interact in the sensory cortex, we exposed mice to sequences of four auditory chords (Methods). Statistical regularities in the transitions between chords created learnable predictions within the sequences (Fig. 1a). Sequences began with a pair of contextual chords: either an A and B stimulus pair (the AB context) or an X and Y stimulus pair (the XY context). These contexts predicted what chord would follow: for 68% of trials, the AB context was followed by a C chord and the XY context was followed by a C* chord. However, for a subset of trials (20%), the context was unexpectedly followed by the other C/C* stimulus (that is, ABC* and XYC; the remaining 12% of trials were ambiguous stimuli; Methods). All sequences ended with a D chord. Importantly, the sequences were designed to balance the overall likelihood of each sensory stimulus across conditions. Therefore, before the start of each sequence, the animal had no expectation as to what chords it would experience. Only after the presentation of the contextual stimulus (A or X) could the animal predict the upcoming C/C* stimulus. Beginning naive, the animals experienced 1,500 sequences per day for 4 consecutive days (Fig. 1a and Methods). No behavioral task was required by the animal, which allowed us to study how unsupervised learning affects sensory processing and short-term memory17–20.
To measure sensory and short-term memory representations in the brain, we recorded 522 neurons from the auditory cortex of 7 mice with an average of 130 neurons per day (across mice; Methods). Although electrodes were chronically implanted, individual neurons were not tracked across recording sessions. Neurons responded selectively to the presentation of the context chords

1Princeton Neuroscience Institute, Princeton University, Princeton, NJ, USA. 2Department of Psychology, Princeton University, Princeton, NJ, USA. ✉e-mail: tbuschma@princeton.edu

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

715

Articles

NaTurE NEurosCiEnCE

a Recording during implicit sequence learning

Day 1 (naive)

b Example cell responses

39 Aud

Neuron selective to A/X

A/X

B/Y C/C*

D

c

Schematic of projection

on A/X classifier

X trials

FR (Hz)

Neuron n (FR)

Chord 100 ms
A
X

ICI

75 ms

68%

B

C

20%

Y

C*

Day 2

Day 3

D

Day 4

(experienced)

FR (Hz)

10

Neuron selective to C/C*

35

A/X

B/Y C/C*

D

ABCD ABC*D XYC*D XYCD

Context

Predicted stimulus

d

Day 1: A/X sensory population encoding

A/X sensory axis training period

X

A/X

B/Y

C/C*

D

0.5

XYC*D

XYCD

0 0

175

350 525

Time (ms)

e

Day 4: A/X sensory population encoding

A/X sensory axis training period

X

A/X

B/Y

C/C*

D

0.5

XYC*D

ABC*D

0

0

A/X sensory axis

A/X sensory axis

–0.5

A AB vs XY

ABC*D ABCD
C vs. C*

0

175

350

525

Time (ms)

–0.5

A AB vs XY

XYCD ABCD
C vs. C*

0

175

350

525

Time (ms)

g

Day 1: C/C* sensory population encoding

h

Day 4: C/C* sensory population encoding

C/C* sensory axis training period

C/C* sensory axis training period

C* A/X

B/Y

C/C*

D

0.5

XYC*D

ABC*D

C* A/X

B/Y

C/C*

D

0.5

XYC*D

XYCD

C/C* sensory axis

C/C* sensory axis

0

–0.5 C

XYCD ABCD AB vs XY

C vs. C*

0

175

350

525

Time (ms)

0

ABC*D

–0.5

C

AB vs XY

ABCD

C vs. C*

0

175

350

525

Time (ms)

Predictive projection (C/C* axis)

A trials

Projection on axis

Neuron 1 (FR)

f

A/X encoding

Train: A/X test: A/X

0.5

Correct projection (A/X axis)

0.4 ***

0.3

*** *** ***

0.2

0.1

0
12 34 Day

i

C/C* prediction

during A/X stimulus

***
0.2
***

0.1

** **

0
1234 Day

Fig. 1 | Associative learning of sequences facilitates prediction. a, Schematic of the implicit sequence-learning paradigm. Beginning naive, animals heard
1,500 sequences of auditory chords every day over 4 days. Sequences had statistical regularities between chords: 68% expected trials (ABCD, XYC*D),
20% unexpected (ABC*D, XYCD), 12% mixed stimuli (Methods). Inset shows a schematic of the silicon probe placement in right auditory (Aud) cortex.
The histology image shows the electrode location: green, immunolabel for astrocytes (highlighting the electrode track); blue, Hoechst stain for cells. Scale
bar, 150 µm. b, Example sequence responses from two neurons preferring the AB context stimulus (top; mouse-496 (M496), day 2) and the C stimulus (bottom; M537, day 2). Lines and bands show the mean ± s.e.m. of the FR. Gray patches indicate stimulus periods. The legend shows the four types of sequences experienced (these colors are maintained throughout the paper). c, Schematic of the classifier trained to discriminate the neural responses
to the A/X stimulus. The projection of the withheld response onto the encoding axis is shown. d,e, The neural population encoding of A/X shown on day
1 (d) and day 4 (e). Lines show the mean ± s.e.m. of the population projection onto the A/X sensory axis for all four conditions. Positive and negative projections indicate X (green) and A (purple) encoding, respectively. Light and dark gray horizontal bars mark significant differences for AB versus XY
and C versus C*, respectively (two-sided t-test, P ≤ 0.001, Bonferroni-corrected). Orange outlines the A/X training period. For panels d–i, n = 1,064 withheld trials, combined across animals per day. f, Points show the mean ± s.e.m. of encoding of the A/X stimulus during stimulus presentation. Day 1 = 0.37 ± 0.02, day 2 = 0.27 ± 0.022, day 3 = 0.28 ± 0.022, day 4 = 0.32 ± 0.021, all greater than zero, P < 1/5,000, two-sided bootstrap tests. Negatively labeled conditions (that is, A) were inverted, such that positive values on the y axis indicate A and X trials are ‘correctly’ encoded as A and X, respectively.
Slope mean ± s.e.m. over days = −0.012 ± 0.009, P = 0.094, one-sided bootstrap test. g,h, Lines show the mean ± s.e.m. of population encoding of C/C* information across the sequence time course on day 1 (g) and day 4 (h). Plots are as in d and e. Blue outlines the C/C* training period. Positive and
negative projections indicate C* (light blue) and C (dark blue) encoding, respectively. i, Predictive encoding of the upcoming C/C* stimulus during A/X
exposure increased with experience. Points show the mean ± s.e.m. encoding of the predicted C/C* stimulus, measured as the projection onto the C/C* sensory axis during the A/X stimulus (black outline in g and h). Day 1 = 0.13 ± 0.022, P < 1/5,000, day 2 = 0.07 ± 0.023, P = 0.0036, day 3 = 0.076 ± 0.023, P < 1/5,000, day 4 = 0.19 ± 0.022, P < 1/5,000, all two-sided bootstrap tests against zero. Lines and shaded regions show the mean and 95% CIs of bootstrapped linear regressions. Slope mean ± s.e.m. over days = 0.02 ± 0.01, P = 0.022, one-sided bootstrap test. See Supplementary Fig. 2b for predictive encoding during blocks of trials within days. For all panels, *P ≤ 0.05, **P ≤ 0.01, ***P ≤ 0.001.

716

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

C/C* sensory axis Angle (degrees) C/C* FR difference C/C* FR difference

a

C/C* prediction during A/X stimulus

sensory state space (day 4)

A/X

B/Y

0.4 AC* ABCD ABC*D
0.2

C/C*

D

XC* XYC*D XYCD

0

–0.2

PCs

–0.4

AC

XC

–0.4 –0.2 0 0.2 0.4 A/X sensory axis

b Angle between A/X sensory c
and C/C* sensory decreased C* 15
100
10 90
5
80 0

70

–5

Day 1: population selectivity to A/X and C/C* sensory
Slope: –0.09 P : 0.205

60

–10

50
1234 Day

C –15

–10

0

10

A

A/X FR difference

X

d
C* 5

Day 4: population selectivity to A/X and C/C* sensory
Slope: 0.25 P : 0.004

0

–5

C

–10

–5

0

5

10

A

A/X FR difference

X

Fig. 2 | Sensory representations align with experience. a, Mean projection of neural activity onto the A/X sensory axis (x axis) and C/C* sensory axis
(y axis) during presentation of the A/X stimulus (−10to 170 ms) on day 4 for all four conditions (n = 266 trials each, n = 1,064 total). The oblique response reflects prediction of the C/C* stimulus. Marker saturation increases with time (key shown along the top); squares indicate time points before stimulus
onset. Inset shows PCs of neural trajectories in gray, with the black arrow size matching the percentage of explained variance per PC. The angle of the
first PC increased with experience (Extended Data Fig. 4a,b). b, The angle between A/X and C/C* sensory axes decreased across days. Points show
the mean ± s.e.m. of angles calculated per block of trials across 4 days (marker color indicates day; 500 trials per block, stepped by 200 trials). Top gray squares indicate significant difference from 90° (P ≤ 0.01, one-sided bootstrap test, n = 5,000 resamples of neurons). Lines and shaded regions show the mean and 95% CIs of linear regressions of change in angle over blocks: slope mean ± s.e.m. = −0.89 ± 0.18, P < 1/5,000, one-sided bootstrap test. c,d, Correlation between A/X selectivity (x axis) and C/C* selectivity (y axis) of individual neurons for day 1 (c) and day 4 (d). Selectivity is the
z-scored FR difference calculated during A/X (10–175 ms) and C/C* (360–525 ms). Dots show individual neurons. Lines and shaded regions show the
mean and 95% CIs of linear regression: day 1 slope mean ± s.e.m. = −0.09 ± 0.1, P = 0.205, n = 121, bootstrap test; day 4 slope = 0.25 ± 0.087, P = 0.004, n = 143. Consistent with the axis alignment shown in b, the slope relating A/X and C/C* selectivity increased over days; change in slope across days mean ± s.e.m. = 0.08 ± 0.04, P = 0.028. All one-sided bootstrap tests.

(A versus X and B versus Y) and the predicted chord (C versus C*; see Fig. 1b for example neurons). To capture how the population of recorded neurons represented each stimulus in the sequence, we trained linear support vector machine classifiers to discriminate the population firing rate (FR) responses to each pair of stimuli (A/X, B/Y, C/C*, with responses averaged over 10–110-ms after stimulus onset; see Methods and Supplementary Fig. 1 for classifier performance details). To ensure that the classifier was unbiased, all trial types were balanced during training (that is, there was an equal number of ABCD, ABC*D, XYCD and XYC*D trials). Separate classifiers were trained for each recording session, using simultaneously recorded neurons. All analyses were performed on withheld data.
Each classifier defined an ‘encoding axis’ for a pair of stimuli (the axis is the vector normal to the hyperplane of the classifier). By projecting the FR of the neural population onto the encoding axis, we could estimate stimulus information in the population at each moment in time (see Fig. 1c for a schematic and Methods for details). As expected, the population encoded each sensory stimulus when it was presented in the sequence on all 4 days (A/X: Fig. 1d–f; B/Y: Extended Data Fig. 1; C/C*: Fig. 1g,h; the accuracy of decoding is shown in Extended Data Fig. 2).
Alignment of encoding axes facilitates prediction and postdiction. Experience over days led to associative learning between stimuli in the sequence. These associations facilitated predictions in the auditory cortex, whereby on day 4, during the presentation of A/X, there was predictive encoding of the expected C/C* stimulus. This can be seen as the neural population representing C or C* when A or X was presented, respectively (Fig. 1g,h, black box, and Extended Data Fig. 3). This predictive effect was relatively weak on days 1 to 3 before increasing on day 4, which suggests that experience strengthened the prediction (day 1 = 0.13 ± 0.022, P < 1/5,000; day 2 = 0.07 ± 0.023, P = 0.0036; day 3 = 0.076 ± 0.023, P < 1/5,000; day 4 = 0.19 ± 0.022, P < 1/5,000, bootstrap tests. Slope mean ± s.e.m. over days = 0.02 ± 0.01, P = 0.022, two-sided bootstrap tests; day 4

to day 1 = 0.07, P = 0.015, one-sided permutation test) (Fig. 1i and see Supplementary Fig. 2b for similar trends within a day).
The relationship between the associated A/X and C/C* stimuli can be highlighted by projecting the activity of the neural population into a two-dimensional (2D) state space defined by the A/X sensory and C/C* sensory encoding axes (Fig. 2a). This state space tracks the co-evolution of information along both sensory axes during the sequence. On day 4, the A/X stimulus evoked an oblique response in this state space, which indicates that the A/X stimulus induced both its own representation and that of the predicted stimulus (A–C and X–C*, respectively). These predictions increased with experience, as reflected by an increase in the angle of the neural trajectories in this 2D space over days (Extended Data Fig. 4a,b).
The oblique response in the sensory encoding state space suggests that experience caused the A/X and C/C* representations to align. If true, then the A/X encoding and C/C* encoding axes should become more similar over time. To test this, we measured the angle between the A/X and C/C* axes (Methods). On day 1, the average angle across blocks was 84 ± 7.4°. This near-orthogonality is consistent with the sensory cortex independently representing different, unassociated, stimuli before learning. With experience, the angle significantly decreased (Fig. 2b; slope mean ± s.e.m. = −0.89 ± 0.18° per block of trials, P < 1/5,000), such that by day 4, the angle was significantly less than orthogonal (67 ± 8.2, P = 0.0057, both one-sided bootstrap tests). This trend started within day 1 (Fig. 2b; P = 0.12, one-sided bootstrap test), which suggests that alignment starts immediately with experience. Note that none of these results depended on the classifier type or its hyperparameters (Supplementary Fig. 3 and Methods).
Our results are consistent with previous experimental and modeling work, which showed that single neurons respond similarly to associated stimuli15,16,21–23. We also found that the response of single neurons to A/X and C/C* became more correlated with experience (Fig. 2c,d; day 1 slope between A/X and C/C* selectivity = −0.09 ± 0.1, P = 0.205, n = 121; day 4 slope = 0.25 ± 0.087, P = 0.004, n = 143; change of slope over days = 0.08 ± 0.04, P = 0.028,

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

717

Articles

NaTurE NEurosCiEnCE

one-sided bootstrap tests). Together, these results suggest that implicit associative learning increased the number of neurons that have joint selectivity to A and C (or X and C*), which aligned the encoding axes and facilitated the neural prediction of future stimuli across days (Fig. 1g–i).
We also examined the relationship between the representation of B/Y and the representations of A/X and C/C* (Extended Data Fig. 1f–g). Unlike A/X, the B/Y and C/C* sensory axes did not align, possibly because B/Y did not add predictive value about which C/C* stimulus would occur (as it was already fully predicted by the A/X stimulus)24.
It is important to note that the alignment of the A/X and C/C* axes does not define a directional relationship between the stimuli. So, similar to the A/X stimulus inducing a predictive response along the C/C* sensory axis, the presentation of the C/C* stimulus should also evoke a response along the A/X sensory axis. This can be seen in the A/X–C/C* state space, where the presentation of the C/C* stimulus drove neural activity along an angle, encoding the A–C/ X–C* association (Fig. 3a), an effect that increased with experience (Extended Data Fig. 4c,d). This is a postdiction; that is, new sensory inputs inform the representation of past events. Postdiction is a common psychological phenomenon that improves perception (and can cause illusions)25–28. Our results suggest that postdiction arises from the same neural mechanism as prediction; that is, the alignment of population representations of associated stimuli. Consistent with this, we found that the angles between A/X and C/C* sensory axes, calculated per mouse, correlated with the strength of the prediction/ postdiction of the animals (Supplementary Fig. 4a,b).
Alignment of encoding axes leads to interference. The alignment of A/X and C/C* sensory representations facilitated prediction/postdiction, but it also led to interference between the current sensory inputs and the representation of the past. This interference occurred on unexpected trials, when the initial sensory representation of A/X

was overwritten by an unexpected C*/C. Before the C/C* stimulus, the representation of the A/X stimulus was correct (Fig. 3a). However, the onset of the unexpected C*/C stimulus caused the population encoding of A/X to reverse and cross the hyperplane to encode the incorrect context: ABC*D trials were encoded as X–C*, and XYCD encoded as A–C (Fig. 3b; day 4, A/X encoding on unexpected trials: −0.16 ± 0.033, P < 1/5,000, two-sided bootstrap test). This effect grew with experience, with unexpected C*/C sounds leading to a stronger reversal of the A/X representation over days (slope = −0.039 ± 0.015, P = 0.0068, one-sided bootstrap test).
An orthogonal memory representation avoids interference. Maintaining an accurate account of stimulus history is critical for making decisions and learning associations across time1,2. Therefore, we were interested in whether the auditory cortex maintained a memory representation of the A/X context that was resilient against interference from associative learning. To this end, we trained an ‘A/X memory’ classifier to discriminate the AB/XY context using the activity of neurons during the presentation of the C/C* stimulus (Fig. 3c and Extended Data Fig. 5). This A/X memory axis encoded the memory of A/X during the C/C* stimulus, but not during the A/X stimulus (Fig. 3d and Extended Data Fig. 6). This complemented the A/X sensory axis, which accurately encoded A/X during its presentation, but failed during the memory period (Fig. 3d). In this way, the transition between A/X sensory to A/X memory encoding reflects a change in the representation of the A/X context during the sequence. This change occurred during the B/Y presentation and progressed earlier in the sequence with experience (Extended Data Fig. 6c).
Unlike the A/X sensory representation, the A/X memory representation of the A/X chord was not overwritten by the C/C* stimulus (Fig. 3e). Interference was avoided because the A/X memory axis was orthogonal to the C/C* sensory axis. By day 4, the angle between A/X memory and C/C* sensory was 90 ± 9.8° (P = 0.49,

Fig. 3 | Orthogonal memory representation avoids interference. a, Neural activity is projected into the A/X–C/C* sensory state space on day 4 during the
C/C* stimulus (340–520 ms, n = 1,064 trials; see Extended Data Fig. 4c for day 1). The A/X sensory encoding (x axis) of unexpected trials (ABC*D, pink, and XYCD, green) was incorrect after C/C* stimulus onset. Figure format follows that in Fig. 2a. b, Experience increased the postdiction of A/X encoding
during the C/C* stimulus (360–460 ms). Points show the mean ± s.e.m. of A/X encoding; positive and negative values indicate correct and incorrect A/X encoding, respectively. Interference on unexpected trials (gray) increased across days (n = 532 trials): day 1 mean ± s.e.m. = −0.024 ± 0.036, P = 0.48, day 2 = −0.084 ± 0.032, P = 0.0056, day 3 = −0.07 ± 0.034, P = 0.034, day 4 = −0.16 ± 0.033, P < 1/5,000, two-sided bootstrap tests; change over days slope mean ± s.e.m. = −0.039 ± 0.015, P = 0.0068, one-sided bootstrap test. A/X encoding on expected trials (black) remained correct over days (n = 532 trials): day 1 = 0.13 ± 0.03, P < 1/5,000, day 2 = 0.091 ± 0.033, P = 0.0052, day 3 = 0.086 ± 0.03, P = 0.004, day 4 = 0.17 ± 0.031, P < 1/5,000, two-sided bootstrap tests; change over days slope = 0.012 ± 0.014, P = 0.19, one-sided bootstrap test. c, The memory of A/X was maintained during the C/C* stimulus along the A/X memory axis on day 4 (and day 1, see Extended Data Fig. 5). Lines show the mean ± s.e.m. of neural activity projections onto the A/X memory axis. The A/X memory classifier was trained during the C/C* stimulus (360–460 ms, blue range) on the preceding A/X stimulus (that is,
ABCD, ABC*D versus XYCD, XYC*D; Methods). Positive and negative projections indicate XY (green) and AB (purple) memory encoding, respectively.
Significant differences between AB and XY trials are shown by the horizontal bar (n = 1,064, P ≤ 0.001, two-sided t-tests, Bonferroni-corrected for multiple comparisons). Figure format follows that in Fig. 1d,e. For c and d, the gray patches indicate the timing of chords. d, Projection of neural responses onto
the A/X sensory axis (orange) and the A/X memory axis (blue) over time. The orange and blue horizontal bars indicate stronger A/X encoding along
the sensory amd memory axes, respectively (n = 1,064, P ≤ 0.001, two-sided t-tests, Bonferroni-corrected). Extended Data Fig. 6c shows when encoding switched from sensory to memory across days. e, The neural activity projected onto the A/X memory (x axis)–C/C* sensory (y axis) state space on
day 4. All four conditions are correctly encoded. Figure format follows a. f, The angle between A/X memory and C/C* sensory axes became orthogonal
with experience. Points show the mean ± s.e.m. of angles, as in Fig. 2b. Change of angle across blocks: slope mean ± s.e.m. = −0.78 ± 0.2, P < 1/5,000, one-sided bootstrap test (n = 5,000 resamples). g, Schematic showing the angles between the three axes of interest, A/X sensory, C/C* sensory and A/X memory, on day 4. h, The dimensionality of state spaces during C/C* (340–520 ms) was estimated by the EVR of the first PC (PC1) of the neural
trajectories within a given state space. Violin plots show the distribution of the EVR, bootstrapped across trials (n = 5,000 resamples). In the A/X–C/C* sensory state space (gray, shown in a), the bootstrapped EVR was significantly greater than chance on all 4 days (day 1 = 0.93 ± 0.02, day 2 = 0.93 ± 0.02, day 3 = 0.93 ± 0.02 and day 4 = 0.97 ± 0.011, all P ≤ 1/5,000 by permutation tests; Methods). The EVR increased from day 1 to 4 (horizontal bar), day 4 to day 1 = 0.036, P = 0.0054, permutation test; regression across days is trending: slope mean ± s.e.m. = 0.01 ± 0.01, P = 0.066, bootstrap test. In the A/X memory–C/C* state space (orange, shown in d), the bootstrapped EVR was greater than chance on day 1 (0.77 ± 0.034, P ≤ 1/5,000), but decreased with experience (day 2 = 0.58 ± 0.04, P = 0.43; day 3 = 0.59 ± 0.04, P = 0.15; day 4 = 0.67 ± 0.05, P = 0.015, all permutation tests; day 4 to day 1 = −0.11, P = 0.011, permutation test; regression is trending: slope mean ± s.e.m. = −0.03 ± 0.02, P = 0.059, bootstrap test). The EVR of the A/X–C/C* sensory state space was significantly higher than the EVR of the A/X memory–C/C* sensory state space: difference on days 1–4: 17%, 40%, 40% and 32%, all
P ≤ 1/5,000 by permutation test. All tests in h are one-sided. For all panels, *P ≤ 0.05, **P ≤ 0.01, ***P ≤ 0.001.

718

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

difference from 90°, one-sided bootstrap test). Again, this changed with experience, with the angle between A/X memory and C/C* sensory beginning slightly obtuse on day 1 and decreasing to become orthogonal over days (Fig. 3f). Figure 3g summarizes the angular relationships between all three axes on day 4, showing both the predictive alignment of the A/X sensory and C/C* sensory axes and the orthogonality between the A/X memory and C/C* sensory axes.
The reduced angle between the A/X sensory and C/C* sensory representations suggest that they reflect a single latent variable (the AC/XC* association). If true, then neural activity should follow a low dimensional trajectory within the A/X–C/C* sensory state space (Methods). Indeed, during the presentation of the C/C* stimulus, the dimensionality of the response within the A/X–C/C* sensory state space was significantly lower than expected by chance and was lower on day 4 compared with day 1 (Fig. 3h

and Methods). Consistent with this, the dimensionality of the full neural space trended toward decreasing over days (Extended Data Fig. 5e). In contrast, the dimensionality of the A/X memory–C/C* sensory state space increased from day 1 to day 4 (Fig. 3h). These results suggest that A/X sensory and C/C* encoding are captured by a single latent variable, while A/X memory is orthogonal to this sensory representation.
Finally, we tested how A/X sensory and A/X memory representations influenced sensory processing of the C/C* stimulus (Extended Data Fig. 7). There was a trial-by-trial correlation between the strength of A/X encoding, measured 50-ms before the C/C* stimulus, and the strength of the C/C* response. Yet, the relationship was dissociated between the two A/X encoding axes. On unexpected trials, the C/C* representation was positively correlated with the A/X memory representation, but negatively correlated with the A/X

a

A/X postdiction during C/C* stimulus

b

sensory state space (day 4)

A/X

B/Y

C/C*

D

AC*

XC*

0.4

XYC*D

0.2

ABC*D

C/C* sensory axis

0

XYCD

–0.2

ABCD

PCs

–0.4

AC

XC

–0.4 –0.2 0 0.2 0.4 A/X sensory axis

Projection on A/X axis

Incorrect

Correct

c

A/X postdiction

during C/C* stimulus

0.2

***

***

0.1

** **

0.5

Day 4: A/X memory population encoding A/X memory axis training period

XY A/X

B/Y

C/C*

D

XYC*D XYCD

A/X memory axis

0
** *

0

–0.1

***

–0.2

Unexpected Expected

–0.5 AB

ABC*D ABCD AB vs XY

1

2

3

4

Day

0

175

350

525

Time (ms)

d

A/X encoding transformation from sensory to memory

during the sequence (day 4)

0.5

A/X

B/Y

C/C*

D

0.4

A/X sensory axis

A/X memory axis

0.3

e A/X memory accuracy during C/C* stimulus
sensory-memory state space (day 4)

A/X

B/Y

AC* ABC*D 0.4

C/C*

D

XYC*D XC*

0.2

C/C* sensory axis

Correct projection on A/X axis

0.2

0

0.1

–0.2

PCs

0

–0.1 0

175

350

Time (ms)

f

A/X memory and C/C* sensory

angle became orthogonal

Angle (degrees)

120 110 100 90 80 70
1234 Day

–0.4 AC ABCD

XYCD XC

525

–0.4 –0.2 0 0.2 0.4 A/X memory axis

g
Day 4 angular relationship between axes
A/X sensory A/X memory C/C* sensory

Memory A

90.0°

C

X

67.0°

A

C*

86.0°

Memory X

h

Experience changed the

dimensionality of state spaces

**

1.0

**

0.9 ***

***

***

***

EVR (PC1)

0.8 ***

0.7

*

0.6

0.5

A/X–C/C* state space

A/X memory–C/C* state space 0.4

1

2

3

4

Day

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

719

Articles

NaTurE NEurosCiEnCE

Population mechanism

Independent mechanism

a

b

c

Random

Structured

Example neuron A/X temporal selectivity
X

Mem. (T2) selectivity

A/X sensory axis

Example neuron

Mem. (T2)

A/X temporal selectivity selectivity

X

Example neuron A/X temporal selectivity
X

Mem. (T2) selectivity

Neuron n

Neuron n

A/X sensory axis

T1 T2 A

A/X memory axis
Neuron 1 A

d

Example A/X temporal selectivity

(M523, day 3)

10

A/X B/Y C/C* D

XY

10

Sen. (T1) selectivity
X

A/X memory axis Neuron 1

T1 T2 A

Sen. (T1) selectivity
X

T1 T2 A

A

A

A/X population selectivity

Example A/X temporal selectivity (M500, day 4)

10

A/X B/Y C/C* D

XY

e
250

Singles 0.33, P < 1/1,000

Sen. (T1) selectivity
X

z-scored FR difference

z-scored FR difference

A/X memory FR difference

AB

5

–10

0 175 350 525

Time (ms)

0

Example A/X temporal selectivity

(M496, day 2)

14

A/X B/Y C/C* D

XY

–5

AB –10

0 175 350 525
Time (ms) Example A/X temporal selectivity
(M496, day 1)

12

A/X B/Y C/C* D

XY

z-scored FR difference

z-scored FR difference

AB

–10

–14

0 175 350 525 Time (ms)

f

Conjunctive

0.18, P < 1/1,000

8 Observed

200

Random

6

z-score (compared to random)

150

4

100

2

50

0

0 0.100 0.125 0.150 0.175

–10

0

A/X sensory FR difference

Conjunctive increased over days

1

2

3

4

Day

AB –12

10

0 175 350 525

Time (ms)

g
250 200

Conjunctive/single ratio 0.54, P < 1/1,000
Observed Random

150

100

50

0

0.2

0.4

z-score (compared to random)

z-score (compared to random)

0

0.4

0.5

Singles decreased over days

0

–2

–4

–6

–8

1

2

3

4

Day

Conjunctive/single ratio increased over days

15

10

5

0

1

2

3

4

Day

Fig. 4 | Rotation creates an orthogonal memory representation. a–c, Schematics of mechanisms for creating orthogonal representations. a, The
independent mechanism predicts that separate populations of neurons are selective during sensory (for example, green and yellow) and memory (for
example, purple and pink) periods. The left plot schematizes neural responses rotating the representation; the right plot shows associated neuronal
selectivity distributions during the A/X stimulus presentation (x axis; ‘Sen. (T1) selectivity’) and the memory period (y axis; ‘Mem. (T2) selectivity’).
Circles and insets show example time courses of selectivity predicted by each mechanism. b, Population mechanisms represent sensory and memory in a
shared population of neurons. c, Orthogonalization occurs through a rotation induced by either random (left) or structured (right) changes in selectivity.
In contrast to random, a structured rotation predicts both positive (for example, green and yellow) and negative (for example, purple and pink) correlations
in selectivity across time. d, The center plot shows the distribution of sensory and memory selectivity of individual neurons (z-scored (A – X) FR difference
during the A/X sensory period (x axis) and the A/X memory period (y axis); data from all days, nonselective neurons not shown). Subplots show A/X
selectivity traces from example neurons (marked in distribution). Top left: A–X switching; bottom left: A–A stable; top right: X–X stable; bottom right:
X–A switching. e–g, Observed proportions of single neurons (e), conjunctive neurons (f) and the ratio of conjunctive/single neurons (g). Conjunctive
neurons are selective during both sensory and memory (P ≤ 0.025), while single neurons are selective during one time period (P ≤ 0.025) but not the other (P > 0.025). All selectivity tests were by permutation (n = 1,000 shuffles) and Bonferroni-corrected. Histograms compare the observed proportion of neuron types across all days (green line; n = 522) to the null distribution (gray histogram; estimated by permuting selectivity across neurons within each time period, n = 1,000 shuffles). Scatter plots show the mean ± s.e.m. of proportion of neurons (z-scored by chance) across blocks and days. Gray squares indicate the significant difference from zero (P ≤ 0.01, bootstrap test, n = 5,000 resamples). e, The neural population contained a lower proportion of single neurons than expected by chance (top; 0.33, P < 1/1,000, permutation test) and decreased across blocks (bottom; slope mean ± s.e.m. = −0.12 ± 0.03, P < 1/5,000, bootstrap test). f, The proportion of conjunctive neurons was higher than expected by chance (left; 0.18, P < 1/1,000, permutation test) and increased across blocks (right; slope = 0.12 ± 0.03, P < 1/5,000, bootstrap test). g, The conjunctive/single ratio was higher than expected by random chance (left; 0.54, P < 1/1,000, permutation test) and increased across blocks (right; slope = 0.24 ± 0.08, P < 1/5,000, bootstrap test). All one-sided tests.

sensory representation (Extended Data Fig. 7d,f). The reverse trend different roles in prediction. That is, the sensory representation was seen on expected trials (Extended Data Fig. 7c). Together, these facilitates responses to expected stimuli, while the memory repreresults suggest that A/X sensory and memory representations have sentation magnifies unexpected stimuli or ‘prediction errors’.

720

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

a

A/X selectivity: stable and switching neurons

(phenograph clustering)

4 A/X
XY
2

B/Y

C/C*

D

X Stable

X Switching

z-scored FR difference

0

A Stable

–2

A Switching

AB
Sen.

(T1)
–4

0

175

Mem. (T2)

350

525

Time (ms)

b

Population A/X temporal selectivty

Sen. (T1)

Mem. (T2)

1

XY

15
100 10

Neuron (grouped by cluster)

z-scored A/X selectivity

200

5

0
300 –5

400

500 0

175

350

525

Time (ms)

–10 –15 AB

c

Similarity of A/X temporal selectivity

in functional clusters

Neurons

Cosine distance

1.75
1.50
1.25
1.00
0.75
0.50
0.25
0 N = 149 N = 59 N = 206 N = 108
Fig. 5 | Rotation creates an orthogonal memory representation. a, Unsupervised Phenograph clustering of the A/X temporal selectivity profiles revealed four clusters in the neural population (n = 522). Lines show the mean ± s.e.m. A/X selectivity over time per cluster (counts per group indicated in c). Purple and pink are switching neurons (32% of neurons, of which 35% prefer AB then XY and 65% prefer XY then AB). Yellow and green are stable neurons (68% of neurons; 42% prefer AB and 58% prefer XY). b, A/X selectivity over time shown across the total population of neurons (n = 522), grouped by cluster (color bars along y axis match a) and sorted by selectivity within group. The color axis indicates the z-scored difference in FR (XY – AB). A total of 36% and 31% of neurons were significantly selective during the A/X sensory and memory periods, respectively; 50% were selective during either period. c, Matrix of cosine distances between the A/X temporal selectivity profiles of neurons sorted by Phenograph labels (as in a, colored on both axes; counts per group indicated on the x axis).

Rotational dynamics transform sensory representations into orthogonal short-term memory representations. Together, our results show that the memory representation of the A/X stimulus is orthogonal to sensory inputs. By becoming orthogonal, the memory representation avoids interference by ‘getting out of the way’ of subsequent inputs (that is, C/C*). Orthogonal representations have notable computational advantages29,30. Theoretical work has found that orthogonalization minimizes the interference13, increases the memory capacity of neural networks12 and maximizes the separability of representations (improving decoding)14. Next, we were interested in understanding how the activity of individual neurons allowed the population representation of the A/X stimulus to transform from the sensory axis to an orthogonal memory axis.
Two general mechanisms could lead to orthogonal sensory and memory representations. First, sensory inputs and memory could be represented by independent populations of neurons (Fig. 4a). Second, sensory inputs and memory could be represented in orthogonal dimensions within the same population of neurons (Fig. 4b,c). To distinguish between these hypotheses, we tested whether neurons carried information about the A/X stimulus during both the sensory and memory time periods. Figure 4d shows the distribution of A/X selectivity during both the sensory and memory time periods across all A/X-selective neurons. This distribution contains two types of neurons: ‘single’ neurons, which are selective during only one time period (sensory or memory), and ‘conjunctive’ neurons, which are selective during both time periods. Under the independent mechanism, there should be more single neurons than expected by chance (Fig. 4a, insets). To test this, we generated a null distribution by permuting A/X selectivity in each time period across neurons, breaking any association of A/X selectivity between the sensory and memory time periods (Methods). Contrary to the prediction from the independent mechanism, we found fewer single neurons than expected by chance (Fig. 4e; single/n = 0.33, n = 522, P < 1/1,000, one-sided permutation test). This suggests that both sensory and memory representations exist within the same population of neurons, but along orthogonal dimensions (Fig. 4b,c).
There is a spectrum of mechanisms by which sensory representations could be transformed into memory representations within the same population. These mechanisms range from relying on neurons with random selectivity (Fig. 4c, left) to relying on neurons with structured changes in their selectivity (Fig. 4c, right). Previous work has argued that random selectivity can generate orthogonal representations29,30. However, in our dataset, a chi-squared test found that the observed counts of conjunctive and single neurons were significantly different from what would be expected by a random mechanism (chi-squared statistic = 120.48, P = 2.6 × 10−22, d.f. = 8; Methods). Likewise, across all 4 days, we found more conjunctive neurons and a greater ratio of conjunctive/single neurons than expected by the random mechanism (Fig. 4f,g; conjunctive/n = 0.18, n = 522, P < 1/1,000; conjunctive/single ratio = 0.54, P < 1/1,000, one-sided permutation tests). These effects increased with experience, whereby the proportion of conjunctive neurons and the ratio of conjunctive/single neurons were not initially significant on day 1, but increased to reach significance by the end of day 1 and continued to increase across days (Fig. 4e–g). Together, these results suggest that orthogonalization in the population is not just due to random changes in selectivity, but is facilitated by a structured mechanism that increases the proportion of conjunctively selective neurons.
To understand the nature of the structured mechanism, we examined how the selectivity of individual neurons changed from the sensory to memory time periods. To this end, we used an unsupervised clustering algorithm31 to group neurons by their time course of A/X selectivity (Methods). Clustering revealed two functional clusters of conjunctive neurons: stable and switching. Stable neurons maintained their contextual preference across the sequence,

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

721

Articles

NaTurE NEurosCiEnCE

while switching neurons switched their A/X contextual preference during the sequence (Fig. 5a and see Fig. 5b for the full population across all 4 days).
Further analyses confirmed that stable and switching dynamics captured the time courses of selectivity in the auditory cortex. First, we measured the pairwise similarity of the time courses of A/X selectivity for each pair of neurons. As seen in Fig. 5c, the four clusters of stable and switching neurons have high similarity within their cluster and low similarity between clusters. Second, these clusters were consistent within subsets of trials (C, C* and ambiguous stimuli; Methods and Extended Data Fig. 8). This reflects the reliability of clustering and suggests that the observed dynamics were not due to nonlinear mixing with the stimulus presented during the memory period. Finally, the clusters were non-overlapping when projected into low-dimensional spaces, and similar clusters were seen with other clustering approaches (Extended Data Fig. 9).
To confirm the significance of these neuron groups outside clustering, we used a binomial test to show the observed counts of stable and switching neurons were greater than expected by chance (Methods; stable proportion = 0.12, P = 5.96 × 10−15; switching proportion = 0.06, P = 0.019; conjunctive proportion = 0.18, P = 6.1 × 10−14; all greater than chance; single proportion = 0.33, P = 0.00019, less than chance, n = 522, all binomial tests). Several lines of evidence suggested that the increase in stable and switching neurons was not due to smoothing. The sensory and memory time periods are well separated within the sequence, our smoothing kernel was less than the space between the time periods and smoothing random selectivity did not produce the same level of structure as our neural recordings (Supplementary Figs. 5 and 6 and Methods).
Next, we investigated how stable and switching neurons supported the rotation of the sensory encoding axis to the memory encoding axis by examining the classifier weights of each neuron group. As expected by their conjunctive selectivity, stable neurons contributed significant weights to both the sensory and memory encoding axes (Fig. 6a). Similarly, switching neurons significantly contributed to both axes, but with inverted contributions to the A/X sensory axis and A/X memory axis (Fig. 6a). This reflects how switching neurons reverse their preference over time. A similar pattern was seen in the classifier weights of individual neurons, whereby sensory and memory classifier weights were positively correlated in stable neurons and negatively correlated in switching neurons (Fig. 6b; stable neurons slope = 0.51 ± 0.069, P < 1/5,000; switching neurons slope = −0.38 ± 0.089, P = 0.0004, one-sided bootstrap test). Over days of experience, the correlation between the A/X sensory and A/X memory weights of stable neurons increased, which is consistent with learning playing a role in developing structure in the rotation (Fig. 6c).
To visualize rotational dynamics in the population, we plotted the time course of A/X selectivity for stable and switching neurons (Fig. 6d,e for day 1 and 4, respectively). During the A/X period, both stable and switching neurons increased their selectivity to their (initially) preferred chord, thereby creating the A/X sensory axis. Then, over the sequence, switching neurons inverted their selectivity, rotating the sensory axis to the A/X memory axis. Thus, both stable and switching neurons work together to facilitate a structured rotation, and either alone is insufficient to create a memory axis that is orthogonal to the C/C* axis or to avoid interference. To directly show how the A/X rotational dynamics avoided interference with C/C*, we plotted the response of stable and switching neurons to the four conditions (Fig. 6f, limited to neurons with significant C/C* selectivity; Methods). Consistent with the alignment of sensory representations, responses to C and C* followed the initial sensory responses to A and X, respectively (as in Fig. 2b–d). Yet, because of the rotational dynamics in the population, the A/X memory axis was orthogonal to the C/C* sensory response, and therefore avoided interference (as in Fig. 3f–g).

Structure in rotation increases the efficiency of orthogonal representations. Our results suggest that sensory and memory representations are represented along orthogonal dimensions in the same population of neurons. Furthermore, we found evidence for structure in the rotational dynamics of these representations (Fig. 4). Previous work has highlighted the advantages of random projections14,32, but the relative advantages of a more structured rotation have not been quantified. Therefore, to contrast random and structured representations, we developed analytical and computational models of rotational dynamics (Methods). The computational model consisted of an input layer connected to a recurrent network of neurons (Fig. 7a). The input layer signaled the A/X and C/C* stimulus during each sensory period. Inputs fed into a recurrent ‘representational’ layer, which acted as a readout of sensory and memory information and was intended to capture the neural activity observed in the auditory cortex. Because the structure of the model mirrors our neural recordings, we could perform the same analyses on both datasets. That is, calculating selectivity and training classifiers to estimate the encoding axes during each time period and examining the dynamics of individual neurons. As with our neural recordings, we found that aligning the A/X and C/C* representations in the model increased both prediction and postdiction (Supplementary Fig. 4a,b).
Using this neural network model, we parametrically varied the degree of structure in the rotation by adjusting the recurrent weights in the representational layer. This allowed us to control the relationship between A/X sensory and A/X memory selectivity in single neurons, while creating network models with rotations ranging from a random rotation, which relied on random patterns of selectivity in individual neurons, to a structured rotation, which relied on stable and switching neurons exclusively (Fig. 7a, lower panel shows the spectrum of A/X selectivity produced by random to structured rotations, and Supplementary Fig. 4c). Regardless of the level of structure or randomness, all the neural network models generated orthogonal representations between A/X memory and C/C* sensory (Supplementary Fig. 4e). Note that some form of rotation was required to preserve A/X memory accuracy, and models without rotational dynamics showed interference between C/C* sensory and A/X memory (Supplemental Fig. 7).
As noted above, our experiments suggest that there is more structure in the rotational dynamics than expected by a random mechanism (Fig. 4). Consistent with our experimental observations, increasing the degree of structure in the rotation in the neural network model generated more conjunctive neurons, which were selective to both A/X sensory and A/X memory (Fig. 7b; a similar prediction was made by the analytical model). The computational and analytical models suggest that the increased structure may have several computational benefits.
First, a structured rotation requires fewer selective neurons than a random transformation, thereby creating a more compact representation. Figure 7c shows that adding structure to the rotation of the model decreases the proportion of neurons selective to A/X during the sensory and memory periods, while maintaining memory accuracy. This is because in a structured network, there are more conjunctive neurons, which carry twice the information of neurons selective during a single time period. To test this hypothesis in our recorded neural data, we randomly permuted sensory and memory selectivity across neurons to estimate the distribution of selection expected by a random mechanism. As predicted, we found that the percentage of selective neurons in our neural recordings was less than expected in a random mechanism (0.5, P < 1/1,000, n = 522, one-sided permutation test). Furthermore, we found that the percentage of selective neurons decreased over days (Fig. 7d; slope = −0.12 ± 0.03, P < 1/1,000, one-sided bootstrap test), which suggests that the structured rotation is learned. The advantage of a compact representation is

722

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Classifier weight (relative to preferred stimulus)

a

Both stable and switching neurons

contribute to A/X axes

A/X sensory

A/X memory

***

0.5
*** *** ***
0
***
–0.5

None

Stable Switching

d

Day 1 stable and switching dynamics

rotate A/X information over time

4

Switching neurons (FR difference, A/X selectivity)

2

C/C*

B

Y

0

DX D

A

C/C*
–2

A/X sensory axis

–4

A/X memory axis

–5.0 –2.5

0

2.5

Stable neurons (FR difference A/X selectivity)

Slope between sensory and memory axes

b

Stable and switching selectivity correlations

between sensory and memory classifiers XY

0.5

0

c

Correlation of A/X weights

increased with experience

Stable Switching

1.0

*** ***

** 0.5 *

0

A/X memory weights

–0.5
AB A

Stable (slope = 0.51)
Switching (slope = –0.38)

–0.5

0

0.5

A/X sensory weights

X

–0.5

**

***

–1.0

12 34 Day

e

Day 4 stable and switching dynamics

rotate A/X information over time

Switching neurons (FR difference, A/X selectivity)

3

2

C/C*

1

D

X

Y

0

–1
B
–2

A

D

C/C*

A/X sensory axis

–3

A/X memory axis

–4

–4

–2

0

2

4

Stable neurons (FR difference A/X selectivity)

Switching neurons (z-scored FR response)

f

Day 4 stable and switching rotational

dynamics avoid interference

1.5

1.0 0.5
0 –0.5

C* C

D
D X

B

A

D

Y C*

–1.0 –1.5

D

C

–2

–1

0

1

Stable neurons (z-scored FR response)

Fig. 6 | Neurons with stable and switching selectivity rotate the sensory representation into a memory representation. a, Stable and switching neurons
contributed to both A/X sensory and A/X memory axes. Violin plots show the full distribution of classifier weights (mean shown by bars). Weights were
reoriented such that positive weights reflect a match to the A/X sensory preference of the neuron. Stable neurons (n = 209) have positive weights in both A/X classifiers (sensory axis: 0.18 ± 0.015, memory axis: 0.17 ± 0.16, both P < 1/5,000 by two-sided bootstrap test). Switching neurons (n = 70) are positively weighted in the A/X sensory axis (0.14 ± 0.02) but negatively weighted in the A/X memory axis (−0.12 ± 0.018; both P < 1/5,000 by two-sided bootstrap tests). Switching neurons invert their selectivity between axes (difference in weights is 0.27, P ≤ 1/5,000, one-sided permutation test). ‘None’ neurons do not have significant selectivity at any time. b, The selectivity (classifier weights) of stable (green) and switching (red) neurons was correlated between the A/X
sensory (x axis) and A/X memory (y axis) classifiers. Lines show the mean and 95% CIs of bootstrapped linear regressions for each neuron type. Correlation
was positive for stable neurons (slope mean ± s.e.m. = 0.51 ± 0.069, P < 1/5,000) and negative for switching neurons (slope = −0.38 ± 0.089, P = 0.0004). Nonselective neurons (not shown) had no correlation (slope = 0.01 ± 0.063, P = 0.44). All one-sided bootstrap tests. c, Experience increased the correlation between A/X sensory and A/X memory classifier weights. Violin plots show the bootstrapped distribution of the slope of linear regression for each neuron
type on each day (horizontal lines indicate the mean). Stable slope mean ± s.e.m. on day 1 = 0.27 ± 0.12, P = 0.013, n = 60; day 2 = 0.46 ± 0.13, P = 0.0008, n = 56; day 3 = 0.72 ± 0.11, P < 1/5,000, n = 43; day 4 = 0.73 ± 0.18, P < 1/5,000, n = 50. Switching slope on day 1 = −0.15 ± 0.17, P = 0.18, n = 22; day 2 = −0.64 ± 0.16, P < 1/5,000, n = 19; day 3 = −0.45 ± 0.2, P = 0.015, n = 10; day 4 = −0.36 ± 0.2, P = 0.036, n = 19. All one-sided bootstrap tests. Differences in the regression slopes between stable and switching neurons: day 1 = 0.41, P = 0.046; day 2 = 1.08, P = 0.0008; day 3 = 1.18, P = 0.0018; day 4 = 1.1, P = 0.0004, all one-sided permutation tests. Experience increased the correlation of weights for stable neurons (slope across days = 0.16 ± 0.07, P = 0.009, one-sided bootstrap test), but not switching neurons (slope across days = −0.04 ± 0.08, P = 0.27, one-sided bootstrap test). d,e, The combined activity of stable and switching neurons rotates the A/X sensory axis into an orthogonal A/X memory axis, shown for day 1 (d) and day 4 (e). Neurons are grouped
by Phenograph labels (Fig. 5a) and initial sensory period preference (purple indicates A-preferring neurons, green indicates X-preferring neurons). Neurons
without A/X selectivity were removed. Average z-scored FR differences are plotted for both stable neurons (x axis) and switching neurons (y axis). The circle
size indicates the time during the sequence (larger radius indicates earlier time point). Labels indicate the time period and preference (that is, preferring A
or X at 0 ms). A/X sensory (orange) and A/X memory (blue) arrows are the average stable/switching selectivity taken during the sensory (0–100 ms) and
memory (350–450 ms) periods, respectively. f, Average stable and switching neuron z-scored responses to the four conditions (ABCD, orange; ABC*D, pink;
XYCD, green; XYC*D, blue). Note that the response to C/C* is aligned to the sensory response to A/X, but not A/X memory, thereby avoiding interference.
Only neurons with C/C* selectivity are included. Responses to A (purple) and X (green) conditions were merged before C/C* onset for clarity. For all panels,
permutation tests used 5,000 shuffles and bootstrap tests used 5,000 resamples across neurons. *P ≤ 0.05, **P ≤ 0.01, ***P ≤ 0.001.

that it is more resistant against interference and is robust against Second, our model showed that increasing the structure leads

changes in the population (for example, due to learning changing to a more efficient transformation from sensory to memory.

the selectivity of neurons)33,34.

Transitioning between states requires energy35; therefore, minimizing

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

723

Articles

NaTurE NEurosCiEnCE

TP2

A/X memory axis (accuracy) A/X memory axis (accuracy)

a
Representational neurons
Input layer A X C C*

Level of structure in rotation

0

0.33

0.65

1.0

b

Model: structured rotation increases

conjunctive/single ratio

0.1 + 0.44

2.5

1.44 – x

(r 2: 0.33)

2.0

Conjunctive/single ratio

1.5

1.0

0.5

c
Model: structured rotation increases efficiency of selectivity

45

Slope: –3.17

(r 2: 0.1)

0.80

40

0.75

Total selectivity (%)

0.70 35
0.65 30
0.60

25

0.55

TP1

d

Neural data: percent selective

decreased over days

(compared to random)

0 –2 –4

z-score

–6

–8

1

2

3

4

Day

0 0.25 0.50 0.75 1.00 Random→structured rotation

e

Model: structured rotation increases

efficiency of temporal dynamics

5.0

0.80

4.5 0.75

City block distance (A/X sensory and memory axes)

0.70 4.0
0.65 3.5
0.60

3.0

Slope: –0.31 (r 2: 0.12)

0.55

0.50

0

0.5

1.0

Random→structured rotation

0.50

0

0.5

1.0

Random→structured rotation

f

Neural data: city block distance

(A/X sensory and memory axes)

z-score (compared to random)

0

–2

–4

–6

1

2

34

Day

Fig. 7 | Rotational dynamics is an efficient mechanism for generating orthogonality. a, Schematic of the neural network model. Top: four input nodes (A, X, C, C*) were connected to a recurrent representational layer (n = 150 neurons; Methods). Trials consisted of binary activation of stimulus input nodes over two time periods (for example, AC, XC, AC* and XC* over TP1 and TP2). Responses from the representational layer were used to train classifiers
and to calculate selectivity. Changing the recurrent weights parametrically controlled the structure in the rotation. Bottom: four example networks with
increasing levels of structure reflecting the correlation of selectivity between A/X sensory (TP1) and memory (TP2; see Supplementary Fig. 4c for the full
range). The number of selective neurons per time period was fixed across all networks (n = 50 selective neurons). Classifier accuracy and mean angular relationships were similar across all levels of structure (Supplementary Fig. 4d,e). b, In the model, increasing structure in the rotation (x axis) increased the ratio of conjunctive/single neurons (y axis; conjunctive neurons are selective during both TP1 and TP2, while single neurons are selective during just one
period; Methods). Data shown from 5,000 model runs. Each dot represents a local density statistic (larger area = more model runs); dot color indicates the average A/X memory accuracy (scale in c). Line shows functional fit, matching analytical predictions (equation shown in plot; Methods). c, Increasing structure in the rotation of the model increased the efficiency of representations. That is, neural network models with increased structure (x axis) required
fewer selective neurons (y axis) to achieve the same representation accuracy. Figure format follows b. d, In the neural data, the percent of neurons selective during one or both time periods was less than expected by random mechanism (0.5, P < 1/1,000, n = 522, one-sided permutation test). Points show the mean ± s.e.m. of the percent selectivity decreasing over blocks of trials (slope mean ± s.e.m. = −0.12 ± 0.03, P < 1/5,000, one-sided bootstrap test). Format follows Fig. 4e–g. e, Increasing structure in the rotation of the model (x axis) increased the efficiency of the transformation, measured as a decrease in the city block distance between the sensory and memory axes (y axis). Format follows b and c. f, In the neural data, the A/X rotation was more efficient than expected by chance. Points show the mean ± s.e.m. of the city block distance calculated between the A/X sensory and A/X memory and divided by total neuron count (0.21, P < 1/1,000, n = 522, one-sided permutation test against random mechanism). Over blocks of trials, the city block distance decreased slightly (slope mean ± s.e.m. = −0.06 ± 0.04, P = 0.04, one-sided bootstrap test). Format follows Fig. 4e–g.

the magnitude of state change allows for a more efficient transformation. To measure the efficiency of the transformation from sensory to memory, we calculated the city block distance between the sensory and memory classifier weights (Methods). A smaller city block distance indicates that fewer changes in neural activity are needed to transform sensory representations to memories. Increasing the structure in the rotational dynamics of the model reduced the city block distance, which reflects a more efficient

transformation (while maintaining A/X memory accuracy, Fig. 7e).
Similarly, the transformation in our neural recordings was more
efficient than chance (city block distance = 0.21, P < 1/1,000, n = 522, one-sided permutation test; Methods), and the efficiency increased across days (Fig. 7f; slope = −0.062 ± 0.035, P = 0.043, one-sided bootstrap test).
Altogether, our results show that structured rotation is a more
compact and efficient mechanism for generating orthogonality

724

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

compared to randomization. It is more compact because it requires fewer neurons to represent both sensory and memory information. It is more efficient because it requires fewer changes in the neural response to move from the sensory to the memory representation. In other words, less energy (for example, from a control input or making a physical connection) is needed to switch from a sensory to a memory representation.
Discussion
Our study found that the brain avoids interference between sensory and memory representations by rotating the memory representation to become orthogonal to incoming sensory inputs. To study the interference between representations, we used an implicit learning paradigm, in which mice were repeatedly exposed to sequences of sounds. Experience with the sequences of sounds aligned the neural representations of associated stimuli in the mouse auditory cortex. This is consistent with previous work in the temporal lobe of monkeys, where single neurons learned to respond to pairs of temporally associated stimuli15,21–23. Our results extend these findings by showing associative learning leads to the alignment of population representations. This alignment facilitated predictions of upcoming stimuli, whereby when the contextual stimulus (A/X) was presented, the neural population encoded the predicted stimulus (C/C*; Fig. 1i).
The sensory alignment can also explain postdiction. An important cognitive phenomenon, postdiction allows new information to update the perception of previous events. This is particularly useful for stabilizing perception under noisy conditions28 because an ambiguous past percept can be updated to match the most probable scenario given the present stimulus2. However, we found that postdiction can also overwrite history when the animal encounters an unexpected stimulus. In this way, associative learning can lead to interference between sensory inputs, thereby reducing the ability of a sensory classifier to accurately represent the history of recent stimuli (Fig. 3b).
We found that the brain avoids such interference by rotating sensory information into a memory subspace (Fig. 3d). In our experiments, the A/X memory encoding existed on day 1, but became orthogonal to the C/C* sensory axis with experience. Thus, despite the associative learning between A/X and C/C* sensory inputs, new stimulus inputs did not interfere with the memory of the context (Fig. 3e,g). These population dynamics, which we observed in the auditory cortex of mice performing an unsupervised learning paradigm, are surprisingly similar to those found in the prefrontal cortex of primates performing working-memory tasks (Extended Data Fig. 6a shows an example cross-temporal correlation similar to previous work36,37). Similar dynamics have also been found in recurrent neural networks trained on serial-order recall13. Our results show that explicit training on a working-memory task is not necessary to generate rotational dynamics. Instead, they may be a property of how the brain processes and maintains sensory inputs. While short-term memory representations have been studied in the context of reward-driven behavior, the majority of learning in the lifespan of an animal is unsupervised, and so these dynamics may exist to avoid interference in those situations.
We examined several different mechanisms that could explain the observed rotational dynamics, and found evidence that rotations are structured. Previous work has proposed that orthogonal representations could emerge from neurons with random selectivity12,29. Our results build on this hypothesis, which suggests that individual neuron dynamics are not purely random, but enriched with two functional neuron types: a stable group that maintains its stimulus selectivity and a switching group that switches its selectivity over time (Fig. 5). Previous work in monkeys has found a similar dichotomy in working memory, whereby some neurons stably represent the contents of working memory38,39, while others

dynamically change their representation40–42. The relative contribution of stable and dynamic representations to working memory has been debated43–46. Our results argue that both response types are important: it is the combination of sustained and dynamic responses that facilitates the transformation of sensory representations into orthogonal memory representations, thereby reducing interference (Fig. 6).
Adding structured dynamics to the rotation creates a more compact and efficient mechanism for generating orthogonal representations (Fig. 7d,f). This has several potential advantages. Compact (sparse) representations maximize the amount of information held in short-term memory34. Similarly, increasing the efficiency of the rotation minimizes the energy needed to transition states. In addition, unlike randomization, a structured rotation is a functional transformation so that it can be easily implemented in a neural network. Future work is needed to understand whether structured rotation is common to all brain regions or if it is restricted to sensory cortices, while more cognitive regions (for example, the prefrontal cortex) use different mechanisms to generate orthogonality.
Future work is also needed to understand the mechanisms generating stable and switching dynamics. In the current study, we did not find any consistent differences in the anatomical location or intrinsic properties of stable and switching neurons that might explain their functional differences (Extended Data Fig. 10). Of course, stable/switching dynamics may reflect other, untested, biophysical differences, such as differences in cell type. Alternatively, the dynamics may reflect network interactions, whether from local recurrent connectivity or nonlinear interactions with top-down inputs. The latter may be more likely given that stable and switching dynamics increased over days and therefore may be learned (Fig. 4e–g). Finally, future work is needed to understand whether the increase in structural dynamics over days was induced by the increasing interference caused by the learned association.
Online content Any methods, additional references, Nature Research reporting summaries, source data, extended data, supplementary information, acknowledgements, peer review information; details of author contributions and competing interests; and statements of data and code availability are available at https://doi.org/10.1038/ s41593-021-00821-9.
Received: 9 December 2019; Accepted: 19 February 2021; Published online: 5 April 2021
References
1. Summerfield, C. & de Lange, F. P. Expectation in perceptual decision making: neural and computational mechanisms. Nat. Rev. Neurosci. 15, 745–756 (2014).
2. Kiyonaga, A., Scimeca, J. M., Bliss, D. P. & Whitney, D. Serial dependence across perception, attention, and memory. Trends Cogn. Sci. 21, 493–497 (2017).
3. de Lange, F. P., Heilbron, M. & Kok, P. How do expectations shape perception? Trends Cogn. Sci. 22, 764–779 (2018).
4. Fiser, A. et al. Experience-dependent spatial expectations in mouse visual cortex. Nat. Neurosci. 19, 1658–1664 (2016).
5. Jaramillo, S. & Zador, A. M. The auditory cortex mediates the perceptual effects of acoustic temporal expectation. Nat. Neurosci. 14, 246–251 (2011).
6. Chun, M. M. & Jiang, Y. Contextual cueing: implicit learning and memory of visual context guides spatial attention. Cogn. Psychol. 36, 28–71 (1998).
7. Dehaene, S., Meyniel, F., Wacongne, C., Wang, L. & Pallier, C. The neural representation of sequences: from transition probabilities to algebraic patterns and linguistic trees. Neuron 88, 2–19 (2015).
8. Carandini, M. & Heeger, D. J. Normalization as a canonical neural computation. Nat. Rev. Neurosci. 13, 51–62 (2012).
9. Buschman, T. J., Siegel, M., Roy, J. E. & Miller, E. K. Neural substrates of cognitive capacity limitations. Proc. Natl Acad. Sci. USA 108, 11252–11255 (2011).

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

725

Articles

NaTurE NEurosCiEnCE

10. Sprague, T. C., Ester, E. F. & Serences, J. T. Reconstructions of information in visual spatial working memory degrade with memory load. Curr. Biol. 24, 2174–2180 (2014).
11. Bouchacourt, F. & Buschman, T. J. A flexible model of working memory. Neuron 103, 147–160.e8 (2019).
12. White, O. L., Lee, D. D. & Sompolinsky, H. Short-term memory in orthogonal neural networks. Phys. Rev. Lett. 92, 148102 (2004).
13. Botvinick, M. M. & Plaut, D. C. Short-term memory for serial order: a recurrent neural network model. Psychol. Rev. 113, 201–233 (2006).
14. Rigotti, M. et al. The importance of mixed selectivity in complex cognitive tasks. Nature 497, 585–590 (2013).
15. Sakai, K. & Miyashita, Y. Neural organization for the long-term memory of paired associates. Nature 354, 152–155 (1991).
16. Miyashita, Y. & Chang, H. S. Neuronal correlate of pictorial short-term memory in the primate temporal cortex. Nature 331, 68–70 (1988).
17. Gavornik, J. P. & Bear, M. F. Learned spatiotemporal sequence recognition and prediction in primary visual cortex. Nat. Neurosci. 17, 732–737 (2014).
18. Li, N. & DiCarlo, J. J. Unsupervised natural experience rapidly alters invariant object representation in visual cortex. Science 321, 1502–1507 (2008).
19. Maheu, M., Dehaene, S. & Meyniel, F. Brain signatures of a multiscale process of sequence learning in humans. eLife 8, e41541 (2019).
20. Kim, R., Seitz, A., Feenstra, H. & Shams, L. Testing assumptions of statistical learning: is it long-term and implicit? Neurosci. Lett. 461, 145–149 (2009).
21. Yakovlev, V., Fusi, S., Berman, E. & Zohary, E. Inter-trial neuronal activity in inferior temporal cortex: a putative vehicle to generate long-term visual associations. Nat. Neurosci. 1, 310–317 (1998).
22. Griniasty, M., Tsodyks, M. V. & Amit, D. J. Conversion of temporal correlations between stimuli to spatial correlations between attractors. Neural Comput. 5, 1–17 (1993).
23. Amit, D., Brunel, N. & Tsodyks, M. Correlations of cortical Hebbian reverberations: theory versus experiment. J. Neurosci. 14, 6435–6445 (1994).
24. den Ouden, H. E. M., Friston, K. J., Daw, N. D., McIntosh, A. R. & Stephan, K. E. A dual role for prediction error in associative learning. Cereb. Cortex 19, 1175–1185 (2009).
25. Eagleman, D. M. Motion integration and postdiction in visual awareness. Science 287, 2036–2038 (2000).
26. Aru, J., Tulver, K. & Bachmann, T. It’s all in your head: expectations create illusory perception in a dual-task setup. Conscious. Cogn. 65, 197–208 (2018).
27. Choi, H. & Scholl, B. J. Perceiving causality after the fact: postdiction in the temporal dynamics of causal perception. Perception 35, 385–399 (2006).
28. Fischer, J. & Whitney, D. Serial dependence in visual perception. Nat. Neurosci. 17, 738–743 (2014).
29. Elsayed, G. F., Lara, A. H., Kaufman, M. T., Churchland, M. M. & Cunningham, J. P. Reorganization between preparatory and movement population responses in motor cortex. Nat. Commun. 7, 13239 (2016).

30. Itskov, P. M., Vinnik, E. & Diamond, M. E. Hippocampal representation of touch-guided behavior in rats: persistent and independent traces of stimulus and reward location. PLoS ONE 6, e16462 (2011).
31. Levine, J. H. et al. Data-driven phenotypic dissection of AML reveals progenitor-like cells that correlate with prognosis. Cell 162, 184–197 (2015).
32. Rigotti, M., Ben Dayan Rubin, D. D., Wang, X.-J. & Fusi, S. Internal representation of task rules by recurrent dynamics: the importance of the diversity of neural responses. Front. Comput. Neurosci. 4, 24 (2010).
33. Olshausen, B. A. & Field, D. J. Sparse coding of sensory inputs. Curr. Opin. Neurobiol. 14, 481–487 (2004).
34. Rust, N. C. & DiCarlo, J. J. Balanced increases in selectivity and tolerance produce constant sparseness along the ventral visual stream. J. Neurosci. 32, 10170–10182 (2012).
35. Bassett, D. S. & Sporns, O. Network neuroscience. Nat. Neurosci. 20, 353–364 (2017).
36. Murray, J. D. et al. Stable population coding for working memory coexists with heterogeneous neural dynamics in prefrontal cortex. Proc. Natl Acad. Sci. USA 114, 394–399 (2017).
37. Stokes, M. G. et al. Dynamic coding for cognitive control in prefrontal cortex. Neuron 78, 364–375 (2013).
38. Freedman, D. J., Riesenhuber, M., Poggio, T. & Miller, E. K. Visual categorization and the primate prefrontal cortex: neurophysiology and behavior. J. Neurophysiol. 88, 929–941 (2002).
39. Fuster, J. M. & Alexander, G. E. Neuron activity related to short-term memory. Science 173, 652–654 (1971).
40. Warden, M. R. & Miller, E. K. The representation of multiple objects in prefrontal neuronal delay activity. Cereb. Cortex 17, i41–i50 (2007).
41. Spaak, E., Watanabe, K., Funahashi, S. & Stokes, M. G. Stable and dynamic coding for working memory in primate prefrontal cortex. J. Neurosci. 37, 6503–6516 (2017).
42. Miller, P. & Wang, X.-J. Inhibitory control by an integral feedback signal in prefrontal cortex: a model of discrimination between sequential stimuli. Proc. Natl Acad. Sci. USA 103, 201–206 (2006).
43. Postle, B. R. The cognitive neuroscience of visual short-term memory. Curr. Opin. Behav. Sci. 1, 40–46 (2015).
44. Chaudhuri, R. & Fiete, I. Computational principles of memory. Nat. Neurosci. 19, 394–403 (2016).
45. Meyers, E. M. Dynamic population coding and its relationship to working memory. J. Neurophysiol. 120, 2260–2268 (2018).
46. Riley, M. R. & Constantinidis, C. Role of prefrontal persistent activity in working memory. Front. Syst. Neurosci. 9, 181 (2016).
Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
© The Author(s), under exclusive licence to Springer Nature America, Inc. 2021

726

Nature Neuroscience | VOL 24 | May 2021 | 715–726 | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Methods
Implicit learning paradigm. Mice were exposed to an implicit sequence-learning paradigm for four consecutive days. On each day, mice were head-fixed and they listened to 1,500 sequences of four chords (ABCD, ABC*D, XYCD and XYC*D). Mice were initially naive to all chords and sequences. Recordings lasted about 1 h and were done at the same time each morning (±1.5 h). As animals were on a reverse light-cycle, recordings were performed during their active time.
Within a sequence, each chord lasted 100 ms and was separated by a 75-ms inter-sound interval. Inter-trial intervals lasted between 500 and 1,000 ms (random uniform distribution). Each chord was a combination of 2 frequencies, all between 10 kHz and 65 kHz and spaced by 7/12 of an octave. A, B, X and Y sounds were lower in frequency than C and C* chords. The frequency of D fell between context and C/C* chords. If the frequency of A was less than B, then the frequency of X was greater than Y, and vice versa (8/12 of an octave). The frequencies and chords were varied across mice. Sound waveforms were created in Matlab, with a sample rate of 140 kHz, and played through MF1-S speakers (range of 1 kHz to 65 kHz; Tucker Davis Technologies). Speakers were calibrated with a CM16 microphone (Avisoft-Bioacoustics) and an Ultramic USB microphone (Dodotronic) to a sound pressure level of 70 dB. Sounds were played to the left ear. A light was presented 100-ms before all sequences, although it did not evoke a response in auditory cortex neurons.
Each sequence began with two chords that indicated one of two contexts. In the first context, the A chord was always followed by the B chord (the AB context). In the second context, the X chord was always followed by the Y chord (the XY context). Context AB was most frequently followed by C (rarely by C*), while context XY was most frequently followed by C* (rarely by C). All trials ended with D. Expected sequences (ABCD, XYC*D) occurred on 68% of trials (equal number of ABCD and XYC*D). Unexpected trials (ABC*D, XYCD) occurred on 20% of trials (equal number of ABC*D and XYCD). Overall, the AB and XY contexts occurred equally per day, as did the C/C* stimuli. This prevented any a priori expectation of any stimulus.
The remaining 12% of trials contained an ambiguous third stimulus, which was created by combining the frequencies of the C and C* chords. The ambiguous stimuli were randomly presented and did not interfere with associative learning. They were introduced for reasons unrelated to the current manuscript and therefore are excluded from all analyses, with the exception of verifying the clustering of the temporal dynamics (as detailed in Extended Data Fig. 8 and the section “Testing cluster labels on withheld data”).
Before and after the block of 1,500 sequence trials, the C and C* chords were played in isolation for 300 trials to measure the stability of representations. Each chord was played for 100 ms, with a random 500−1,000-ms delay between chords.
All animals experienced the same paradigm and therefore were not assigned to groups and did not require blinding of experimenters. All trial types occurred randomly during the 1,500 trials on a given day, according to their probabilities and ensuring equal numbers of trial types. The experimenter was blind to the trial details during the preprocessing of the data (for example, filtering, spike and sorting).
Neuronal recordings. Animal subjects. All animal procedures were approved by the Princeton IACUC and carried out in accordance with National Institutes of Health standards. Seven adult male PV-Cre+/− C57BL6 mice were used for recording and the passive-learning experiments. Mice were between 13 and 19 weeks old at the start of recording. Animals had free access to food and water and were housed in a reverse light-cycle. The ambient temperature was 20–26 °C and the humidity was 20–40%. Experiments were conducted in a soundproofed behavioral chamber.
Neural recordings. Neural activity was recorded at 30 kHz using an Intan RHD2000 system (Intan Technologies). Analog signals for the speakers were split and routed to the interface board, allowing for alignment of sound timing and neural activity.
Implant surgery. While under anesthesia, 32-channel silicon recording arrays (NeuroNexus) were implanted into the auditory cortex. Six mice were implanted with a four-shank probe (eight electrodes per shank), inserted along the anterior– posterior axis. One mouse was implanted with a one shank probe (32 electrodes total). All electrode probes were implanted in right auditory cortex, centered on stereotaxic coordinates −2.7 mm anterior–posterior and 4.8 mm medial– lateral from bregma. Probes were lowered to 970–1,400-µm below the cortical surface to target the primary auditory cortex (see Extended Data Fig. 10g for approximate neuron locations), although dorsal contacts may have also recorded from the secondary auditory cortex. Electrodes were stabilized using KwikSil (World Precision Instruments). Three screws (miniature self-tapping screws made from no. 303 stainless steel; J.I. Morris) were used to keep the headpost (three-dimensionally printed at Midwest Prototyping) and electrode stable. Ground wires were wrapped around the screw on the opposite side of the brain. Metabond (Parkell) was used to fix all implants to the skull.
After surgery, mice were given several days to recover, and buprenorphine was provided during recovery. Before the recording sessions, mice were acclimated to handling by the experimenter and head fixation in increments of 15 min.

The location of the silicon probe was confirmed by histology (see Fig. 1a for an example electrode placement from one animal). Electrode tracks were determined by labeling for astrocytes (GFAP, green).
Isolating single neurons. Single units were isolated from the raw 30-kHz signal using Plexon Offline Sorter. Raw data were imported into Plexon Offline Sorter and filtered using a 350-Hz highpass, 4-pole filter. Next, we re-referenced all channels to the common average. Using these traces, we identified clusters of spikes. Animals were excluded from future analysis if they had fewer than five single units. We recorded from ten animals, but only seven had sufficient single-unit activity to be included; otherwise no data were excluded from the study. No statistical methods were used to predetermine sample sizes, but our sample sizes were similar to those reported in previous publications4,17. From the remaining animals, we found 522 single units across the 4 days of recording (n = 121 on day 1, n = 124 on day 2, n = 134 on day 3 and n = 143 on day 4). See Supplementary Table 1 for a breakdown of neurons recorded per animal per day.
FR rate calculation. The instantaneous FR of neurons was estimated at each time point by inverting the inter-spike interval. This trace was smoothed with a 1-ms boxcar and downsampled to 1,000 Hz. Data were then segmented by trial start and end times. For sequence data, trials were taken from 70-ms before the A/X chord to 355-ms after the end of the D chord. For the C/C* chord alone, trials were taken to start 70-ms before chord onset and end 280-ms after the chord ended. Data were smoothed again with a 20-ms boxcar. All time labels in figures indicate the leading edge of any time frame or window (that is, including data before that labeled point). In example FR plots (Fig. 1b), the mean and s.e.m. are shown; expected conditions were randomly downsampled to match the trial count of unexpected conditions (n = 150 trials per condition). Preprocessing of FR data (segmentation and smoothing), computation of the z-scored FR difference and Phenograph clustering were performed in Matlab 2016 (Mathworks). All other analyses were performed in Python 3.5.5. For the Python analyses (jupyter notebook47), we utilized the scipy (v.0.19.1)48,49, sklearn50 numpy (v.1.13.1)51 and pandas (v. 0.20.3)52 packages (specific functions referenced below). All plotting was done with matplotlib (v.3.0.3)53. The network model (Supplementary Figs. 4 and 7 and Fig. 7) was written in Python 3.7.3 using PyTorch v.1.0.1.
Encoding axes (classifiers). Training classifiers. All classifiers were trained using the same procedure. Classifiers only differed in their training period and condition groupings. Each classifier was trained on each day for each animal, using the vector of the averaged FR of simultaneously recorded neurons. The FR was averaged over a 100-ms time period, starting 10-ms after stimulus onset (to account for the delay in sensory response). This resulted in a matrix of mean FRs for each neuron and each trial (that is, matrix size = neurons × trials). See Supplementary Table 2 for a list of classifiers and their details. When forming groups for all classifiers, trials were balanced across conditions (ABCD, XYCD, ABC*D and XYC*D), and a subset (10%) were withheld for testing. The resulting classifier is a hyperplane defined by its orthogonal vector (size = neurons) and an intercept (size = neuron).
Classifier type. We used a standard linear support vector machine classifier for all classification analyses. The linear classifier relates x (features) to y (output) via a linear equation, with weights (w) and an intercept (b) as follows:
f ðxÞ ¼ wT x þ b

Using the projection (f(x)), inputs (x) can then be classified into categories. Here, we used classifiers to map N-dimensional FR data onto a one-dimensional (1D) encoding space. This allowed us to understand how the FR data encodes a given stimulus (that is, A versus X).
For cross-validation, a condition-balanced set of trials (10% of all trials) were withheld and used in all future analyses and figures. The remaining trials were used to train the classifier. To prevent bias in the classifier, we downsampled the expected trials to match the unexpected trial count. To ensure that all of the training trials were incorporated into the classifier, we downsampled the expected data 100 times and trained a classifier on each sample. The final classifier was calculated by taking the mean (intercept (b) and weights (w)) of these 100 trained classifiers.
To train the classifier, we used the stochastic gradient descent SGDClassifier function in the sklearn.linear_model package (sklearn v.0.19)50 for Python 3 (v.3.5.5). This method fits the classifier weights (w) and intercept (b), by minimizing the error function, which is a combination of a loss function (L(y,f(x)) = hinge loss) and regularization (R(w) = elastic net) as follows:

Eðw;

bÞ

¼

1 n

Xn
i¼1

Lðyi ;

f

ðxi ÞÞ

þ

αRðwÞ

Classifier regularization. To minimize overfitting of the classifiers, we used elastic net regularization (R(w) in the above equation). Elastic net regularization combines the L1 and L2 norms to increase the sparsity and to decrease the length

Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

of the weights (w), respectively. The alpha (α) parameter determines the amount of regularization. Parameters were the same for all classifiers (neural data and model): the L1 ratio (the elastic net parameter specifying the ratio of L1-to-L2 penalties) was set to 0.65, α (the regularization amount) was set to 0.01, the learning rate was set to 0.00001 and the number of iterations was set to 1,000.
Testing the generalizability of results across classifier hyperparameters. As shown in Supplementary Fig. 3, we varied the hyperparameters and classifier type to ensure that neither affected our results. We tested hinge, log and squared loss-linear classifiers. Hyperparameter ranges were α (regularization level) =  [0, 0.001, 0.01, 0.1] and L1/L2 ratio (elastic net ratio) = [0, 0.25, 0.5, 0.65, 0.75, 1].
Sensory classifiers. Sensory classifiers distinguished between two sounds during their presentation. The A/X, B/Y and C/C* sensory classifiers were trained using the average stimulus-evoked FR activity (A/X = 10–110 ms, B/Y = 185–285 ms and C/C* = 360–460 ms). Condition groups were the two possible stimuli (for example, A/X classifier distinguished A and X trials). Note that an additional C/C* sensory classifier was trained using the response to the C/C* chords (100 ms) presented in isolation (Extended Data Fig. 3). Similar results were found with both the C/C* classifiers.
Memory classifier. The A/X memory classifier was trained to classify trials by their context (AB or XY) based on neural activity during the presentation of the C/C* stimulus (360–460 ms).
Relationship between the B/Y classifier and the other classifiers. The probabilistic transition from A/X to C/C* allowed us to balance the trials used in their classifiers and, thus, independently decode both the A/X and C/C* representations during the sequence. In contrast, the transition from A/X to B/Y is deterministic (all A stimuli were followed by a B stimulus and X by Y). Because of this, we could not balance A/X and B/Y trials when constructing a B/Y classifier; therefore, the B/Y classifier is only differentiated from the A/X sensory and memory classifier by the time period of the response. Unsurprisingly, on day 1, A/X and B/Y sensory axes were aligned (consistent with their association), but this decreased with experience (Extended Data Fig. 1f). In contrast, the B/Y and C/C* sensory axes were not aligned (Extended Data Fig. 1g). This may reflect the fact that the C/C* stimulus was already fully predicted by the A/X stimulus, and so the subsequent B/Y stimulus did not add predictive value24. Importantly, this does not affect the results relating the A/X sensory, C/C* sensory and A/X memory axes.
Cross-temporal classification. To study the evolution of A/X context information, we performed cross-temporal classification. We trained classifiers to distinguish between A and X conditions using 25-ms time bins of FR data, stepping by 10 ms, throughout the sequence. These classifiers were then tested on their ability to distinguish A/X trials on withheld trials (across the same set of 25-ms bins). This provided an estimate of how well the classifiers generalized across time (Extended Data Fig. 6a).
Tracking the evolution of sensory and memory information within a day. In addition to training a single classifier for the entire day, we trained classifiers within a day. This allowed us to follow the time course of learning within a session. To train within day, classifiers were trained on 6 blocks per day, with each block consisting of 500 trials, stepped by 200 trials. For each block of trials, we balanced conditions and used cross-validation (withholding 10% of trials) to test performance and to make projections.
Within-day classifiers were used to study the angular relationship between encoding axes during learning (Figs. 2b and 3g) and to measure the city block distance between the A/X sensory and A/X memory classifier (Fig. 7f). To combine across animals, classifier weights were length-normalized by the number of neurons. Within-day classifiers showed similar trends to whole-day classifiers when decoding responses (Supplementary Fig. 2). Differences are likely due to the limited number of trials (limiting the statistical power) available for testing the classifier performance within a block of trials (12 trials per condition per animal).
Projection onto the encoding axis. To study how the high-dimensional population activity encodes variables within the sequence, we projected the FR activity on withheld trials into a 1D encoding space defined by the trained classifiers. The projections are signed on the basis of labels chosen during training. For example, on the A/X sensory axis, a negative projection indicates A encoding while a positive projection indicates X encoding (see Fig. 1c for a schematic of the projection).
To examine how this encoding evolved over time, we projected neural activity over the time course of the sequence. For each trial (withheld from training, n = 1,064 trials), we calculated the average vector of neuron FR in 25-ms time bins, stepping by 10 ms, over the course of the sequence presentation. At each time bin (t), we took the dot product between each FR vector (FR(t)) and the relevant encoding axis (w, size = neuron), and then added its intercept (b) as follows:
ProjectionðtÞ ¼ FRðtÞ  w þ b

Classifier training and projections were completed for each trial (withheld from training) on a mouse-by-mouse basis (that is, each day is separate and we did not create a pseudopopulation of neurons across days). Before combining trial projections across mice, we z-scored the projections across conditions (that is, subtracted the mean and divided by the standard deviation, calculated from all conditions). Once, z-scored we could combine trial projections across animals to study population encoding. Note that this z-score captures the relative separation between conditions across time and ignores any absolute drift in FRs occurring over time.
To examine how encoding of context (AB versus XY) and C/C* stimulus changes over time, we performed two-sided t-tests (function: ttest_ind from scipy.stats package) on each time bin (d.f. = 1,062). Although we did not test for normality, the z-scoring procedure was intended to normalize the data to support the assumption of normality underlying the t-test. The neural population is said to be carrying significant information about a stimulus (or memory) if the associated P values is ≤0.001, Bonferroni-corrected for multiple comparisons across time (for example, Fig. 1d,e).
Strength of encoding. We defined the ‘strength of encoding’ as a metric of classifier accuracy, which combines both the magnitude and accuracy of the trial projections. Recall that the projection of a trial on a given axis indicates how much activity of that trial represents either the negative or positive label (for example, A and X respectively, on the A/X sensory axis). Therefore, to combine trial projections across all conditions (and animals), we inverted (that is, flipped the sign of) the projection of trials with a negative label. For example, to test A/X encoding (Fig. 1f, n = 1,064 withheld trials per day), we inverted the projection of A condition trials (ABCD and ABC*D).
Measuring classifier accuracy with area under the curve. After training, each classifier defines a hyperplane in feature space (FR of neurons) that separates samples as belonging to one of two conditions (for example, AB or XY). This label may be correct (true positive or true negative) or incorrect (false positive or false negative). To supplement analyses using the projection onto encoding axes, we calculated the area under the curve (AUC) of the receiver operator characteristic curve to measure classifier performance (Supplementary Fig. 1; using sklearn. metrics package). The AUC statistic measures how well the classifier is able to separate the two distributions, whereby an AUC of 1 indicates perfect performance, an AUC of 0.5 indicates random chance and an AUC < 0.5 indicates that the classifier assigned samples to the wrong condition label. The AUC was calculated for fixed time periods and in a sliding window moved over the sequence time course (Extended Data Fig. 2). The AUC showed qualitatively similar effects as the projections onto the encoding axis. In the main manuscript, we focused on the projections because they show on a trial-by-trial basis whether neural representations move in the predicted or unpredicted direction and provide a more direct measure of effect size.
Statistics and reproducibility. Almost all analyses used one of three different forms of nonparametric permutation tests: (1) bootstrap to estimate the distribution of a statistic, (2) bootstrap to estimate the distribution of a linear regression and (3) permutation test to test for differences between groups. Below we detail these three tests.
Bootstrapped estimates of the distribution of a statistic. Bootstrapped distributions were used to estimate distributions for plotting and for statistical tests. In general, the procedure involved resampling data (for example, trials or neurons) with replacement 5,000 times54 and recalculating a statistic (for example, mean projection, angle or principal components (PCs)). Next, this distribution was tested against a null hypothesis (for example, tested against zero). The percent of the bootstrapped distribution above or below the null hypothesis value was taken as the likelihood that the neural data were greater than (or less than) the null hypothesis.
For example, we tested the significance of encoding strength (accurate versus inaccurate) during each time period. We randomly resampled from the observed trials with replacement54. Using this bootstrapped distribution, we could determine whether the encoding strength (that is, accuracy) was significantly different from zero (that is, significantly positive/correct or negative/incorrect). To do this, we estimated the probability that the observed response was zero by measuring the percent of the bootstrapped distribution that was above or below zero, for positive and negative observed mean projections, respectively (in this example, we doubled the probability and report the two-sided P value).
Bootstrapped estimate of the distribution of linear regressions. To measure changes across time (for example, days or blocks), we calculated linear regressions (scipy.stats.linregress) across time points. For example, we measured the change in encoding strength across days (Figs. 1i and 3b), the change in angle between classifiers (Figs. 2b and 3g) and the change in relative structure in the rotation (Fig. 4e–g). To estimate the distribution of values of the linear regression, we used a bootstrapped procedure, as described above (5,000 resamples). Using this distribution, we calculated the mean and standard deviation of the slope

Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

(or r values) and plotted the mean trend line and their 95% confidence intervals (CIs; that is, ±1.96 times the standard deviation of the trend lines). Finally, we tested whether the observed slope was significant by estimating the probability that the observed slope was zero and by measuring the percent of the bootstrapped distribution that was above or below zero, for positive and negative observed slopes, respectively (one-sided P value).

Permutation test for differences between groups. We used permutation tests to test the significance of an observed difference across groups. First, we calculated the observed difference between group means. Then, the group labels were permuted (4,999 times), and the difference between the means of the shuffled groups was calculated. The shuffled and non-shuffled differences were combined to create a null distribution (size of 5,000). This null distribution shows the differences expected given no actual difference between the two groups. The likelihood of our observed difference was then estimated as its percentile within the full null distribution.
For example, we used a permutation difference test to compare the A/X encoding strength along the A/X sensory axes versus the A/X memory axes (Extended Data Fig. 6b). First, we calculated the difference of mean encoding strength between axes. Then, we randomly permuted the classifier labels (for example, A/X sensory or memory) across trials (4,999 times) and recalculated the difference in mean encoding strength. This distribution was combined with the original observed difference to create the null distribution, which was used to calculate the significance of the observed difference.

Assumptions underlying the statistical tests. One advantage of nonparametric tests is that they do not make assumptions about the underlying distribution. Note that there is a lower bound on nonparametric significance measures; exact P values below 1/N cannot be reported, where N is the number of shuffles/resamples. Parametric t-tests were used when measuring differences between trial projections onto a specified encoding axis (for example, Fig. 1d). These data were z-scored before the t-test, supporting the underlying assumption of normality, although normality was not formally tested for each time bin. In addition, these results were confirmed with nonparametric tests.
For all statistical tests, all neurons and trials from the four relevant conditions were used. As detailed above, the experimental paradigm was repeated in seven animals.
Additional information on research design is available in the Nature Research Reporting Summary.

Calculation of angles between axes. To examine the relationship between

representations, we measured the angle between encoding axes (that is, the angle

between the trained classifiers/hyperplanes). To estimate the angle across animals,

classifier weights were normalized to length 1 and combined across animals (per

day or per block). Using these vectors (one per hyperplane; size = neurons), we

calculated their angle as follows:





Angle ¼ arccos

AB kAkkBk

To ensure that the angle was not biased by outliers within the neural population, we bootstrapped across neurons, recalculating the angle on each of 5,000 resamples; these distributions were then used when measuring changes in angles across days with linear regression. The reported angles within a day were calculated by taking the mean and standard deviation across all blocks within a day (Fig. 3g). These results were not qualitatively different from angles calculated between classifiers trained on all trials within a day.
When building the A/X and C/C* classifiers, we labeled conditions such that associated stimuli shared the same sign (A and C were negative, X and C* were positive). Therefore, angles between the classifiers that are less than 90° correspond to the classifier responses aligning with the predicted, expected associations (for example, neurons that prefer A (or X) also prefer C (or C*)). Angles greater than 90° indicate that the selectivity of the populations is aligned with respect to unexpected pairings (for example, neurons that prefer A (or X) also prefer C* (or C)).
Testing the correlation of single neuron responses to A/X and C/C*. We found the alignment between the A/X sensory and C/C* sensory axes (Fig. 2b). To relate this to the selectivity of single neurons, we calculated the selectivity of each to the A/X and C/C* stimuli (see the section “Temporal selectivity profiles”). We measured the correlation between A/X and C/C* selectivity across neurons with linear regression (variance estimated by bootstrapping across neurons). To test whether this relationship changed across days (Fig. 2c,d), we performed a regression on the slope across days.
Neural activity in 2D state spaces (dimensionality and angle). To understand how the neural population encoded two dimensions at once, we projected neural activity over time onto two encoding axes, creating a 2D space. For example, Fig. 2a shows the encoding of A/X sensory and C/C* sensory information along

the x and y axes, respectively. Projections were as described above in “Projection on the encoding axis”.
Calculation of PCs and dimensionality of neural trajectories in state space. To understand the dimensionality within each 2D state space, we performed PC analysis (sklearn.decomposition.PCA) on the distribution of the mean projections of all four conditions within the 2D state space (that is, concatenating the time course from ABCD, ABC*D, XYC*D and XYCD). This resulted in two PCs. Each PC captured a proportion of the variance in responses within the 2D space, which defined the explained variance ratio (EVR) of that PC. The EVR of PC1 was used to estimate the dimensionality of the neural trajectories within the 2D state spaces. A high EVR for PC1 indicates low dimensionality because PC1 is explaining most of the variance. Meanwhile, if PC1 EVR equals half, the dimensionality is high because both PCs explain similar amounts of variance, which occurs when the trajectories move equally in all dimensions (Fig. 3h).
We used a permutation test to test whether the observed dimensionality was lower than expected by chance (Fig. 3h). For this, we created a null distribution of projections into the 2D state space by randomly permuting (4,999 shuffles) the time labels within the sequence of each point, separately in both the x and y dimensions. For each permutation, we recalculated the EVR. The null distribution (5,000; shuffles plus the observed value) was used to estimate the probability of randomly observing a value greater-than-or-equal to the original EVR (one-sided test).
Statistics on EVR and PC angle. We used a bootstrap procedure (as described above) to estimate the distribution of PC angles (that is, violins in Fig. 3h) and the EVR of the PCs. The bootstrap process involved randomly sampling trials (5,000 with replacement) within each condition group, projecting neural activity into the state space, calculating the mean trajectory per condition and then recalculating the PCs (and respective EVRs). These distributions were used for calculating regressions (one-sided test) and estimating the variance of the distributions.
We use a permutation procedure (as described above) to compare the PC angles and EVRs across state spaces. For this, we shuffled (4,999 permutations) mean data projections across state spaces and recalculated the difference in PCs, angles and EVR (5,000; shuffles plus the observed value). With this distribution, we estimated the probability of observing the original difference across state spaces under the null hypothesis that there was no difference between state spaces (one-sided test).
Dimensionality in full neural space. To study global changes in the neural space, we also calculated the dimensionality of neural responses in the full N-dimensional neural space (where N is the number of neurons). The analyses followed the same framework as the dimensionality calculations within the encoding state spaces. For each day, we combined neurons across animals to create a pseudopopulation. We averaged the FR per condition (ABCD, ABC*D, XYCD and XYC*D, balancing the number of trials) within 25-ms bins, stepped by 10 ms. The average response was calculated for each condition around the presentation of C/C* (340–520 ms) and PCA was performed on the concatenated data (size = (condition × time) × N). The distribution of EVRs was estimated with a bootstrap; resampling neurons with replacement per day and then recalculating the PCs. These were then used to estimate the change in EVR across days (Extended Data Fig. 5e).
Estimating trial-by-trial correlations between C/C* encoding and A/X sensory and memory encoding. To test whether the A/X sensory and memory representations affect sensory processing, we correlated the A/X sensory and memory responses on a given trial with the strength of C/C* response (Extended Data Fig. 7). To understand how A/X encoding strength influences future sensory processing, we took A/X encoding 50-ms before the C/C* stimulus and correlated it with C/C* encoding strength (taken during the C/C* stimulus: 360–460 ms). The timing of A/X and C/C* encoding were separated to ensure any observed relationships did not simply recapitulate the alignment of the axes.
We examined expected and unexpected stimuli independently (n = 532 trials for both groups; all trials withheld from classifier training). Responses to negatively coded trials (for example, A trials and C trials) were inverted such that all positive values indicate correct encoding and negative values indicate incorrect encoding. We used bootstrapped linear regression to correlate the strengths of the C/C* representations and the A/X sensory or A/X memory representation.
Timing of crossover from A/X sensory to A/X memory encoding. To gain insight into the timing of the A/X rotation, we estimated the moment during the sequence when A/X encoding switched from A/X sensory to A/X memory encoding (Extended Data Fig. 6c). The crossing time point was defined as when the A/X encoding was stronger along the A/X memory axis than the A/X sensory axis. The crossover time was restricted to 25-ms after sequence onset to avoid early spurious crossovers. A bootstrap procedure (5,000 resamples of trials with replacement) estimated the variance in timing and changes over days.
Rotation of A/X sensory to A/X memory. Temporal selectivity profiles. A/X selectivity changed over the sequence time course, from a sensory representation

Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

to a memory representation. To understand how the dynamics of individual
neurons supported this transformation, we measured the temporal selectivity
of each neuron (n = 522 neurons). Selectivity was measured as the difference in FR between the AB and XY trials (n = 600 trials). All four conditions were balanced (n = 150 trials), which ensured that A/X selectivity did not reflect the C/C* stimulus response. The A/X FR difference was calculated in 25-ms time bins
(stepping by 10 ms) over the entire trial (from −160 ms to 790 ms, relative to the onset of the A/X stimulus, creating 96 time bins). To normalize the FR difference
of each neuron, we z-scored its FR difference (for each time bin, t) against a null
distribution, which was created by randomly permuting the trial labels (n = 1,000 shuffles of AB and XY trial labels).

zFRðtÞ

¼

FR

differenceðtÞ � meanðFR difference shufflesðtÞÞ s:d:ðFR difference shufflesðtÞÞ

To measure the changes in selectivity within a day, we calculated the z-scored FR difference for each neuron in 6 blocks per day (again balancing trials by condition; 500 trials per block, stepped by 200 trials). A similar approach was used to calculate z-scored FR differences to the C/C* stimulus (grouping trials by C/C*).
To illustrate how A/X rotational dynamics avoid interference from the C/C* sensory input, we plotted how stable and switching neurons respond to the four conditions (Fig. 6f). The z-scored FR response of each neuron to each of the four conditions (ABCD, ABC*D, XYCD and XYC*D) was estimated by calculating the difference in response to that condition, relative to the mean response to all conditions (trials were balanced across conditions). To combine and average condition responses across neurons within a group (stable and switching), we inverted neurons with a preference to X. As the goal of this analysis was to plot the response to the C/C* stimulus, we only included neurons selective to C/C* (similar results were seen when including all neurons). To declutter the plot, we averaged the condition traces across A and X conditions before the onset of C/C*.
Testing for structure in the rotation: measuring the proportion of conjunctive and single selectivity in the neural population. The three different mechanisms for rotation (Fig. 4a–c; independent, random and structured) make different predictions about the number of neurons selective for A/X in one time period (single neurons are selective during either sensory or memory) or both time periods (conjunctive neurons are selective during both sensory and memory). The independent mechanism predicts more single neurons than expected by the random mechanism. In contrast, a structured rotation predicts more conjunctive neurons (and fewer single neurons). Therefore, to differentiate between these mechanisms, we determined the A/X selectivity of each neuron during the sensory and memory time periods. A neuron was considered selective for a given time period if its z-scored FR difference was significant at any time point during that time period (abs(z-score) ≥ 1.96, or P ≤ 0.025, Bonferroni-corrected by the number of time points). Significance was independently measured in both the A/X sensory time period (0–100 ms) and the A/X memory period (350–450 ms). In rare cases where multiple crossings occurred within the time range, the selectivity was determined by the mean response.
For each time period, a neuron belonged to one of three categories: it represented the A stimulus, X stimulus or was not selective for either (a null, or 0, neuron). Combining across the two time periods (sensory and memory), neurons can be in nine different categories (Supplementary Table 3). These can be grouped into three categories: conjunctive neurons that are selective during both time periods (AA, XX, AX and XA); single neurons that are selective during only one time period (A0, X0, 0X and 0A); and nonselective neurons that are not selective to A/X in either time period (00). On a given day (or within a block), we calculated the proportion of recorded neurons in each selectivity category (conjunctive or single). To correct for the overall degree of selectivity in the network, we used the conjunctive/single ratio as our main measure of structure in the rotation.
Nonparametric test against the random mechanism. While the independent mechanism predicts more single neurons than the random mechanism, the structured rotation predicts fewer single and more conjunctive neurons than the random mechanism. By definition, the random mechanism argues that changes in selectivity should have no relationship over time. Therefore, to test against the random mechanism, while controlling for overall selectivity, we created a null distribution by permuting selectivity across neurons within each time period (n = 1,000 permutations), thereby breaking any relationships in selectivity across time periods. We determined the likelihood of our observed results by measuring the percentile of our observed neural proportions in the null distribution (Fig. 4e–g).
To examine changes over time (blocks and days), we first controlled for changes in the number of selective neurons by z-scoring. To this end, we subtracted the mean of the random chance distribution and divided it by the standard deviation of the random chance distribution (Fig. 4e–g). To estimate the distribution of z-scored values, we used a bootstrap procedure (5,000 resamples of neurons, per block per day). For each bootstrap, we recalculated the z-scored proportions of conjunctive and single neurons and used the resulting distributions to estimate changes across days.

Testing for structure in the rotation: chi-squared and binomial tests. We tested the full table of A/X temporal selectivity of neurons from all 4 days (n = 522; Supplementary Table 3) against random chance by using a probabilistic model followed by chi-squared and binomial tests. For each time period, a neuron has a probability of being selective to either A or X. The probability of being selective tppomAs Ae=mooprrsAXenpdmX=uemrpi,nsXregnestaphneedcsteipvnmesloy=r. yWpomAereammsse=ummopemXrdyemtph.eeHripeorrdoe,bcpaasbnailbnitedywppmreirtatrseetnimtahsuelppusArseonibsoaerbqipulisXateilne: asnodf selectivity during the sensory period and memory period, respectively. Therefore, the probability of nonselectivity during the sensory period and memory period can be written as 1 − 2ps and 1 − 2pm, respectively. Because the random mechanism predicts selectivity will be independent across time, the probability of each of the nine categories can be estimated by multiplying the probabilities of selectivity in each time period. Supplementary Table 4 shows the probabilities of each of the nine A/X selectivity types as predicted by a random mechanism.
Because we were interested in comparing the levels of conjunctive neurons against random, we used the counts of single (A0, X0, 0A and 0X) and nonselective neurons (00) to fit ps and pm (using the scipy.optimize.minimize function, by minimizing the sum of squared errors between the predicted single and nonselective counts). Using the fitted values for ps and pm, we calculated the probabilities of each of the nine neural selectivity categories. Together, these nine probabilities can be compared to the observed proportions in the neural data with chi-squared and individual binomial tests.
Testing for structure in the rotation: generating and testing random selectivity data. To further test against a random mechanism and to ensure that our results were not due to smoothing over time, we generated random temporal selectivity profiles and performed the same set of analyses as were applied to our neural data. Random profiles consisted of responses that ranged from a sustained response (profile 0) lasting the full sequence of 550 ms to a short 50-ms response (profile 20), with intermediate profiles decreasing linearly after the initial 50-ms response (Supplementary Figs. 5 and 6). Next, each response profile was multiplied by random values drawn from a standard normal distribution (μ = 0, σ = 1) to generate A/X selectivity. Finally, we smoothed this random data using kernels between sizes 80 ms and 400 ms (lowess function in Matlab). To avoid smoothing artifacts, time points were padded by the size of the largest smoothest kernel. This process was repeated 1,000 times for each profile and smoothing level to create a distribution of randomly generated temporal selectivity profiles.
The resulting random selectivity data were analyzed in the same manner as the neural data, calculating selectivity during A/X (0–100 ms) and C/C* (350–450 ms). For each ‘random’ population, we calculated the number of neuron counts per A/X temporal selectivity pattern (Supplementary Table 3). Note that the random data cannot yield similar selectivity as our data, as the percentage of selective neurons was much greater than expected by chance (36%). So, we had to set a ‘selectivity’ threshold to reproduce the observed neural selectivity. Using these random selectivity counts, we tested whether random data could generate a structured rotation to the same degree as observed in the neural data. Supplementary Fig. 6a shows the resulting chi-squared values on random data, and Supplementary Fig. 6b compares the results to the neural data. Supplementary Fig. 6d shows the percentage of random populations that were significant (P ≤ 0.05) for the three binomial tests that were all significant in the neural data.
Using the same techniques applied to the neural data, for each ‘random’ population, we obtained z-scores indicating whether the selectivity proportions (of single and conjunctive neurons) of the random population were unexpected by a random mechanism. Next, we compared the level of structure observed from our neural data to what was observed in the randomly generated data. Supplementary Fig. 6e,g,i shows how far away, in standard deviations, the neural results were from the results generated for each profile/smoothing combination of randomly generated data. Supplementary Fig. 6f,h,j compares neural data to the combined results from all randomly generated data.
Clustering of temporal selectivity profiles. Phenograph. To explore the structure in the temporal selectivity profiles across our neural population, we used the unsupervised Phenograph clustering algorithm55 to cluster the profiles of all recorded neurons, across all days (n = 522). Phenograph works by (1) forming a connected graph of data points, where the edge weight between two nodes is the Euclidean distance in their temporal profile of selectivity, and then (2) clustering points based on the community structure within this connected graph. Each community has a ‘modularity’, which compares the density of edges within and between identified communities. The Louvain Community algorithm56 iteratively discovers communities within the K-nearest neighbors, and collapses connected nodes into groups until modularity is maximized55. We chose the Phenograph algorithm because it does not require a priori specification of the number of clusters and is used in several fields31.
Varying the parameter (k) in Phenograph. The Phenograph algorithm is unsupervised, whereby the only parameter is the number of local connections (k) that are used to define the local communities. Previous work has shown that the algorithm is robust against changes in this parameter31. Based on recommendations

Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

from this work, we initially chose k = 40. As shown in Extended Data Fig. 9b, we confirmed the stability of clustering by systematically varying k and calculating two
measures of clustering: the modularity statistic of Phenograph and the silhouette score of the discovered clusters57.

Validating Phenograph clustering: d-prime. We used d-prime to validate that the

clusters were not overlapping in space. For each pair of clusters being compared,

the Euclidean distance between cluster means (μ1 and μ2) is calculated in the full

96-dimensional space. This is divided by the square root of the average of the

variances

(

σ

2 1

and

σ22)

within

each

cluster

as

follows:

d0 ¼ qdiﬃsﬃﬃtﬃﬃðﬃμﬃﬃﬃ1ﬃﬃ;ﬃﬃμﬃﬃﬃ2ﬃﬃÞﬃﬃﬃ

1 2

ðσ21

þ

σ 22 Þ

Following the methods described above, we used a permutation test (shuffling cluster labels 999 times) to test whether the observed d-primes were significantly greater than expected by chance Extended Data Fig. 9a.

Validating Phenograph clustering: UMAP. To further verify our observed clusters, we used the uniform manifold approximation and projection algorithm (UMAP)58 to project the temporal profiles of single neurons into two dimensions (Extended Data Fig. 9c).

Validating Phenograph clustering: K-means clustering. We also compared the Phenograph clustering to K-means clustering (sklearn.cluster.KMeans) using the same data. As K-means performs poorly in high dimensional spaces59, we clustered points within the reduced dimensional UMAP space. For each fit, we used 1,000 random restarts. All function parameters were set to the default. Unlike Phenograph, K-means requires the number of clusters to be prespecified. To test how the number of clusters affected the clustering, we varied the number of clusters prespecified and compared the resulting silhouette scores (Extended Data Fig. 9d). To facilitate the interpretation of the silhouette score, we performed the same clustering on different datasets (random data and C/C* temporal selectivity profiles). The random data were generated by smoothing the Gaussian noise with the same number of neurons and time points as the neural data.

Validating Phenograph clustering: cosine distance matrix. To assess the similarity of the temporal profiles of all recorded neurons, we measured the cosine distance (scipy.spatial.distance.cdist) between the vectors (Fig. 5c). Cosine similarity is defined as follows:

1

�

uv kukkvk

where −1 is maximally dissimilar and 1 is maximally similar.

Testing cluster labels on withheld data. We tested whether the dynamics of stable and switching neurons were consistent across condition groups (for example, trials where C, C* or Cmix stimuli were presented). For example, the dynamics of A/X selectivity could be calculated using only C trials (that is, ABCD and XYCD). We applied the original Phenograph labels to these selectivity profiles and measured the correlation between the selectivity in the subset of trials and the original dataset (Extended Data Fig. 8a,b). Note that because only trials with the same one-third of stimuli were used, A/X FR differences could not arise from interactions between A/X and the C or C* stimulus. Furthermore, the ABCmixD and XYCmixD datasets were never included in the original A/X z-scored FR difference or Phenograph clustering. Nevertheless, stable and switching neurons showed similar A/X response profiles and averaged selectivity on these withheld trials (Extended Data Fig. 8a,b).

Measuring the contribution of stable and switching neurons to the A/X encoding axes (classifiers). Average classifier weight for stable and switching neurons. To understand how the stable and switching functional neuron types contributed to the A/X sensory and memory axes, we calculated the distribution of classifier weights for each cell type (Fig. 6a). To reduce noise, we post-hoc identified and isolated neurons that were selective for none of the time periods (P > 0.025, Bonferroni-corrected). To combine weights from both A-preferring and X-preferring neurons, the weights of all initially A-preferring neurons were inverted (that is, multiplying their weights by −1). Therefore, the weight distributions in Fig. 6a reflect similarity with the initial preference of that neuron (either A or X). We combined the weights of all neurons (across days and animals) for each neuron group (stable, switching and none).

Correlation between sensory and memory classifier weights. We tested how A/X selectivity of individual neurons changed between the A/X sensory and A/X memory time periods by linearly regressing the weights of the A/X sensory and A/X memory classifiers for each group of neurons (stable, switching or none; Fig. 6b). The weight vector within each animal was length-normalized before combining weights across all animals and days. Statistical significance of the

linear regression was determined with a bootstrap test (as described above, 5,000 resamples of neurons with replacement). To test whether experience changed the linear relationship between A/X sensory and A/X memory classifier weights, we calculated the linear regression between weights on each day (Fig. 6c; bootstrapping to assess significance). To test whether the linear relationship in weights was significantly different between the switching and stable neurons, we compared the observed difference in slope to a randomly permuted, null distribution created by shuffling stable and switching labels across neuron weights (4,999 times; Fig. 6c).

C/C* selectivity in functional neuron types. The representation of A/X and C/C* became more similar with experience (Fig. 2). To test whether these changes were specific to either stable or switching neurons, we examined C/C* stimulus temporal selectivity of both neuron types for both expected and unexpected sequences (Extended Data Fig. 10e). For each neuron group (stable or switching), we plotted their A/X and C/C* z-scored FR differences. To combine across all preferences within a group, we inverted the A/X selectivity and C/C* selectivity of neurons that initially preferred A. This means that the A/X responses are relative to initial preference. Likewise, C/C* responses reflect whether the average selectivity of the neuron group aligns with expected (AC/XC*, positive responses) or unexpected (AC*/XC, negative response) sequences. To test whether a neuron group carried the prediction, we averaged the C/C* response (350–450 ms) and used a bootstrap test across neurons (5,000 resamples, two-sided test; Extended Data Fig. 10f).

Testing for intrinsic differences in stable and switching neurons. Fano factor. Fano factor measures the variability of neural responses. To compare the inherent variability of each neuron group (stable and switching), we measured the fano factor of single neurons over the sequence. First, we binned the raw spiking data (sample rate = 30 kHz; 40-ms bins, stepping by 16.7 ms). In each bin (w), spikes were summed and the fano factor (F) was calculated across all trials per neuron:

FðwÞ

¼

σ

2 w

μw

For each functional group (stable and switching neurons), we combined across neurons and days (Extended Data Fig. 10a). Extended Data Fig. 10b shows the average fano factor during the pre-stimulus period (−400 to 0 ms, relative to the A/X stimulus start), the stimulus presentation periods (A/X, B/Y, C/C* and D) and the inter-chord intervals

Intrinsic timescale of neuron types. Following previous methods60, we estimated

the intrinsic timescale of each neuron using autocorrelation, which reflects the

time duration over which the neuron integrates information. Extended Data

Fig. 10c shows the average autocorrelation of stable and switching neurons (on

the pre-stimulus period: −400 to 0 ms). To quantify the decay exponential to the bootstrapped average autocorrelation: y =

time, Ae−

we fit

x τ

+C

an (using

scipy.optimize.curve_fit).

Analytical model of rotational dynamics. Our data show that A/X information rotates from a sensory representation to a memory representation over time via dynamics in the population response. As detailed in the manuscript, these dynamics can range from random to structured. To understand the relative benefits of a structured versus random rotation, we derived analytical expressions for the efficiency of the representation. To facilitate closed-form solutions, this model is simplified. Therefore, it is missing several characteristics of the real data or the neural network model (which is detailed below), such as noise in the responses and variability in the level of selectivity across neurons.

Random network. In the random network, we defined the probability of oappfsXs0seeminng,ne=rmiefsi1ocprae−ync-ttspirevsAeleeesnlpcy−.toiTnvpehssXeenenbep.yurLoraiobknnaeebswuiailrsiroteeyn, pdotmAufoeramsinnenagonsntodhsreeyplemmXicnetempimvutetoosrAAeynapasnenodrrdiyXoXdna,emsutherpemosAenpnoriraosynb,dabilities respectively. The probability of nonselective neurons during the memory period is pm0 em = 1 − pmA em − pmX em.

Structured network. A ‘pure’ structured rotational network consists of only stable

and switching neurons. Similar to the random network, these neurons are either selective for A or X during the sensory time period, with probability psAen and psXen.
Stable neurons maintain their selectivity across A and X time periods, such that



pmA em ¼

1; 0;

if neuron is selective for sensory input A else



pmX em ¼

1; if neuron is selective for sensory input X 0; else

The opposite relationship exists for switching neurons:

Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE



pmA em ¼

1; 0;

if neuron is selective for sensory input X else



pmX em ¼

1; if neuron is selective for sensory input A 0; else

To define an intermediate model, we portioned the total available neurons (N) into two groups: structured and random, with proportion q. Here, qN neurons adhere to structured (stable/switching) rules, while (1 − q)N adhere to random rules.
First, the model allowed us to write the conjunctive/single ratio as a function of rotational structure. Second, using this model, we can highlight the efficiency of a structured rotation with two metrics: percent selectivity and rotational cost.

Ratio of conjunctive/single selective neurons. One key feature differentiating

a structured from a random rotation is the relative proportions of conjunctive

neurons to singly selective neurons. In the random network, the likelihood of a

conjunctive neuron is pconj = probability of single neuron is

ppsAseinng(p=mA epms0en+(ppmAmXeemm)++ppmXsXeemn )(p+mA epmm0 e+m

p(pmXsAeemn

), and the + psXen).

To simplify the algebra, we assumed that the probability of a neuron

selectively representing sensory or memory is all equal. In other words, p = psAen = psXen = pmAem = pmX em. With this simplification, the proportion of conjunctive to singly selective neurons in the random network is as follows:

pconj psing

¼

4ð1

4p2 � 2pÞp

¼

1

p � 2p

In contrast, in a structured rotation, all selective neurons are conjunctive, with a likelihood
pconj ¼ psAen þ psXen ¼ 2p

We defined the conjunctive/single ratio in an intermediate network by linearly

mixing between the models. Recall that q defines the proportion of structured

neurons in the network. Therefore, the proportion of conjunctive to singly selective

neurons can be written as follows:

pconj psing

=

4p2 (1−q)+2pq 4(1−2p)p(1−q)

=

2p(1−q)+q 2(1−2p)(1−q)

=

p (1−2p)

+

q 2(1−2p)(1−q)

=

1

1

2(1−2p) (1−q)

−

1 2

singGleivraetniothsactal(e1s−1w2pi)th≥(1−01 q∀).pIn∈o[t0h,er12

], and that q ∈ [0, words, increasing

1], the conjunctive/ q (that is, increasing

the

proportion of structured neurons) increases the conjunctive/single ratio.

Percent total selectivity. Next, we examined the metrics of efficiency using this

analytical framework. First, we calculated the percent of selective neurons. A lower

percentage indicates more efficiency in the representations of the network.

In the random network, the probability that a neuron

is involved in the sensory and/or memory representation is

prsealnd = 1 selectivity

− (1 − psAen − psXen)(1 are equal, this reduces

− to

ppmArseaelnmd

− =

p4mXp e−m ).4Ap2s.suming

all

probabilities

of

In the structured network, because the sensory selectivity of a

neuron determines its memory selectivity, the probability of selectivity is

pssterluc = 1 − (1 − psAen − psXen Importantly, for 0 ≤ p ≤

) = 2p. 12, pssterluc

≤

prsealnd,

showing

the

structured

rotation

is

always more efficient than the random one.

From these equations, we defined the percent selectivity in intermediate

models as a linear mixing of the structure and random network, such that the

number of selective cells in an intermediate model is a linear function of q:

pmselix that

= (4p p ≤ 12,

− 4p2) (1 − q) + 2pq = −2p (1 − 2p) the percent selectivity will decrease with

q + (4p − q, showing

4p2). Given that increasing

the structure in the network reduces the number of neurons involved in the

representation.

Efficiency of the rotation. Finally, we estimated the efficiency of the rotation. For

this, we scored neurons based on how much their selectivity (response) changed

between time periods. Neurons with no change (for example, nonselective or stable

neurons) cost 0. Neurons that are selective in one time period but not the other (for

example, single neurons) cost 1. Neurons that switch their selectivity cost 2.

The random network consisted of conjunctive, single and

nonselective (psAenpmX em +

npsXeeunpromAnems.)T+hepcs0oenst(pomAf eamra+ndpomXmemr)o+tat(iopnsAenis+CopsXsetnra)npdm0 =em.2Assuming

a

single likelihood of selectivity (p), this can be reduced to 4p − 4p2.

A structured rotation involves only stable neurons (which cost 0) and switching

neurons (which cost 2). Assuming half the conjunctive neurons are switching

neurons,

the

cost

of

the

structured

rotation

is

Coststruc

=

2

1 2

(psAen

+

psXen )

=

2p.

Intermediate models linearly combine these costs, weighted

by q, and so the relative proportion of structure in the network is

Costmix = (4p − 4p2) (1 − q) + 2pq = −2p (1 − 2p) q + (4p − 4p2). Again, this is a linear function with respect to q and, given p ≤ 12, cost decreases with increased structure.
Altogether, this simplified analytical model shows that increasing the structure of rotation increases the ratio of conjunctive/single neurons, reduces the total number of neurons involved in the representations and increases the network efficiency.
Neural network model of rotational dynamics. To compare structured and random rotations, we developed a neural network model of rotational dynamics. This model extended the analytical model as it included sensory variance, noise and the observed associative learning between the A/X and C/C* sensory representations (and subsequent interference).
The network consisted of two layers: an input layer (Li) that represented external inputs and a representational layer (Lr) that captured the recorded neural responses. While there is no learning in the model, we used PyTorch to take advantage of its network module structure. The input layer consisted of four different inputs capturing sensory inputs (A, X, C and C*). The representational layer consisted of 150 neurons, with the selectivity of each neuron determined by the feedforward weights (Wir) from the input layer. Weights between neurons in the representational layer (Wrr) defined the recurrent dynamics. The FR of the representational layer was a rectified linear function of the input (x) ReLU(x) = max(0, x). The network ran in two time steps, with added Gaussian noise (ε = N(0, a), where a = 2, unless otherwise noted). Therefore, activation in the representational layer (Lr) at a given time period (t) can be described by Lr (t) = ReLU(Li (t) Wir + Lr (t − 1) Wrr + ε).
Each trial involved the sequential activation of A or X inputs, followed by C or C* inputs. As in the task, the four possible sequence trial types were AC, AC*, XC and XC*. Each instance of the model consisted of 1,000 trials with equal trial counts per condition. There is no learning in the model, and the weights between the sensory layer and network were preset to reflect the association between A/X and C/C*. Without learning, there was no need for unequal trial counts to generate an association; therefore, trial counts per condition were balanced to match our neural analysis.

Model recurrent weights. Recurrent weights (Wrr) were designed via two general

ways. First, control models without rotation had no recurrence (Wrr = 0), decaying

self-recurrence or stable self-recurrence (that is, Wrr

=

1 2

I

and Wrr = I for decaying

and stable, respectively).

Second, rotation models had recurrent weights that rotated representations

with varying degrees of structure. Creating rotation models, with or without

structure, required specifying the selectivity of each neuron. The selectivity of a

neuron can be understood as a point in two dimensions (ws, wm), where the first dimension (ws) defines selectivity during the sensory time period, and the second dimension (wm) defines selectivity during the memory time period. We created a relationship between the sensory and memory selectivity by drawing their values

from a 2D Gaussian with a nondiagonal covariance matrix. The diagonal elements

of the covariance matrix represent the variance of selectivity within each time

period (set to 0.451). The off-diagonal elements represent the covariance across

time periods (that is, the relationship between sensory and memory selectivity).

Increasing the off-diagonal covariance increased the structure of the rotation

(Supplementary Fig. 4c).

Depending on its specified selectivity, each neuron was assigned a positive

FR response to A and X (giving it A/X selectivity) per time period. This defined

the sensory response matrix (SenAX = N × 2), and the memory response matrix (MemAX), where the first and second columns of each matrix indicate A and X
selectivity, respectively. For example, an A-preferring neuron (n) would be assigned

a (ws,0) sensory response in SenAX[n,:]. If the neuron had stable selectivity for A, its memory response in MemAX[n,:] = (wm,0). Meanwhile, an AX-switching neuron would be assigned the sensory response (ws,0) in SenAX and the memory response (0,wm) in MemAX. The network contained an equal number of stable and switching neurons (N = 25 of each, N = 50 overall), although the model results were robust

against changes in the ratio between stable and switching neurons (for example,

using a ratio of 2:1 of stable to switching neurons, similar to the experimentally

observed ratio, gave qualitatively similar results). In addition, there was an

equal probability of neurons preferring A or X. Given the sensory and memory

selectivity matrices, the recurrent weight matrix could be determined as Wrr = MemAX × inv(SenAX).
To vary the degree of structured rotation in the model, we varied the

covariance of sensory and memory selectivity. When covariance = 0, the rotation

occurs by random changes in selectivity. By increasing the covariance (from 0

to 0.45 in 50 steps), we increased the number of conjunctively selective neurons,

which increased the structure of the rotation. All graphs show the normalized

covariance as the level of structure in the rotation (for example, Fig. 7b, x axis:

random→structured). The normalized covariance (valued between 0 and 1) is

the selectivity covariance (off-diagonal) divided by the variance in selectivity

(diagonal). Increasing the covariance led to an increase in the conjunctive/single

ratio in the network (Fig. 7b). Note that unlike when analyzing the neural data, we

did not z-score our calculation of the conjunctive/single ratio because selectivity

Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

was fixed across model runs. Given the predictions from our analytical model,

we quantified how the increased structure (x) leads to an increased conjunctive

proportion (y) by fitting the following function: optimize.curve_fit).

y

=

A B−x

+ C (fit with the scipy.

We did not directly fit the observed neural conjunctive/single ratio to our

model because it is not possible to disambiguate measurement noise in neural

activity and differing levels of structure in the rotational dynamics (random versus

structured).

Model input weights: controlling the degree of association between A/X and C/C*. Associations between A/X and C/C* stimuli were built into the model through construction of the input weights (Wir). All weights between the input and representational layer (Wir) were drawn from the absolute value of a Gaussian distribution (that is, zero input weights lead to nonselective neurons). We parametrically controlled the level of association between A–C and X–C* in the population by adjusting the number of neurons with combined A–C and X–C* selectivity. The association level was varied between 0 and 0.95. Importantly, the structure of the model allowed us to manipulate the level of association without affecting the metrics of efficiency or the rotational dynamics.

Analysis: alignment of axes and prediction/postdiction. Neural network activity was analyzed in the same way as the experimental neural data using activity from the representational layer (Lr) of the network. As above, we trained linear classifiers (using the same parameters) during both sensory and memory time periods to determine A/X sensory, C/C* sensory and A/X memory axes. Likewise, we calculated the classifier accuracy (using AUC), and the angle between them, to ensure that our model recapitulated the observed angular relationships.
Also following neural analyses, we validated the relationship between alignment (AC/XC* prediction) and interference (postdiction). We measured the prediction of the network by calculating the accuracy of the C/C* sensory classifier in discriminating the A/X sensory input, which reflects the extent to which the A/X stimulus encodes the expected stimulus C/C* (Supplementary Fig. 2b). To determine the amount of postdiction or interference, we calculated how accurately the A/X sensory classifier discriminated A/X on unexpected trials (A–C*, X–C) during the A/X memory period (Supplementary Fig. 2c). The same model structure was used to study rotational dynamics, where the level of rotation was fixed to 0.31 for these simulations (although the level of rotation did not affect the prediction/postdiction results).

Recurrent neural network weight manipulation: validation of rotation. To test

whether rotation avoids interference, we created three networks to serve as

controls that had recurrent weight matrices without rotational dynamics. In

the first control, nonrotating network, we set all weights to zero (Wrr = 0); this also removes any sustained activity. The second and third control networks

had diminishing and sustaining self-excitatory activity by setting the recurrent

weights to Wrr

=

1 2

I

and I, respectively. To test whether these networks could

avoid interference, the association between A/X and C/C* sensory inputs was

set to 0.95. After simulating the networks, we assessed rotation by calculating

the change in A/X selectivity (z-scored FR difference) across sensory and

memory time periods (Supplementary Fig. 7a). Networks with nonrotating

weight

matrices

(Wrr = 0,

1 2

I

and

I)

did

not

rotate

their

A/X

representations,

thereby showing that nonlinear mixing of A/X sensory and C/C* responses is not

sufficient to induce a rotation.

Next, we compared the A/X memory accuracy in these nonrotating networks

to the memory accuracy from networks with rotation (random and structured). In

addition, we calculated A/X memory accuracy over all trials and on unexpected

trials (where interference is expected). Supplementary Fig 7b shows that the

nonrotating

networks

(Wrr = 0,

1 2

I

and

I)

exhibited

interference.

Metric of efficiency: total selectivity. We measured the efficiency of rotational dynamics by quantifying how compactly the network stores information about the A/X stimulus. To measure this, we calculated the percentage of neurons involved in representing A/X at any time during the sequence (that is, the total selectivity). We tested the observed percent of selective neurons against expectations from a random mechanism using the permutation test described in “Nonparametric test against the random mechanism” (Fig. 7d).
Using our network model, we varied the rotational structure to test its impact on efficiency. For networks with varying rotation structure, we calculated the percent total selectivity (that is, number of A/X-selective neurons/N). Based on predictions of the analytical model, we used linear regression to relate the level of structure in the rotation to the total selectivity (Fig. 7c).

Metric of efficiency: city block distance. We measured the efficiency of the network by quantifying the number of neurons that changed their preference between the sensory and memory representations. To estimate the energy of a change in representation, we used the city block distance (that is, Manhattan distance or L1 norm) as follows:

Xn City blockðu; vÞ ¼ jui � vij
i¼1
To measure the efficiency in rotation of the neural data, we measured the city block distance between the A/X sensory and A/X memory axes. Classifier weights were normalized within each animal by dividing the weight vector by its norm, before combining weights across animals. To control for changes in the number of recorded neurons across days, we divided the city block distance by the total number of neurons. A null distribution, representing the random mechanism, was created by permuting selectivity across neurons within the sensory and memory time periods. The null distribution was then used to calculate the z-scored city block distance per block across the 4 days of recording (Fig. 7f).
Using our network model, we tested whether parametrically increasing the structure in the rotation decreased the city block distance between the axes by using linear regression to relate the level of structure in the rotation to the city block distance between axes (Fig. 7e).
Reporting Summary. Further information on research design is available in the Nature Research Reporting Summary linked to this article.
Data availability
The data that support each main figure are included as source data. Original data are available upon reasonable request. Source data are provided with this paper.
Code availability
The code supporting the implementation and analysis of the neural network model is available on our lab GitHub repository (www.github.com/buschman-lab). As the model was analyzed in the same way as the neural data, the same analysis code can be applied to neural data.
References
47. Perez, F. & Granger, B. E. IPython: a system for interactive scientific computing. Comput. Sci. Eng. 9, 21–29 (2007).
48. Millman, K. J. & Aivazis, M. Python for scientists and engineers. Comput. Sci. Eng. 13, 9–12 (2011).
49. Oliphant, T. E. Python for scientific computing. Comput. Sci. Eng. 9, 10–20 (2007).
50. Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011).
51. Walt, S., van der Colbert, S. C. & Varoquaux, G. The NumPy Array: a structure for efficient numerical computation. Comput. Sci. Eng. 13, 22–30 (2011).
52. McKinney, W. Data structures for statistical computing in Python. Proc. 9th Python Sci. Conf. 445, 56–61 (2010).
53. Hunter, J. D. Matplotlib: a 2D graphics environment. Comput. Sci. Eng. 9, 90–95 (2007).
54. Manly, B. Randomization, Bootstrap and Monte Carlo Methods in Biology (Chapman & Hall/CRC, 1997).
55. Nicosia, V., Mangioni, G., Carchiolo, V. & Malgeri, M. Extending the definition of modularity to directed graphs with overlapping communities. J. Stat. Mech. Theory Exp. 2009, P03024 (2009).
56. Blondel, V. D., Guillaume, J.-L., Lambiotte, R. & Lefebvre, E. Fast unfolding of communities in large networks. J. Stat. Mech. Theory Exp. 2008, P10008 (2008).
57. Rousseeuw, P. J. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. J. Comput. Appl. Math. 20, 53–65 (1987).
58. McInnes, L., Healy, J. & Melville, J. UMAP: uniform manifold approximation and projection for dimension reduction. Preprint at arXiv https://arxiv.org/ abs/1802.03426 (2018).
59. Beyer, K., Goldstein, J., Ramakrishnan, R. & Shaft, U. in Database Theory— ICDT’99 (eds Beeri, C. & Buneman, P.) 217–235 (Springer, 1999).
60. Wasmuht, D. F., Spaak, E., Buschman, T. J., Miller, E. K. & Stokes, M. G. Intrinsic neuronal dynamics predict distinct functional roles during working memory. Nat. Commun. 9, 3499 (2018).
Acknowledgements
The authors thank C. MacDowell, M. Panichello, C. Jahn, F. Bouchacourt, P. Hoyos and S. Henrickson for their detailed feedback during the writing of this manuscript. We also thank B. Briones for helping with histology and B. Morea for helping with surgery. We thank the Princeton Laboratory Animal Resources staff for their support. This work was supported by NIMH R01MH115042, ONR N000141410681 and NIH DP2EY025446 to T.J.B.
Author contributions
T.J.B. and A.L. conceived the project and designed the experiments. A.L. did surgery on the animals, collected the data, constructed computational models and analyzed the data, with supervision from T.J.B. A.L. and T.J.B. wrote the paper.

Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

Competing interests
The authors declare no competing interests.
Additional information
Extended data is available for this paper at https://doi.org/10.1038/s41593-021-00821-9.

Supplementary information The online version contains supplementary material available at https://doi.org/10.1038/s41593-021-00821-9.
Correspondence and requests for materials should be addressed to T.J.B.
Peer review information Nature Neuroscience thanks Omri Barak and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.
Reprints and permissions information is available at www.nature.com/reprints.

Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Extended Data Fig. 1 | Encoding along the B/Y Sensory Axis. a, The neural population encoding of B/Y shown on (a) Day 1 and (b) Day 4. For each of the four conditions, the plot shows the mean ± s.e.m. of the population projection onto the B/Y sensory axis. Yellow outlines B/Y training period (185–285 ms). For panels a-e, n = 1064 withheld trials, z-scored and then combined across animals per day. Positive and negative projections indicate Y (green) and B (purple) encoding, respectively. Light and dark grey horizontal bars mark significant differences for AB vs XY and C vs. C*, respectively (two-sided t-tests, p ≤ 0.001, Bonferroni corrected). c, Data show mean ± s.e.m. of B/Y stimulus encoding strength on the B/Y sensory axis. Negatively labeled conditions (that is, B) were inverted, such that positive values on y-axis indicate B and Y trials are ‘correctly’ encoded as B and Y, respectively. Day 1 = 0.34 ± 0.021, Day 2 = 0.33 ± 0.22, Day 3 = 0.33 ± 0.022, Day 4 = 0.31 ± 0.021, all days p < 1/5000 two-sided bootstrap tests. Slope across days mean ± s.e.m. = −0.01 ± 0.01, p = 0.16, one-sided bootstrap test. d, Points show mean ± s.e.m. of A/X stimulus encoding strength on the B/Y sensory axis, during A/X stimulus presentation. For panels d-f, lines and shaded regions show mean and 95% CI of bootstrapped linear regressions. Positive values indicate correct A/X encoding: Day 1 = 0.13 ± 0.021, p < 1/5000, Day 2 = 0.062 ± 0.023, p = 0.0064, Day 3 = 0.096 ± 0.022, Day 4 = 0.031 ± 0.023, p = 0.17, all two-sided bootstrap tests. Slope across days mean ± s.e.m. = −0.028 ± 0.01, p = 0.0016, one-sided bootstrap test. e, Points show mean ± s.e.m. of C/C* stimulus encoding strength on the B/Y sensory axis. Positive values indicate correct encoding of C/C* association on the B/Y sensory axis (that is, C and C* should go in B and Y direction, respectively). Day 1 = −0.10 ± 0.023, p < 1/5000, Day 2 = −0.056 ± 0.024, p = 0.016, Day 3 = −0.006 ± 0.023, p = 0.81, Day 4 = −0.044 ± 0.023, p = 0.055, all two-sided bootstrap tests. Slope across days mean ± s.e.m. = 0.022 ± 0.01, p = 0.017, one-sided bootstrap test. Note, this trend does not appear in analysis of blocks of trials within a day (Supplementary Fig. 2f). f-g, Points show mean ± s.e.m. of angles between B/Y sensory axis and (f) A/X and (g) C/C* sensory axes (n = 5000 resamples of neurons). Significant differences from 90 degrees shown by grey boxes (p≤0.01, one-sided bootstrap tests). Significant change in angle to A/X sensory axis over time is shown by grey line (shaded region is 95% confidence interval of bootstrapped linear regression). The B/Y and A/X sensory axes were initially aligned, but became orthogonal over days: change over days, slope = 0.84 ± 0.24, p < 1/5000, one-sided bootstrap test. B/Y and C/C* sensory axes were always orthogonal. Change over days: slope = 0.29 ± 0.2, p = 0.077, one-sided bootstrap test. For all panels, p-values: * ≤ 0.05, ** ≤ 0.01, *** ≤ 0.001.
Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

Extended Data Fig. 2 | Classifier Performance over Sequence Timecourse. For each classifier, the accuracy (y-axis) was measured as the area under the curve (AUC; see methods). Accuracy was calculated using data from trials withheld from training (n = 152 trials per animal) and was calculated in a sliding window fashion (25 ms windows, stepped 10 ms). Lines show mean ± s.e.m. of accuracy timecourses (n = 7 animals). Day 1 and 4 shown in left and right panels, respectively. a, A/X sensory classifier performance over time, shown for decoding A/X (orange) and C/C* (blue) stimuli. Orange rectangle indicates A/X training period (10–110 ms). b, C/C* sensory classifier performance over time. Line colors follow panel a. Blue rectangle indicates C/C* training period (360–460 ms). Consistent with predictive coding shown by projections in Fig. 1g-h, on Day 4 the C/C* sensory classifier decoded A/X during the A/X stimulus and immediately before C/C*. c, A/X sensory classifier performance shown for expected trials (black line - ABCD vs. XYC*D) and unexpected trials (grey line - ABC*D vs. XYCD). Consistent with postdiction results shown in Fig. 3b, the A/X sensory classifier performs well on expected trials, but incorrectly classifies A/X during unexpected C/C* trials. d, A/X memory classifier performance over time, shown for A/X discrimination (dark blue) and C/C* (light blue). Dark blue rectangle indicates training period (360–460 ms). Consistent with projection results shown in Fig. 3c-d and Extended Data Figs. 5 and 6, A/X memory classifier can decode A/X near the end, but not beginning of the trial. A/X discrimination of C/C* is close to chance (AUC = 0.5), reflecting the fact that the two axes are independent. e, A/X memory classifier performance, divided by expectation. Colors follow panel c. The A/X memory classifier performs well at discriminating A/X on both expected and unexpected trials.
Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Extended Data Fig. 3 | Associative Learning Generalizes to C/C* Chords Presented Outside of Sequence. a-b, Lines show mean ± s.e.m. of neural activity (trials balanced across conditions) projected onto a C/C* chord encoding axis on (a) Day 1 (n = 4204) and (b) Day 4 (n = 4196). The C/C* chord encoding axis was trained using the firing rate response to the C/C* chord presented in isolation, outside of sequences (n = 300 trials). Line colors indicate trial types (ABCD – orange, ABC*D – pink, XYCD – green, XYC*D – blue) and line style indicates 3rd chord type (C – solid, C* – dashed). Positive and negative projections indicate C* and C encoding, respectively. Light and dark grey horizontal bars mark significant differences for AB vs. XY and C vs. C*, respectively (two-sided t-test, p ≤ 0.001, Bonferroni corrected). Results are consistent with projections onto the C/C* sensory axis (Fig. 1g,h). c, Points show mean ± s.e.m. of C/C* prediction strength during the A/X stimulus, which grew over days. Positive prediction (y-axis) indicates the C/C* chord sensory axis correctly encoded the association (that is, C during A and C* during X) during the A/X stimulus (black outline in panels a-b, 10–110 ms). Day 1 = 0.017 ± 0.023, p = 0.44, Day 2 = 0.025 ± 0.023, p = 0.27, Day 3 = 0.071 ± 0.023, p = 0.0008, Day 4 = 0.14 ± 0.022, p < 1/5000, two-sided bootstrap tests. Trials used in other projection analyses were also used here (n = 1064). For panels c-d, lines and shaded region show mean and 95% CI of bootstrapped linear regressions. Consistent with Fig. 1i, the prediction along the C/C* sensory chord axis increased across days; slope mean ± s.e.m. = 0.04 ± 0.01, p < 1/5000, one-sided bootstrap test. d, Violin plots show bootstrapped distributions of the angle between A/X sensory and C/C* chord sensory axes (n = 5000 resamples of neurons). The mean ± s.e.m. angle between axes by day (degrees): Day 1 = 95 ± 6.5, p = 0.19; Day 2 = 84 ± 5.9, p = 0.16, Day 3 = 78 ± 5.0, p = 0.011, Day 4 = 83 ± 4.4, p = 0.064, one-sided bootstrap tests against 90 degrees. Regression across days: slope = −4.3 ± 2.5, p = 0.039, one-sided bootstrap test. e, Angle between A/X memory and C/C* chord sensory axes. Angle (degrees) on Day 1 = 88 ± 7.0, p = 0.36; Day 2 = 103 ± 6.3, p = 0.019, Day 3 = 95 ± 4.5, p = 0.14, Day 4 = 83 ± 5.2, p = 0.10, one-sided bootstrap tests against 90 degrees. Regression across days: slope = −2.2 ± 2.8, p = 0.21, one-sided bootstrap test. For all panels, p-values: * ≤ 0.05, ** ≤ 0.01, *** ≤ 0.001.
Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

Extended Data Fig. 4 | Alignment of Neural Activity in A/X-C/C* State Space. a, Neural activity projected into A/X-C/C* state space for Day 1 (left) and Day 4 (right). Lines show mean projections of neural activity onto the A/X sensory axis (x-axis) and C/C* sensory axis (y-axis; n = 1064 trials). Activity is shown during the A/X stimulus presentation (−10–170 ms) for each of four trial types, indicated by legend. Marker saturation increases with time, as shown in sequence timecourse legend above graph. Inset shows principal components (PCs) of neural trajectories in grey; black arrow size matches percentage of explained variance per PC (see methods). On day 1, the neural trajectory moved predominately along the A/X encoding axis (x-axis). By day 4, the neural trajectories followed an angle, encoding both A/X and the expected C/C* information (y-axis). b, The angle of PC1 (relative to horizontal) during the A/X period increased across days. Radial lines show the circular mean ± s.e.m. of angle shown for Day 1 (light grey) and Day 4 (dark grey). Angle of PC1 per day (degrees): Day 1 = 18 ± 2.9, Day 2 = 14 ± 3.6, Day 3 = 11 ± 4.7, Day 4 = 31 ± 2.3 degrees (bootstrap, n = 5000 resamples of neurons). Change in angle across days, slope = 3.7 ± 2.4, p = 0.0028, one-sided bootstrap test. c, Neural activity during the C/C* stimulus period (340 to 520 ms) projected into A/X-C/C* state space, as in panel a. d, The angle of PC1 (relative to vertical) during the C/C* period decreased across days. Format follows panel b. Angle of PC1 per day (degrees): Day 1 = 79 ± 3.5, Day 2 = 74 ± 3.8, Day 3 = 77 ± 4.3, Day 4 = 58 ± 2.7 (bootstrap); change in angle across days, slope = −6.0 ± 1.4, p < 1/5000, one-sided bootstrap test. For all panels, p-values: * ≤ 0.05, ** ≤ 0.01, *** ≤ 0.001.
Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Extended Data Fig. 5 | A/X Memory Representation and Full Neural Dimensionality. a,b, The neural population encoding of A/X memory shown on (a) Day 1 and (b) Day 4. For each of the four conditions, the lines show the mean ± s.e.m. of the population projection onto the A/X memory axis (blue outlines A/X memory training period; for all panels, n = 1064 withheld trials, combined across animals per day). Positive and negative projections indicate XY and AB encoding, respectively. Light and dark grey bars mark significant differences for AB vs. XY and C vs. C* respectively (two-sided t-test, p≤0.001, Bonferroni corrected). c-d, Neural activity projected into A/X memory - C/C* state space for (c) Day 1 and (d) Day 4, around the C/C* stimulus presentation (340–520 ms). The x-axis and y-axis are the projections of neural activity onto the A/X memory axis and the C/C* sensory axis, respectively. Marker saturation increases with time (shown across top). Inset shows PCs of neural trajectories in grey; black arrow size matches percentage of explained variance per PC (for distributions see Fig. 3h). e, Violin plots show distribution of the dimensionality of the full neural response during the C/C* stimulus presentation. For each day, PCA was performed on the firing rate responses across a pseudo population (neurons were concatenated across animals; see methods). Similar to Fig. 3h, the dimensionality was estimated using the explained variance ratio (EVR) of the first two PCs (see methods). Dimensionality of the neural responses tended to decrease over days, as shown by the increased in the EVR of first two PCs: Day 1 = 0.63 ± 0.062, Day 2 = 0.54 ± 0.056, Day 3 = 0.68 ± 0.064, Day 4 = 0.76 ± 0.091 (bootstrap, n = 5000 resamples of neurons). Change in EVR of first two PCs over days: slope mean ± s.e.m. = 0.053 ± 0.034, p = 0.065, one-sided bootstrap test.
Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

Extended Data Fig. 6 | A/X Sensory to Memory Transformation. a, Cross-temporal performance of A/X classifiers. A series of A/X classifiers were
trained across the sequence (x-axis; 25 ms windows, stepping by 10 ms) and then each classifier was tested across the sequence (y-axis). Color indicates
the average correct projection on withheld data for all combinations of training times and test times. White bars indicated onset and offset of A/X,
B/Y, C/C* stimuli. Note, the low cross-temporal decoding performance between the A/X and C/C* time periods reflects the temporal dynamics of the
representation of A/X during the sequence. b, Points show mean ± s.e.m. of correct projection along the A/X sensory axis (orange) and A/X memory axis (blue), during the first three stimuli in the sequence (A/X, B/Y, and C/C* columns). Positive values indicate correct encoding strength; negatively
encoded conditions (that is, A) were inverted before averaging. Horizontal bars indicate significant differences between A/X encoding during the A/X
stimulus and C/C* stimulus. The A/X sensory axis had stronger A/X encoding during A/X sensory compared to the C/C* stimulus (differences per
day: Day 1 = 0.31, Day 2 = 0.26, Day 3 = 0.27, Day 4 = 0.32, all p≤1/5000, one-sided permutation tests). The A/X memory axis had stronger encoded A/X encoding during the C/C* stimulus compared to the A/X stimulus (differences per day: Day 1 = −0.19, Day 2 = −0.22, Day 3 = −0.11, Day 4 = −0.17, all p = 0.0002, one-sided permutation tests). (A/X Stimulus) Projections of neural activity during the A/X stimulus (10–110 ms) onto A/X sensory axis (mean ± s.e.m.): Day 1 = 0.37 ± 0.2, Day 2 = 0.27 ± 0.022, Day 3 = 0.28 ± 0.022, Day 4 = 0.33 ± 0.021, all p < 1/5000. Onto A/X memory axis: Day 1 = 0.053 ± 0.023, p = 0.022, Day 2 = 0.06 ± 0.024, p = 0.013, Day 3 = 0.12 ± 0.023, p < 1/5000, Day 4 = 0.053 ± 0.023, p = 0.019 (all two-sided bootstrap tests). During the A/X stimulus, A/X sensory encoding was stronger than A/X memory encoding on all days (Sen. – Mem. differences: Day 1 = 0.31, Day 2 = 0.21, Day 3 = 0.16, Day 4 = 0.27, all p≤1/5000, one-sided permutation tests). (B/Y Stimulus) Projections of neural activity during the B/Y stimulus (180–280 ms) onto the A/X sensory axis: Day 1 = 0.12 ± 0.022, p < 1/5000, Day 2 = 0.0038 ± 0.024, p = 0.87, Day 3 = 0.12 ± 0.023, p < 1/5000, Day 4 = 0.046 ± 0.024, p = 0.046. Onto A/X memory axis: Day 1 = 0.07 ± 0.023, p = 0.0044, Day 2 = 0.22 ± 0.23, p < 1/5000, Day 3 = 0.19 ± 0.23, p < 1/5000, Day 4 = 0.11 ± 0.024, p < 1/5000 (all two-sided bootstrap tests). During B/Y stimulus, A/X sensory encoding was slightly stronger than A/X memory on Day 1 (Sen. – Mem. diff. = 0.05, p = 0.064), but after experience, A/X memory encoding of A/X information was significantly stronger than A/X sensory encoding (Day 2 = −0.21, p = 0.0002, Day 3 = −0.07, p = 0.017, Day 4 diff. = −0.07, p = 0.02, all one-sided permutation tests). (C/C* Stimulus) Projections of neural activity during the C/C* stimulus (360–460 ms) onto A/X sensory axis: Day 1 = 0.053 ± 0.023, p = 0.021, Day 2 = 0.0034 ± 0.023, p = 0.87, Day 3 = 0.008 ± 0.023, p = 0.72, Day 4 = 0.0069 ± 0.023, p = 0.77. Onto A/X memory axis: Day 1 = 0.24 ± 0.023, Day 2 = 0.28 ± 0.023, Day 1 = 0.24 ± 0.024, Day 4 = 0.23 ± 0.024, all p < 1/5000 (all two-sided bootstrap tests). During the C/C* stimulus, the A/X memory encoding was stronger than A/X sensory encoding on all days (Sen – Mem. differences: Day 1 = −0.19, Day 2 = −0.28, Day 3 = −0.23, Day 4 = −0.22, p = 0.0002, all one-sided permutation tests). c, Violin plots show distribution of when A/X memory encoding strength crossed A/X sensory encoding strength. Horizontal line indicates
mean. Mean ± s.e.m. of switch times (ms) relative to sequence onset: Day 1 = 248 ± 13, Day 2 = 182 ± 10, Day 3 = 178 ± 22, Day 4 = 194 ± 22 (n = 5000, bootstrap over trials). The switch time decreased over days (slope mean ± s.e.m. = −16 ± 8.2, p = 0.02, one-sided bootstrap test). The change in switch time decreased the most between days 1 and 3 and then stabilized by day 4 (Day 4-3 diff. = 16.11 ± 31, p = 0.31, one-sided bootstrap test). For all panels, p-values: * ≤ 0.05, ** ≤ 0.01, *** ≤ 0.001.

Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Extended Data Fig. 7 | A/X Sensory and A/X Memory Encoding have Opposite Effects on C/C* Encoding. Trial-by-trial correlation of encoding strength along three relevant axes: A/X sensory, C/C* sensory, and A/X memory. Positive and negative values on each encoding axis indicate correct and incorrect projections, respectively. All lines show mean and 95% confidence interval of bootstrapped linear regressions; slope, correlation (r) and p-values (all one-sided bootstrap tests, uncorrected for multiple comparisons across panels) are listed in plots. a-b, Correlation between A/X sensory encoding strength (x-axis; 10–110 ms) and A/X memory encoding strength (y-axis; 360–460 ms) on (a) Day 1 and (b) Day 4. Consistent with a transformation of A/X information from sensory to memory, there is a significant correlation on Day 1 and 4. c-f, Relationship between A/X encoding strength (x-axis) and C/C* sensory encoding strength (y-axis). A/X encoding strength by the sensory and memory axes was estimated during the 50 ms prior to C/C* onset (300–350 ms). C/C* sensory encoding strength was estimated during C/C* (360–460 ms). Panels show correlations between C/C* representation and A/X sensory representation (c and d) or A/X memory representation (e and f). Correlations are shown for both expected stimuli (c and e; ABCD, XYC*D) and unexpected stimuli (d and f; ABC*D, XYCD). c, On day 4, A/X sensory encoding was positively correlated with C/C* encoding accuracy on expected trials (ABCD, XYC*D). d, On day 4, A/X sensory encoding was negatively correlated with C/C* encoding accuracy on unexpected trials (ABC*D, XYCD). e, On day 4 there was no significant correlation between A/X memory encoding accuracy and C/C* encoding on expected trials. f, On day 4, A/X memory encoding accuracy was positively correlated with C/C* encoding during unexpected trials.
Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

Extended Data Fig. 8 | Dynamics of A/X Selectivity Are Consistent across C/C* Stimuli. Phenograph clustering (Fig. 5a) was applied to z-scored firing
rate differences calculated for specific C/C*/Cmix stimuli. a, Z-scored differences were calculated for XYCD-ABCD (left), XYC*D-ABC*D (middle), and
XYCmixD-ABCmixD (right) pairs of conditions. Lines show mean ± s.e.m. of A/X selectivity over time per original Phenograph cluster (n = 522). Note, Cmix trials involved presenting a novel stimulus that was a mix between the two chords making up C and C*; ABCmixD and XYCmixD sequences occurred
on 12% of trials, randomly distributed throughout the day (see methods). b, Data points show the individual neurons’ original AB-XY z-scored differences
(x-axis) were highly correlated with z-scored differences calculated on the ‘C’ trials (XYCD-ABCD), during sensory (dark blue, left; r = 0.91 ± 0.01) and memory (dark blue, right; r = 0.89 ± 0.02) time periods. Similarly, the correlation was high to ‘C*’ trials (XYCD-ABC*D) during sensory (blue, left; r = 0.92 ± 0.01) and memory (blue, right; r = 0.87 ± 0.02) time periods. Finally, this correlation was also seen on Cmix trials (XYCmixD-ABCmixD) during both sensory (green, left; r = 0.8 ± 0.02) and memory (green, right; r = 0.73 ± 0.02) time periods. All correlations were significant (p < 1/5000, one-sided bootstrapped linear regressions, n = 5000 resamples across neurons).

Nature Neuroscience | www.nature.com/natureneuroscience

NaTurE NEurosCiEnCE

Articles

Extended Data Fig. 9 | Stable and Switching Dynamics Capture the Temporal Dynamics of Single Neurons. a, Sensitivity index (d-prime) calculated between all pairs of the four Phenograph clusters (see methods). Red line shows observed d-prime; histograms show d-prime after permutation (1000 shuffles). All clusters were more separated than expected by chance (all p≤0.001, one-sided permutation tests). b, Plot shows how systematically varying the number of neighbors in the Phenograph algorithm (K; color-axis) changed the goodness of clustering, as measured by the silhouette score (x-axis) and modularity (y-axis, see methods). White text shows the resulting number of identified clusters. A K value between 35 and 45 results in 4 clusters and high silhouette scores and modularity. Increasing the K value beyond this recommended range leads to unstable clustering with highly variable silhouette scores and low modularity. c, Density of UMAP projection of A/X temporal selectivity. Dot colors indicate Phenograph clustering (left) and K-means clustering (right, number of clusters = 4) labels. Area of circle indicates number of data points in region (max size = 8). d, K-means silhouette score as a function of cluster number. K-means was performed on UMAP projections for timecourse of A/X selectivity, random selectivity, and C/C* selectivity. e-g, A/X temporal selectivity profile clustered by K-means applied to UMAP, as shown in panel c. Lines show mean ± s.e.m. of each cluster’s selectivity timecourse, after each K-means run, when the number of clusters set to (e) k = 2, (f) k = 3, and (g) k = 4.
Nature Neuroscience | www.nature.com/natureneuroscience

Articles

NaTurE NEurosCiEnCE

Extended Data Fig. 10 | Properties of Stable and Switching Neurons. a, Intrinsic variability was higher in stable neurons. Lines show mean ± s.e.m. of fano factor of stable (orange, n = 355) and switching (blue, n = 167) neurons over the sequence (neurons combined days). b, Violin plots show distribution of fano factor during pre-stimulus period (−400–0 ms), stimulus presentation (A/X, B/Y, C/C* and D/D* combined, 100 ms each) and inter-chord interval (ICI; 75 ms each). Fano factor was higher in stable neurons compared to switching neurons before the stimulus (stable, mean ± s.e.m. = 1.06 ± 0.01, switching = 1.04 ± 0.01; diff. = −0.02, p = 0.02), during stimulus presentation (stable = 1.03 ± 0.01, switching = 1.01 ± 0.01; diff. = −0.02, p = 0.016), and during the ICI (stable = 1.03 ± 0.01, switching = 1.01 ± 0.01; diff. = −0.02, p = 0.01, all one-sided permutation tests). Difference between the pre-stimulus and stimulus periods were significant for both neuron types (stable = 0.03, p = 0.001; switching = 0.03, p = 0.03; one-sided permutation tests). c, Line show mean ± s.e.m. of intrinsic autocorrelation of functional neuron types, calculated during the pre-stimulus period. The autocorrelation at lag zero was removed for clarity. d, Histograms show distribution of time constants from autocorrelations. The time constant (tau; x-axis) provides a measure of each neuron types’s intrinsic timescale; it was estimated by fitting an exponential function to the autocorrelation shown in panel c. No difference was observed between neuron types: switching mean ± s.e.m. = 94 ± 51 ms, stable = 86 ± 31 ms (bootstrapped exponential fit; n = 1000 resamples with replacement). e, Switching neurons carried slightly more of the A/X-C/C* association than stable neurons. Lines show mean ± s.e.m. of stable (orange) and switching (blue) neurons’ A/X and C/C* temporal selectivity profiles. Neurons without significant C/C* selectivity were removed (stable n = 123; switching, n = 24, data combined across days). Selectivity of neurons is plotted with respect to their initial A/X preference (that is, initial selectivity is always positive). Dashed lines show C/C* selectivity of the same neurons. Responses to associated stimuli (AC/XC*) are positive, while responses to unassociated stimuli (AC*/XC) are negative. f, Violin plots show distribution of average predictive selectivity during C/C* stimulus presentation (350–450 ms). Each dot is a neuron; all days included. The mean ± s.e.m. of prediction in stable neurons = −0.13 ± 0.31, p = 0.67; switching neurons = 1.16 ± 0.53, p = 0.022, two-sided bootstrap tests. g, Data points show estimated locations of neurons in each functional cluster along recording array. Switching (blue), stable (orange), and none (grey) neurons are plotted according to their estimated electrode location (x-axis – AP, y-axis – depth (DV) based on implant coordinates; 6 probes had 4 shanks separated by 200 µm). Small, random jitter in anterior-posterior (AP) direction was added for clarity of presentation and does not reflect actual differences. For all panels, p-values: * ≤ 0.05, ** ≤ 0.01, *** ≤ 0.001.
Nature Neuroscience | www.nature.com/natureneuroscience

nature research | reporting summary

Data
Policy information about availability of data All manuscripts must include a data availability statement. This statement should provide the following information, where applicable:
- Accession codes, unique identifiers, or web links for publicly available datasets - A list of figures that have associated raw data - A description of any restrictions on data availability
The data that support each main figure are included as Source Data. Due to its size, original data is available upon reasonable request.

Field-specific reporting

Please select the one below that is the best fit for your research. If you are not sure, read the appropriate sections before making your selection.

Life sciences

Behavioural & social sciences

Ecological, evolutionary & environmental sciences

For a reference copy of the document with all sections, see nature.com/documents/nr-reporting-summary-flat.pdf

Life sciences study design

All studies must disclose on these points even when the disclosure is negative.

Sample size

No statistical methods were used to pre-determine sample sizes. Our sample sizes were chosen to follow those reported in previous publications examining sequence learning in mice (Gavornick and Bear 2014; Fiser et al. 2016).

Data exclusions Recordings were taken from 10 animals, only 7 had a sufficient number of spikes to be included in further analyses. Otherwise, no data was excluded from subsequent analyses. All neurons isolated during spike sorting were included in analysis.

Replication

Recordings and analyses were replicated across 7 animals. Across all animals, we recorded 522 neurons. Separate classifiers were trained per animal. Classifier performance was significantly above chance for each animal (Supplementary Fig. 1). We used cross-validation (test-train splits) in all of our classifier and projection analyses. When analyzing results about the neurons (e.g., angles between classifiers) we used bootstrap tests (sampling with replacement) to prevent outliers from influencing our results. When comparing the rotational mechanisms, we used multiple statistical tests (permutation against random, a chi-squared test, binomial tests and tests against randomly generated data), which all supported our finding that the observed neural rotation was more structured rotation than random. Finally, we replicated our observed results in a neural network model (Fig. 7, Supplementary Fig. 4).

Randomization

All animals experienced the same unsupervised sequence paradigm and were not assigned to groups. Furthermore, all animals experienced all 'condition' trial types. All trial types occurred randomly during the 1500 trials on a given day, according to their probabilities and ensuring equal numbers of trial types.

Blinding

All animals experienced the same paradigm and therefore were not assigned to ‘groups’ and did not require blinding of experimenters. Experimenter was blind to trials during preprocessing of the data (e.g., filtering, spike sorting, etc).

Reporting for specific materials, systems and methods

We require information from authors about some types of materials, experimental systems and methods used in many studies. Here, indicate whether each material, system or method listed is relevant to your study. If you are not sure if a list item applies to your research, read the appropriate section before selecting a response.

Materials & experimental systems
n/a Involved in the study Antibodies Eukaryotic cell lines Palaeontology and archaeology Animals and other organisms Human research participants Clinical data Dual use research of concern

Methods
n/a Involved in the study ChIP-seq Flow cytometry MRI-based neuroimaging

Animals and other organisms

Policy information about studies involving animals; ARRIVE guidelines recommended for reporting animal research

Laboratory animals

7 adult male PV cre+/- C57BL6 mice used were between 13 and 19 weeks old at the start of recording.

2

April 2020

nature research | reporting summary

Wild animals

No wild animals were used in the study.

Field-collected samples No field collected samples were used in the study.

Ethics oversight

All animal procedures were approved by the Princeton IACUC and carried out in accordance with the standards of the National Institute of Health.

Note that full information on the approval of the study protocol must also be provided in the manuscript.

April 2020

3

