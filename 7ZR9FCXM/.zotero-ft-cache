Psychological Research (2009) 73:559–577 DOI 10.1007/s00426-009-0237-z
ORIGINAL ARTICLE
Thinking as the control of imagination: a conceptual framework for goal-directed systems
Giovanni Pezzulo · Cristiano Castelfranchi

Received: 15 September 2008 / Accepted: 10 February 2009 / Published online: 4 April 2009 © Springer-Verlag 2009

Abstract This paper oVers a conceptual framework which (re)integrates goal-directed control, motivational processes, and executive functions, and suggests a developmental pathway from situated action to higher level cognition. We Wrst illustrate a basic computational (control-theoretic) model of goal-directed action that makes use of internal modeling. We then show that by adding the problem of selection among multiple action alternatives motivation enters the scene, and that the basic mechanisms of executive functions such as inhibition, the monitoring of progresses, and working memory, are required for this system to work. Further, we elaborate on the idea that the oV-line re-enactment of anticipatory mechanisms used for action control gives rise to (embodied) mental simulations, and propose that thinking consists essentially in controlling mental simulations rather than directly controlling behavior and perceptions. We conclude by sketching an evolutionary perspective of this process, proposing that anticipation leveraged cognition, and by highlighting speciWc predictions of our model.
G. Pezzulo Istituto di Linguistica Computazionale “Antonio Zampolli”, CNR, Via Giuseppe Moruzzi, 1, 56124 Pisa, Italy
G. Pezzulo (&) · C. Castelfranchi Istituto di Scienze e Tecnologie della Cognizione, CNR, Via S. Martino della Battaglia, 44, 00185 Rome, Italy e-mail: giovanni.pezzulo@cnr.it C. Castelfranchi e-mail: cristiano.castelfranchi@istc.cnr.it

Keywords Anticipation · Control theory · Goal · Intention · Internal modeling · Simulation
Introduction
Psychology and neuroscience have shown that most behavior in living organisms is goal directed, i.e., behavior is predominantly determined by endogenously generated (and internally represented) goals, rather than by external stimuli. Two characteristics of the goal-directed functional organization are that actions are selected which are expected to produce desired results, or goals, and these actions are guided toward such goals by an interplay of prediction, control and monitoring. Control-theoretic models, which were popular at the origin of cybernetics, recognized clearly that purposive action necessitates goals and the support of quite a complex organization, as also described by Jeannerod (1997):
Goal-directed behavior implies that the action should continue until the goal has been satisWed. The description of the motor representation must account for this property, i.e., it must involve, not only mechanisms for steering and directing the action, but also mechanisms for monitoring and eventually correcting its course, and for checking its completion.
One well-known example of a mechanism able to steer and control goal-directed action is the TOTE model (Miller, Galanter, & Pribram, 1960), in which a desired state (goal) and actual sensory states are compared, and their discrepancy triggers action until the goal is achieved. A related goaldirected functional organization is proposed by Rosenblueth, Wiener, and Bigelow (1943), who argue that the eVects of an action are responsible for its selection. Similarly,

123

560

Psychological Research (2009) 73:559–577

Powers (1973) proposes that the functional organization of living organisms is (hierarchical) feedback control, and that behavior consists in the control of perceptions.1
Historically, these ideas were very important in giving mechanistic ground to slipping psychological concepts such as volition, and purpose in terms of feedback and feedforward control mechanisms. Moreover, control-theoretic models clearly recognize the importance of the mutual relations between perceptual and motor processes (e.g., feedback and circular causality), of internal modeling, and of goals—all ingredients of our recent understanding of actions and cognition. Therefore, it is not surprising that, in the context of theories of grounded cognition, the controltheoretic framework has been revitalized not only in the Weld of (computational) motor control (Ito, 1993; Kawato, 1999; Wolpert & Ghahramani, 2004), but also for understanding cognitive abilities such as goal-directed action, perception, representation, imagery and planning as well as sophisticated social abilities such as mindreading and imitation (Gardenfors, 2007; Grush, 2004; Jeannerod, 2001; Wolpert, Doya, & Kawato, 2003).
Nonetheless, there are some aspects of this theoretical framework that need to be updated in light of novel evidence, or that have simply received less attention. The aim of our paper is to (re)integrate them in a coherent controltheoretic framework.
The ideomotor nature of action
In early control-theoretic models goal representations, or representations of intended action eVects, had mostly regulatory roles: they were reference signals ‘from the future’ (Adams, 1971) whose activity constrained and regulated behavior toward the achievement of the goal. That this view is somewhat reductive is revealed by empirical studies (Jeannerod, 1994, 1997, 2006) showing that the same goal representation underlies action preparation, planning, control, simulation and observation. These are all related processes that share neural circuits and have similar timing (Jeannerod, 2001; Decety & Grèzes, 2006), suggesting that they represent diVerent aspects of the same capability for motor cognition. These studies (among others) highlight that goal representations have perceptual and motor aspects, and are not transduced in an abstract and amodal code, contra purely informational approaches (and others) that segregate sensory, cognitive, and motor processes.
1 As an example, when I decide to go 120 km/h with my car, my task consists of maintaining the speedometer around 120 km/h, and to do so I base my actions on perceptual feedback concerning the bar of the speedometer. In the formulation of Powers (1973), I therefore ‘control’ (in a technical sense) my inputs and not my outputs, and execute some action (e.g. accelerate) with the aim of keeping the speedometer bar (the controlled variable) constant.

Moreover, they show that the same neural structures could underlie sensorimotor, cognitive and social abilities to an previously unsuspected extent (Barsalou, 1999).
Along these lines, converging empirical results have lead to a recent (re)discovery of the essentially ideomotor structure of action (James, 1890), indicating that action is activated and controlled by an anticipatory representation of the desired eVect (HoVmann, Stöcker, & Kunde, 2004; Hommel, Musseler, Aschersleben, & Prinz, 2001). Ideomotor theories like the TEC (Hommel et al., 2001) assume also a common coding of perception and action planning (Prinz, 1997), or that actions are coded in terms of their perceptual eVects, therefore realizing a close coupling between the motor and perceptual domains. Neurophysiological studies of monkeys have also shown that goals are linked to the motor systems, which achieve them via mirror neurons (Rizzolatti & Craighero, 2004).
Several eVects predicted by the ideomotor organization of action are being revealed by empirical studies. For instance, there is an automatic binding of action and eVect codes during learning despite reward of the eVect (Hommel et al., 2001), and speciWc motor programs are prepotentiated in the presence of aVordances (Tucker & Ellis, 2004). In addition, there is ample evidence that priming eVects extend to the social dimension, where speciWc behavioral patterns can be executed automatically, leading for example to social contagion, mimicry and imitation (Bargh & Chartrand, 1999; Gallese, 2001; Wohlschlager, Gattis, & Bekkering, 2003b). Moreover, it has been shown that observing another’s action facilitates its reproduction (Brass, Bekkering, Wohlschlger, & Prinz, 2000; Kilner, Paulignan, & Blakemore, 2003), that we can use our plans to observe others’ actions (Flanagan & Johansson, 2003), and that our motor apparatus is deeply involved in perception of external events that we can reproduce ourselves (Fadiga, Craighero, Buccino, & Rizzolatti, 2002), those of conspeciWcs (Wilson & Knoblich, 2005), and also those that we cannot reproduce (Schubotz, 2007).
The studies of Rizzolatti et al. (1988) have shown that the neural structures supporting ideomotor eVects are part of the brain motor apparatus (and speciWcally of the premotor area of the brain of monkeys and humans). Here, a (hierarchically organized) ‘vocabulary’ of recombinable motor actions has been found, which permits their selection and Xexible recombination once given the idea of an action, facilitates action observation (since the stimulus dimension is directly related to motor patterns), and provides a basis for non exclusively motor purposes, such as motor imagery and social cognition, and for the understanding of the actions, emotions and intentions of other agents (Gallese, Keysers, & Rizzolatti, 2004).
In particular, two classes of neurons with ideomotor properties have been identiWed in monkeys: canonical

123

Psychological Research (2009) 73:559–577

561

neurons (Rizzolatti et al., 1988), activated when the monkey performs certain actions with an object in its visual Weld, suggesting that the animal anticipates potential interactions and prepares its body for them. The second class is mirror neurons (Rizzolatti & Craighero, 2004), activated when the monkey performs certain actions or observes a human or other monkey doing so, with the observed actions correlating with high activity of a given neuron being similar to the executed actions linked to that neuron. Such neural structures also allow the Xexible chaining of multiple actions, thus allowing, too, the recognition and achievement of distal goals (e.g., grasping for eating, grasping for placing; see Fogassi et al., 2005). These studies along with many others (e.g., Martin, Wiggs, Ungerleider, & Haxby, 1996 on activation of premotor areas when seeing objects and tools) also suggest that motor processes contribute to understand the meaning of observed objects in terms of their potential uses.
The interface with theories of motivation and executive functions
The endogenous formation and the selection of goals are considered motivational processes separate from motor control, and have received little attention in control-theoretic models. (This could be due to the origin of controltheoretic ideas in engineering, where goals are supplied from outside, or by the fact that in most psychological experiments goals are predetermined by the experimenter.) On the contrary, living organisms are able to self-generate goals for satisfying their basic motivations (e.g., from ‘thirst’ to ‘open the refrigerator’), and face the problem of selecting among multiple goals under diVerent environmental and internal (motivational and cognitive) contexts. Moreover, there is neural evidence of a co-speciWcation of planning and selection of alternative actions (Cisek & Kalaska, 2005), indicating that the separation of motivational and control processes is blurry (see also Damasio, 1994.
If we consider the (intertwined) processes of goal formation and selection, it becomes clear that goals have roles in addition to control (Bratman, 1987; Miceli & Castelfranchi, 2002). First, they have a motivational (‘wanting’) side: they are active because the organism has to satisfy a certain basic motivation (e.g., a drive), and wants to do so. Goals also have an evaluative role and permit the evaluation of states of the world (also independent of any action taken). Finally, they have a prescriptive role that biases the selection of certain future behavior and favors intertemporal self-coordination for the achievement of distal objectives.
This last aspect leads us to another part of the framework that is poorly investigated: its interface with executive functions, which we deWne here as the set of self-directed actions that are functional to future-directed behaviors and

intertemporal choices (Barkley, 2001; Fuster, 1997). For instance, in order to maintain commitment for all the time necessary to achieve distal intentions, it could be the case that a high level of motivation is not suYcient, and additional mechanisms of active self-regulation and inhibition of alternative goals could be required. In the cognitive science literature, the ‘mind as computer’ metaphor has been used to describe executive functions and higher level cognition. On the contrary, in our perspective executive functions are just more sophisticated forms of control that arise in continuity with basic sensorimotor actions and for this reason they preserve vestigial motor aspects that can be revealed through empirical studies (Diamond, 2000).
SpeciWcally, while early cybernetics was more concerned with the maintenance of equilibrium or homeostasis based on external feedback loops, we will argue that the control-theoretic framework can be extended to account for internal, mental operations, including the self-generation of goals and plans. In other words, mental operations can be considered a form of covert action, and, oV-line, utilize the same mechanisms as overt action: they are mental simulations of action (Barsalou, 1999; Cotterill, 2001; Grush, 2004; Hesslow, 2002). Indeed, the idea that mental simulation is a unifying phenomenon explaining multiple capabilities (including planning, perception, mindreading, and imitation) is being investigated through theoretical (Gallese et al., 2004; Jeannerod, 2001; Wolpert et al., 2003), empirical (Decety & Grèzes, 2006; Wilson & Knoblich, 2005) and computational studies (Demiris & Khadhouri, 2005; Haruno, Wolpert, & Kawato, 2003; Oztop, Wolpert, & Kawato, 2005; Pezzulo, 2008b; Wolpert & Kawato, 1998).
The term ‘simulation’ is used ambiguously in the literature, in several contexts. Here we endorse the view that simulations consist in oV-line reenactments of internal models that create an ‘inner loop’, as sketched in Fig. 2, and that can generate predictions of arbitrarily distal events. For this reason, simulations have similar characteristics and utilize the same neural machinery as overt action. Note that because internal models can be arranged hierarchically and generate predictions at diVerent levels of abstraction (see below), by re-enacting internal models at diVerent levels of abstraction it is possible to produce diVerent kinds of simulations, e.g. simulations of all the steps leading to a goal (process simulations) or simulations that only activate the goal (outcome simulations). Empirical studies reveal that only the former type facilitates planning, and both enhance motivation and self-eYcacy (Pham & Taylor, 1999).
The aforementioned simulative processes can be modeled by adding two elements to the basic control-theoretic framework: self-generated, internal feedback loops that permit one to predict the consequences of potential actions, or of observed events, for one or more steps (see Fig. 2), and an inhibition mechanism that permits the suppression

123

562

Psychological Research (2009) 73:559–577

of ongoing motor commands, and the ‘switching’ of external feedback (and perceptions) and internal feedback (and imaginations). Another step toward a truly autonomous mental life is learning to control self-generated, internal events instead of controlling external events only by direct means (or, better, to correlate control of internal events with control of external events). For example, a mechanic who needs to remove the damaged part of an engine can mentally dismantle the engine before doing it in practice, with the aim of understanding which parts have to be removed before eventually removing the damaged one— with the advantage that mental operations are less costly and risky. Analogous to Analogous to Powers (1973) argument that behavior consists in the control of perception, we argue that thinking consists in the control of imagination, or the capability to control mental simulations to set up interactive subgoals and plans that achieve intentions beyond the here-and-now of perception, and to maintain them despite novel distracting opportunities—all of which depends on internal motivations. This view is in accordance with Piaget (1954), who argued that mental operations have their origin in internalized action: they are covert actions that utilize (oV-line) at least part of the same neural machinery of their overt counterparts; see also (Glenberg, 1997).
Intentions, goal representations, and internal models
To understand goal-directed action it is important to distinguish between multiple levels of causes. Take, for example, the act of drinking a glass of wine. If one asks the ‘why’ of this action, one can think of a chain of causes, which range from the less esoteric ‘to drink’, and ‘to enjoy a good wine’, to the ultimate reasons ‘to satisfy my thirst’, ‘to equilibrate my need of sucrose’, ‘to survive’, or even to distal reasons such as ‘to get drunk’, ‘to forget something’, or ‘to enjoy this party’. What is the ‘right’ level for pinpointing intentions? This question can be better answered by focusing on the ‘how’ of this action instead of its ‘why’, and by illustrating the machinery behind intentional action.
Closed-loop controllers are well suited to model the basic regulatory system of an organism, which plausibly work to maintain internal physiological variables in an acceptable range (homeostasis) when supported by an adequate learning mechanism permitting the acquisition of likes and dislikes (e.g., for food). At this level, in controltheoretic terms it is plausible to say that this is a goal of the homeostatic machinery, since the level of variables is explicitly represented and monitored, although this is a ‘non-cognitive’ sense of goal. Moreover, we can say, nonmetaphorically, that a discrepancy between the goal state and the sensed state of one or more variables triggers a chain of (learned) actions leading in order to minimize the

discrepancy (say, drinking). If we go even further, we can say that such homeostatic machinery is ultimately devoted to increasing the organism’s Wtness and its chance of survival (or the survival of its genes). However, as far as we know there is neither specialized closed-loop survival-monitoring mechanism, nor the survival-related variables are represented or monitored. At most we can say that survival is a function, not a goal of the organism—and the ‘thirst’ drive is functionally related to survival, in the sense that satisfaction of the former (often) guarantees satisfaction of the latter.
Functions and intentions should not be confused, however (consider the example of sex, Castelfranchi, 2000), and purposes of actions cannot be reduced to the rewards they carry on or their hedonic value, even if those rewards are predicted and are used to learn actions (Schultz, 1998). In this framework we deWne intention as the (mental) process of steering and controlling actions until the intended goal is achieved; note that this implies a transformation of abstract goal states into concrete actions to take.2 One of the advantages of adopting a computational perspective is that we can replace the question: what is the intention of this action? with the operational question: what variables are controlled? In particular, the same action (drinking wine) can lead to diVerent behavioral patterns depending on its underlying intention (‘getting drunk’ or ‘enjoying a good wine’); intentions, in turn, are realized by controlling diVerent variables (say, those signaling my state of inebriation vs. the level of liquid in the glass) and by setting up diVerent termination conditions.
Based on background knowledge (that can be a set of beliefs or perceptions) and internal motivations an intention is selected (say, enjoying wine or being happy) and this has several eVects. The Wrst consequence is the triggering and control of actual action (and perception), which is typically done by setting up a goal to be used by the comparator. Pacherie (2008) (among others) has argued convincingly that it is worth distinguishing distal, proximal and motor intentions, so that distal and proximal intentions are realized in a cascade of processes, Wnally leading to action execution; (see also Jacob & Jeannerod, 2005). In other words, the goal of drinking this cup of wine can be selected as a speciWcation of the intention to be happy, the former (drinking) being the proximal cause of action, and the latter (happiness) its distal one, which together activate a grasping action. The second eVect of selection is intertemporal, since those intentions that do not last immediately bias the selection of successive actions and intentions: any successive
2 True intention is not (always) transparent and accessible to introspection: it is a complex self-attribution and self-monitoring process that can dramatically fail, as revealed by studies of delusions of control in schizophrenia (Frith, Blakemore, & Wolpert, 2000; Pacherie, 2008).

123

Psychological Research (2009) 73:559–577

563

intention has to negotiate with those already active, and their constraints. The third eVect of selection is related to the executive processes of maintenance in memory, monitoring and self-regulation, as well as to the ‘protection’ of the intention against potentially distracting opportunities, which includes inhibition of alternatives.
In the next section, we provide a control-theoretic model of these processes. Before doing so, however, here we brieXy describe the main computational challenges posed by intentional action, and illustrate our view on how goals and intentions can be described in a control-theoretic framework.
Taking intentional action: computational challenges
Almost by deWnition, any intentional action has to be preceded by a representation of its desired eVect (James, 1890). However, not all eVects of actions are intended, and not all are predicted. These are separated dimensions: both intended and unintended eVects can be predicted (and their costs can be evaluated before taking action). For the aims of our paper, we will assume that intended eVects are both predicted and controlled. Achieving proximal and distal eVects is however a diYcult computational challenge, since intentions and actions have composite structure.
Internal and external eVects
Although some goals such as ‘getting drunk’ are probably judged based on internal variables, most are expressed in terms of eVects and events in the external environment, not their internal correlates, although internal correlates can be used to control an action (and achieving internal eVects is often the function, not the goal, of actions). Consider the case of turning on the light, illustrated in Fig. 1. Event B is ‘having the light turned on’, and event A is ‘feeling a certain sensation in the Wnger when I press the light switch’. Clearly the action goal is B (an external event), and the action of pressing the light switch can be monitored at two

levels: A is monitored for its internal eVects (the feelings resulting from clicking the light switch), and B is monitored for its external eVects (vision of the light). Moreover, in this case part of the action’s success depends on (and is delegated to) the external environment. For example, when I press the light switch, part of the control is delegated to the electrical circuit, upon which I then rely (this does not mean however that I have to understand the causal mechanism). So, one task that any acting organism has to solve is learning the functional relations between A and B, so that it can intentionally achieve B by doing A. This also involves coupling prediction with the monitoring of internal and external eVects, which could rely on diVerent control strategies. Studies by Wohlschlager, Engbert, and Haggard (2003) reveal that actions aiming to achieve external goals are guided by feedback (and predictions) in exteroceptive modalities, while actions aiming to achieve internal goals are mainly guided by proprioception. Evolutionarily speaking, the passage from (the control of) internal to external action eVects is of paramount importance for cognitive development, since the latter is the basis for goal-directed action, which often consist in controlling and modifying external variables, and at the same time it provides a sophisticated understanding of the external environment in terms of objects and events and not only action contingencies.
Proximal and distal eVects
This basic scheme can be extended to distal (external) eVects. For example, I can turn on the light (event B) with the intention of making someone happy (event C). Here the transition from B to C can be direct (taking more or less time), or can depend on some other action I should take in the future, or on someone else’s actions. Distal intentions pose additional challenges: distal goal representations are often detached from the here-and-now of current perception (Pezzulo, 2008a; Pezzulo & Castelfranchi, 2007) and have to be mentally represented. Also,

Fig. 1 A sample action: turning on the light (see main text for explanation). Action execution: by doing A I achieve B (and sometimes C). If I learn this relation, I can do A with the purpose to do B (or C). Action observation: I can infer B or C by observing the movements

leading to A since B and C predict A, and A predicts the movements given a suitable context. Note that this diagram omits feedback loops, which are shown in Fig. 2

123

564

Psychological Research (2009) 73:559–577

most distal eVects can only be realized by compound actions, which require coordination of one’s own actions in the present and the future.3 Empirical studies reveal that this can be done early in the distal intention preparation, and that distal intentions shape how proximal actions are realized (Jeannerod, 1997). For example, when grasping a bottle, the posture of the arm (i.e. part of its proximal realization) is diVerent depending on whether the long-term intention of shelving it or serving wine; this indicates that distal intentions set up constraints for proximal actions (this does not mean, however, that all details should be pre-planned, see below). In addition, distal intentions require extra mechanisms to support self-regulation over long periods of time; these are the hallmark of executive functions, such as the ability to ‘shield’ these intentions from distracting opportunities, and dedicated memory mechanisms. The passage from proximal to distal action is therefore a major evolutionary step, requiring a sophisticated form of control.
Goal representations and their content
What kind of (goal) representations support goal-directed action? One central claim of several psychological theories (Hommel et al., 2001; Jordan, 2003) is that goals are coded in terms of their external (perceptual) action eVects (more precisely, they are distributed feature codes of external action eVects). This naturally suggests that plans are procedures for specifying ordered sequences of representations of external action eVects. In agreement with this view, we assume here that goals are typically coded as external events (although exceptions exist, as in the case of the goal ‘getting drunk’). For computational reasons that we will shortly illustrate, these have to be particular kinds of events: those that one can reliably perceive, produce (behaviorally), and predict, since this guarantees that it is possible to close the loop from goal representations to goal achievement (along these lines, Kurby and Zacks (2008) suggest that perceptual events are segmented as a byproduct of perceptual anticipation mechanisms).
Abstraction and hierarchies of goals
Note that the content of (goal) events can include more than the immediate sensory and perceptual input. It is suggested in the psychological literature that this is achieved by merging active processes with memorized ‘schemata’ that include features of similar events (Zacks, Speer, Swallow,
3 Note that the distinctions internal/external and proximal/distal are orthogonal. For instance, I can achieve the distal intention of getting drunk (an internal eVect). In our example, however, the distal eVect is external.

Braver, & Reynolds, 2007). Similarly, it has been proposed that event sequences playing the role of subgoals in frequently used actions can be assembled into ‘templates’ (Fiebach & Schubotz, 2006), and can be retrieved from memory during the execution of similar action sequences to help set up appropriate subgoals. These studies suggest that in some cases (sub)goal events can be retrieved from memory rather than created de novo.
In addition, goal representations often include conceptual and non-perceptual elements. In other words, not only can goals be distal, but also they can have degrees of abstractness, too. Indeed, the term goal has been ambiguously used in the literature to explain diVerent phenomena, and so can also imply diVerent coding: (1) guiding and regulating actual action, and (2) conceiving possible outcomes in more abstract terms and outside any actual immediate action. Empirical research, indeed, reveals diVerent encodings of goals, for example eVector-dependent and eVector-independent (Arbib, Bonaiuto, Jacobs, & Frey, 2009; Gallese & Metzinger, 2003; Iacoboni et al., 2005; Umiltà et al., 2008), and suggests that the motor system could contain a speciWcation of means-end relations at diVerent levels of abstraction. Evidence on motor equivalence (Stelmach & Diggles, 1982) also indicates that goals can be action-independent, as well, and that the same goal representation could underlie multiple realizations involving diVerent eVectors and patterns of action.4 Therefore, it is worth distinguishing between action goals, which are end states of a certain action (e.g., picking up this glass of wine), and situational goals, which can be more abstract (e.g., getting drunk). Indeed, most theories assume a neural hierarchy of goals (Botvinick, 2008; Fuster, 1997; Hamilton & Grafton, 2007). Regardless, any goal, concrete or abstract, has to unfold into action codes that specify the organism’s behavior. How is this possible?
From intention to action: an internal modeling perspective
Central to recent theories of animal (Balleine & Dickinson, 1998) and human learning (HoVmann et al., 2004; Hommel et al., 2001) is the idea that goal-directed action is served by ideomotor codes (ACTION ! EFFECT), which associate actions and predictions of their (perceptual) eVects, instead of stimulus-response and stimulus-reward associations.
4 Not only do abstract goals allow multiple realizations; in parallel, the same action can (be selected to) realize multiple goals at multiple levels of abstraction. Consider how many descriptions we can give of the same motor action of moving our hands quickly toward one another: clapping hands, expressing enthusiasm, show celebration, contribute to the election of a new President, contribute to peace-keeping, etc. As already mentioned, the same representational structure holds for observed goals, as well; see Fig. 1.

123

Psychological Research (2009) 73:559–577

565

One important aspect of ideomotor codes is that they can be used bidirectionally: in the EFFECT ! ACTION direction to steer goal-directed action, and in the ACTION ! EFFECT direction to predict an action’s eVects. The main advantage of a goal-directed encoding of actions is an increased autonomy from stimuli and current aVordances in the environment, since actions can be triggered proactively (because of their desired eVects) and not only reactively. Moreover, choosing a goal implies proactively deciding which aspects of the environment (e.g., which stimuli) are relevant, and which are not; for this reason, stimuli that signal appropriate contextual conditions for realizing an action can be actively searched for or produced, not just passively experienced. Another important aspect is that, unlike inXexible associations between stimuli, patterns of response and rewards (without goals), explicit outcomes can be Xexibly associated to diVerent utilities under diVerent (motivational) contexts, therefore providing a basis for goaldirected action selection (Niv, Joel, & Dayan, 2006).
The idea of coupling between action execution and anticipation of its eVects is also central to recent theories of internal modeling (Grush, 2004; Kawato, 1999; Ito, 1993; Miall & Wolpert, 1996; Oztop et al., 2006; Wolpert & Ghahramani, 2004), which we adopt here in continuity with the ideas of early control-theoretic models (Craik, 1943); note, however, that one recent advance in our understanding of internal models is that they are grounded in the motor apparatus. According to Kawato (1999, p. 718):
Internal models are neural mechanisms that can mimic the input/output characteristics, or their inverses, of the motor apparatus.
Internal models are crucial not only for action execution, but also for perception (Arbib, 1981; Gregory, 1969). The two main classes of internal models are inverse models (or controllers), which based on actual and desired states generate (sequences of) motor commands to achieve the latter, and forward models, which, based on eVerence copies of motor commands predict the (sensory) consequences of actions. Of particular interest is the idea of forward modeling, which produces anticipations and oV-line simulations. Forward models are believed to play many roles: compensating delays, Wltering sensory input, training inverse models (Jordan & Rumelhart, 1992), sensory cancellation (von Helmholtz, 1867), sensory substitution (using predicted feedback instead of real feedback), state and context estimation (Desmurget & Grafton, 2000). Moreover, prediction of the sensory consequences of our own actions permits one to distinguish reaVerence (i.e. stimulation resulting from movements of one’s own body) from exaVerence (i.e. stimulation resulting from external factors) (von Holst & Mittelstaedt, 1950), and so externally produced events and self-produced ones (Blakemore,

Goodbody, & Wolpert, 1998; Synofzik, Thier, & Lindner, 2006). Other kinds of internal models have been postulated that permit the prediction of external events (Mehta & Schaal, 2002; Schubotz, 2007).
Hierarchical internal modeling
One central claim of control-theoretic models is that higher level goals are carried out via low-level goals and motor actions; this implies the existence of hierarchies of control loops (Powers, 1973) having (almost) the same structure but diVerent representations. This unfolding process is problematic, however, for at least three reasons. First, there is the well-known problem of redundancy: each goal allows for multiple realizations, for example with diVerent sequences of actions, diVerent eVectors, or diVerent movements. This problem is even more dramatic in the case of abstract goals. To be implemented in motor actions, any abstract goal must be speciWed in a way that supports situated control in the lower level(s). Almost by deWnition, abstract goals cannot be directly matched with perception, but regardless should lead to the selection of (sub)goals and actions that can be executed and monitored. Consider how abstract goals such as ‘remain thin’, or culturally-imposed goals such as ‘be polite’ can determine the selection of ‘decline oVer’ over ‘eat this piece of chocolate’. This process can be explained better in terms of a cascade of constraints from higher level to lower level goals (which apply at diVerent timescales) than in terms of a speciWcation of increasingly more concrete end state representations to control action, in the sense that higher level goals do not fully specify but constrain what lower level goals should be selected (Jordan, 2003; Rosenbaum, Meulenbroek, & Vaughan, 2001b). Second, not only are there multiple ways to realize a goal, but also multiple ways to control it and to check its completion. Consider the case of ‘having a cup full of tea’. Typically we check the completion with visual information: mentally comparing the desired level of liquid with the perceived level. In some cases, we can check the characteristic noise of liquid in a cup. Blind people can use another method, that is putting a Wnger in the cup to check if it becomes wet. Still another method, used with automatic tea machines, involves waiting until a red light Xashes, signaling that the preparation of the tea is completed. Computational studies suggest that control strategies can use the best error-signaling frame of reference (Bullock and Grossberg, 1988). Third, most higher level goals can only be achieved by chaining and coordinating multiple actions.
How to solve these problems remains largely an open issue (see Arbib et al., 2009 for a detailed discussion of this issue). The most recent computational models include hierarchies of internal models operating in parallel at multiple layers, and inXuencing each other in top-down and bottom-

123

566

Psychological Research (2009) 73:559–577

up ways (see Demiris & Khadhouri, 2005; Haruno et al., 2003 for hierarchies realized with a modular architectural scheme, and (Nishimoto & Tani, 2009) for a distributed architectural scheme). Internal models at the higher levels could encode generalized motor programs (Schmidt, 1975), which are able to control classes of actions rather than speciWc movements, and internal models at the lowest levels could be responsible instead for the Wne grained details of action. This control scheme requires also diVerent kinds of predictions at diVerent levels of the hierarchy5, for example sensory feedback (internal eVects), the consequences of entire actions in terms of what events they bring about (external eVects), what other actions are available as a consequence of a given action (as an example of the latter case, one can predict that after ‘grasping a glass’ the actions ‘drink’, ‘throw’, and ‘wash’ will be available), and possibly increasingly abstract expectations relative to distal, nonperceptual events or objects6.
Hierarchical control gives one the capability to adaptively recombine or substitute its primitive motor actions with alternatives (subgoals and actions), in order to achieve its current goals under an extremely wide set of contexts, including those never before encountered (Konidaris & Barto, 2007). For example, when one has limited space in which to wash the dishes, one must select which dish to wash when, so that the others do not break, and where to pile clean dishes so that they do not get dirty again. Moreover, depending on free space, there are diVerent strategies available such as soaping and rinsing out each dish individually, or piling several soaped dishes Wrst, then rinsing all dishes together. In this example, the basic skills of grasping, washing and piling are continuously rearranged into sequences that achieve subgoals, and new subgoals are generated when one must successfully complete some actions before others can be executed.
In addition, including layers in the model allows one to formulate increasingly abstract expectations and goals, such as ‘piling all dishes’, the satisfaction of which depends on multiple actions whose sequence is not known in advance, or distal goals, such as ‘invite friends’, which trigger concrete goals such as ‘clean house’. When expectations and goals are represented more abstractly, planning is also more Xexible, since one can simply specify sequences
5 See the discussion in Friston (2005) of a related architectural scheme, described in Bayesian terms, in which modules operating at each level introduce constraints for higher level and lower level modules that can be described as priors and prediction errors, respectively, in Bayesian terms. This leads to generative models, whose organizing principle is the reduction of prediction error at all levels. 6 See Gardenfors (2004) for a discussion of how internal loops can generate hidden variables that explain causal mechanisms, and, for instance, help us perceive the forces behind events.

of actions (e.g., where the Wrst action serves to produce a certain aVordance, and the second to exploit it) and Wll in the details of their realization later on (e.g., what eVector will be used). Human planning is exemplary for such detachment, since we can (with certain limits) plan means and ends at a quite abstract level, although evidence that these mental operations are hardly fully detached from sensorimotor action continues to accumulate (Barsalou, 2008).
Purposive behavior: a control-theoretic view
In this section, we introduce (in three stages) a controltheoretic model with increasingly complex capabilities. The Wrst step is a closed-loop controller, which is fed a goal state. We further discuss how the inclusion of internal modeling permits the parallel extraction of many aVordances available in the environment by running mental simulations of possible actions. This leads us to the second stage, in which a selection process (involving motivational and cognitive aspects) operates on the multiple aVordances and feds the selected goal. This architecture is therefore able to self-determine its goals. Moreover, for this architecture to work, the presence of an extra mechanism is required, one for the inhibition of the preponderant responses automatically triggered by aVordances and of selection of external versus internally generated (simulated) stimuli; this provides a natural explanation of executive processes in the control-theoretic framework. As a third stage, when a comparison is done not between sensed and desired states, but between internally simulated and desired states, the architecture acquires control over its own imagination: this makes it able to interactively set its goals and plans, and ultimately to think by mentally simulating actions.
Stage 1: feedback control and the control of perception
Figure 2 illustrates a control-theoretic loop for perceptual control (Powers, 1973) composed of a selector unit (equivalent to a TOTE unit) above, and an execution unit (composed of multiple paired inverse and forward models) below, inside the dotted square. We will refer to this latter part as a motor schema (Arbib, 1981), where a repertoire of motor schemas (for diVerent basic actions) can be considered as a functional view of the vocabulary of motor actions in Rizzolatti et al. (1988). Although this is not shown in the Wgure, as described before the schema repertoire can be hierarchically organized and realize nested loops of control. This functional architecture is suYcient for basic goaldirected action, including simple aspects of motor control and the direction of attention.

123

Psychological Research (2009) 73:559–577

567

Fig. 2 Simple control-theoretic loop, with the equivalent of a TOTE unit on the top and (multiple) schema(s), composed of inverse and forward models, inside the dotted square

Motor control
The cycle of execution for motor control is simple. The comparator compares the desired and estimated7 states/ inputs and sends an error signal to the controller (inverse model), which computes motor commands to Wll the gap between current and goal states. In this process feedforward and feedback processes are integrated, and the more accurate the feedforward (i.e., the better the inverse models), the less time spent in feedback corrections. The part in bold is the ‘internal loop’, involving the inverse and forward models; this loops parallels the external feedback loop and supports states and inputs estimation and fast corrective command (Desmurget & Grafton, 2000) via feedback prediction (the part inside the ‘internal loop’). The ‘inner feedback loop’ is especially important in our model, since, in accordance with Grush (2004), we argue that it is representational, in the sense that it allows mental operations that refer to the external reality (but can include non-perceptual variables, too; see Grush, 2004 on articulated emulators). In other words, internal models give rise to ‘manipulable world models’ that can be used to do mental operations, for e.g., trying out diVerent solutions to a given problem, instead than operating directly in the external reality. This is done by re-enacting inner loops oV-line, and therefore
7 In this control scheme there is nothing like ‘pure perception’, but imagination is part of the perceptual process. This is due to the fact that the Wlter component fuses external feedback and internal predictions to obtain an estimated state (which can be perceptual or non perceptual). This operation is important for central cancellation and Wltering and for providing stable perception in face of changing environment and moving agent. It is worth noting, however, that this slightly modiWes the idea of ‘control of perception’, since one can use predicted inputs instead of actual inputs (if I drive with my eyes closed, I can only imagine the speedometer bar, and I control imagined, self-generated variables and not perceptions).

generating mental simulations, or representations of possible actions and their outcomes that are detached from the here-and-now of perception (Pezzulo & Castelfranchi, 2007). The part in gray above the internal loop is characteristic of the MOSAIC model (Wolpert & Kawato, 1998), which is composed of multiple paired forward and inverse models. Essentially, the command of each inverse model is gated, depending on the accuracy of predictions of its paired forward model.
Note that, although most control-theoretic models presuppose a trajectory planner module operating before the inverse model, this aspect is left unspeciWed here (it can be considered part of the inverse model). Indeed, in this architecture it is not required that a full-Xedged plan (i.e., the full speciWcation of a trajectory) is computed. Empirical and theoretical studies indicate that plans could be encoded as ‘diVerence vectors’ between the desired and controlled states of an object (in an eVector-independent frame of reference), and then the trajectory can unfold on-line, thanks to the joint work of forward and inverse models, which realize a set of nested feedback loops, with forward models playing the role of compensatory mechanisms (Cisek, 2005; Bullock and Grossberg, 1988). Note also that it is not strictly necessary that the reference signal be the target of an action (e.g., the end position of an eVector). What is important is that a calculation of the discrepancy between desired and estimated states is possible, so they should be coded in a comparable (not necessarily perceptual) format.
Behavior routinization
This basic control scheme does not prevent habits or other routinized actions from ‘skipping’ one or more phases. One hypothesis we put forward is that when the responsibility predictor (Wolpert & Kawato, 1998) provides high a priori

123

568

Psychological Research (2009) 73:559–577

conWdence values for an action, i.e. when it is reliably and skillfully executed by experts, most checks and controls can be safely skipped. Routinization consists in the eVective delegation of (part of) action control to the external environment and its stimuli, so that its eVective functioning resembles a stimulus-response reXex, which is much less demanding than attentional control and in some cases can operate without ‘fresh’ sensory input, thanks to sensory substitution. Hommel (2000) has coined the term prepared reXex for such processes, which is particularly appropriate since it highlights both the process’s intentional origin and its routinary execution. Essentially, a prepared reXex is a strategy for eVective delegation of (stimulus-based) control to the external information, which can also include additional mechanisms such as cue sensibilization and the orienting of selective attention. In addition, we argue that monitoring processes (in the comparator) remain active that permit the restoration of attentional control when needed (i.e., when errors are too big).
Control of perception and attention
A fundamental part of planning is the control of perception and attention, which in our account is achieved by sets of perceptual schemas that have a similar structure as motor schemas (Arbib, 1981). Contrary to the traditional view that the visual system generates a general-purpose representation of the external environment prior to cognitive processing, recent studies indicate that it actively picks up information relevant to the task at hand (Berthoz, 2000; Gibson, 1979; Land, 2006). Interestingly, this can be done in coordination with the control of action and without a dedicated control mechanism. According to the premotor theory of attention (Rizzolatti et al., 1994), the preparation of goal-directed action and shifts of attention share common neural (sensorimotor) structures—in terms of our model, perceptual and motor schemas. When goal-directed actions are prepared, the common neural structures are activated which automatically produces attentional shifts. A second, coordinated attentional strategy consists in the priming of stimuli dimensions related to the action plan (Craighero, Fadiga, Rizzolatti, & Ulmita, 1999; Fagioli, Hommel, & Schubotz, 2007) and the suppression of alternatives (see below).

toward desired goals; this is the main role of the comparator. (We will see later on that executive control has a complementary directing role which consists in the inhibition of the preponderant automatic responses.)
In terms of our model, schemas are always active in the generation of motor commands and predictions. This permits them to ‘respond’ automatically to aVordances of the external environment (including social aVordances) (Gibson, 1979); this means that certain action patterns or imitation behaviors are triggered automatically that lead either to overt or covert (simulated and non executed) action, which in turn provides a ‘motor understanding’ of objects, events, and others (Gallese et al., 2004). As illustrated in Fig. 3, we argue that aVordances are revealed by internal simulations of patterns of potential actions (see also Moller & Schenck, 2008), and not by direct perception (Gibson, 1979), the diVerence being that the former is a full-Xedged representational mechanism. Moreover, there is in parallel an evaluation of potential actions based on the internal (motivational and cognitive) context, by which means the characteristic stimuli of the object acquire incentive salience (Berridge, 2004). This makes (only) some aVordances available and biases their selection.
Note that this model of functioning is not strictly limited to visible aVordances. First of all, hierarchical forward modeling permits the integration, in the same simulation, of currently perceived events, anticipated events, and action alternatives. Indeed, research on action precuing (Rosenbaum, 1991) reveals that humans preprogram aspects of actions that are prespeciWed by external cues, suggesting that planning via mental simulations could be quite sophisticated. Secondly, as suggested by Glenberg (1997), simulations can be meshed with memories (episodic and semantic), providing extra Xexibility and reference to similar experiences. For example, goals can be triggered by context (e.g., ‘going to cinema’ triggers ‘buy pop corn’ even if pop corns are not visible) or by observation of others. Finally, it is worth noting that the motivational system can further inXuence these ongoing simulations (e.g., sad

Ideomotor aspects, aVordances and mirroring

DiVerently from traditional control-theoretic models, and in accordance with the previously mentioned studies on the automaticity of action, we assume that action schemas can be automatically activated by objects and events (including social ones). The control-theoretic part controls this basic ‘automatic’ behavior and directs the activity of schemas

Fig. 3 AVordances are revealed by internal simulation

123

Psychological Research (2009) 73:559–577

569

Fig. 4 Adding the problem of selection of aVordances. Note that the part indicated as schema repertoire is the one inside the dotted square in Fig. 2 and can be hierarchically organized

simulators vs. happy simulators) or can be inXuenced by them (e.g., simulating eating could activate the internal drive of hunger).
Mirroring
If we also assume that the same automaticity of action execution is shared by action imitation, the same model can be used to explain mirroring, and the automatic understanding of others’ actions and intentions in terms of one’s own actions (this happens also when action imitation is inhibited and not executed, since ‘covert’ imitative actions activate schemas, too). Here the control scheme consists in the ‘inversion’ of the internal loop (in bold) in Fig. 2, so that internal models are used to simulate others’ actions and intentions. Inverse models compete for producing motor commands (which are inhibited and not executed) whose sensory eVects resemble more those observed in a demonstrator, and the more successful inverse model is considered to be the one that embeds the demonstrator’s action, from which its intention can be inferred, too (Hurley, 2008; Miall, 2003; Wolpert et al., 2003). Successively, in order to imitate observed actions, it is suYcient to dis-inhibit motor commands of the ‘winning’ inverse model.
Stage 2: goals speciWcation and selection
By considering jointly Figs. 2 and 3, we have a mechanism for planning and evaluating potential patterns of actions speciWed by current aVordances, and a mechanism for controlling action toward a speciWed goal. Figure 4 illustrates the synthesis of the two mechanisms, augmented with a mechanism for selecting one of the available aVordances based on their value and achievability. The result is a system which is able to self-assign its goals, and fulWll them; the key idea is that predicted states are not only used for action monitoring and control, but also evaluated and used as desired (goal) states which steer and guide action. The upper-left part of the Wgure is responsible for decision-mak-

ing by evaluating, comparing and selecting the speciWed actions. The upper-right is responsible for executive control, coupling the directing inXuence of the comparator and inhibitory mechanisms. The bottom part is responsible for speciWcation (via simulation) of action and plans, and their execution after selection.
It is commonly assumed in informational approaches that action speciWcation, decision making and execution are successive processing phases. On the contrary, in this model all these aspects can hardly be disentangled. First, in this model evaluation consists in the meshing of simulations with motivational and cognitive elements, which leads to the ampliWcation of stimuli dimensions of the preferred alternatives (as shown in Fig. 3). This is compliant with neural evidence that action planning and the decision to act are two aspects of the same neural process (Cisek & Kalaska, 2005) and similar to the ‘aVordance competition’ hypothesis advanced to explain these Wndings (Cisek, 2007). Evidence of a ‘pull’ from competing response alternatives during a reaching task (McKinstry, Dale, & Spivey, 2008) provides further indication that decision making might not be its own a single, clear-cut phase, but operates, rather, in continuity with planning and execution. We also know that uncertainty in the decision can inXuence accuracy of execution (consider the uncertain soccer player who misses the penalty shot). Second, in this model planning and execution processes are intertwined, in that they recruit the same schemas, in simulation Wrst and execution thereafter, although it is not required that complete plans are prepared even for the selected actions8. A parsimonious
8 Although plans can be prepared in simulation and stored in working memory to steer action, there is no guarantee that during execution the same sequence of schemas will be used, since the contextual conditions can vary. For example, I can plan grasping an object with my left hand, and then grasp it with my right hand if it is not longer in reach of left hand. At the same time, simulations can be quite abstract and involve eVector-independent representations. Anyway, in this model planning always inXuence action execution since re-enacts schemas and primes them and their stimuli dimensions.

123

570

Psychological Research (2009) 73:559–577

explanation of these phenomena is that all these subsystems use the same (motor) representation, which assumes diVerent roles throughout the process. The representation of a to-be-performed action is Wrst speciWed, then evaluated (with a contribute of the motivational system which assigns it some value), and then used for action execution. This integration also explains how the comparator can always operate on representations having comparable formats.
Interface with motivational system and bodily models
The addition of the problem of selection naturally permits us to incorporate motivation into the control-theoretic framework. Indeed, to select the best available action alternative, the organism has to evaluate potential actions in advance with respect to its needs and preferences. The essence of goal-directed selection is that because the internal (motivational and cognitive) context can vary, potential actions can be evaluated diVerentially, providing that a Xexible mapping between outcomes and values can be computed (Daw, Niv, & Dayan, 2005). For the aims of this paper we consider that this evaluation is performed primarily by the somatic markers system (Damasio, 1994), which we hypothesize acts like an internal bodily model, in the sense that it mimics the bodily aVective response to a stimulus, and oVers a (motivational) ‘evaluation’ of hypothetical (simulated) outcomes of actions (diVerently from other internal models, they are created from bodily signals such as feelings and rewards and are not grounded in the motor apparatus but in the visceral system). In addition, cognitive information and reward prediction mechanisms appear to operate in concert during the selection process, forming a complex (and layered) network whose complete description lies out of the scope of this paper (see for example Berridge, 2004 on the distinction between mechanisms determining motivation and valence).
Interface with executive functions
As shown on the right of Fig. 4, two inhibitory mechanisms are also required for this mechanism to work. The Wrst mechanism consists in the choice of input channel. There is evidence that action selection acts on stimulus dimensions by amplifying stimuli and assigning them incentive salience (Redgrave, Prescott, & Gurney, 1999). As noted by Grush (2004), in control-theoretic models this is equivalent to the notion of Kalman gain, or the gating of sensory feedback (e.g., depending on its noise). The second mechanism consists in the (temporary) suppression of both control commands and external inputs, whose result is a shift from outward to inward, or from the external context to internal simulations and memories (Glenberg, 1997; Jeannerod, 2001). Inhibition of this second type is required

because the same schemas cannot execute and simulate at the same time and there is a competition to resolve between two sources of stimuli: sensed and predicted. Indeed, there is evidence of a strong inhibition of action execution when the same action is observed (Rizzolatti & Arbib, 1998), imagined (Jeannerod, 1999) or verbally described (Tettamanti et al., 2005). Overall, eVective control-theoretic mechanisms which can operate simulations and selection necessitate the inhibition of automatic responses and the selection of relevant stimuli dimensions, which are two of the hallmarks of executive functions, and parallel the directing action of the comparator in the top-down modulation of attention and behavior (Miller & Cohen, 2001).
Two complementary mechanisms serving executive functions are progress monitoring and working memory. Indeed, the progress of the comparator can be monitored in parallel with successes or failures in performance, as they provide information for abandoning selected actions revealed to be too diYcult to achieve, and can give hints about conXicts arising in composite actions when contextual conditions change. This process has dramatic eVects on motivation; for example, it can induce relief or frustration (Scheier & Carver, 2003). Also, a working memory (Baddeley & Hitch, 1974) mechanism is required for active maintenance of distal goals over long periods of time and for transmitting constraints to successive actions (see Burgess & Hitch, 2005 for a recent review of associated computational mechanisms).
Simulations, mental time travel and intertemporal choice
Although in the discussion of Figs. 3 and 4 we have mostly discussed (perceptually) available aVordances, this architecture is not doomed to be opportunistic; it can also exploit aVordances cued by (episodic) memories primed by the current context. Simulative capabilities and the meshing with memory allow one to imagine future (and not perceptually present) events. Suddendorf and Corballis (2007) have named this ability mental time travel, and argued that is equivalent to episodic memory but directed to the future and not the past. With this ability an agent can, for instance, mentally generate scenarios concerning future aVordances, and imagine future rewarding events, so that it can disregard immediate rewards in favor of distal and potentially higher ones; this is a basic capability required for intertemporal choice (McClure, Laibson, Loewenstein, & Cohen, 2004). In accordance with hierarchical selection models (Redgrave et al., 1999; Koechlin & SummerWeld, 2007), we argue that the mechanisms of action evaluation and selection could be the same for all kinds of events, proximal or distal. This seems to indicate that there could be a common currency for (implicit) intertemporal tradeoVs which (Rolls, 1999) suggests to be emotion (see also Rick & Loewen-

123

Psychological Research (2009) 73:559–577

571

stein, 2008 for the idea that anticipatory, or anticipated, emotions such as guilt or anxiety can serve as proxy for intangible outcomes related to future scenarios, since distal events are more diYcult to simulate, and uncertain).
Stage 3: the control of imagination
The aforementioned architecture for goal speciWcation and selection has several limitations. First, its agenda is mostly dictated by aVordances that can be easily perceived from the external environment or memory, so it is only partially autonomous. Even worse, since aVordances always vary, novel opportunities risk the ruining of old plans. This severely impairs the pursuit of distal objectives, which requires the active maintenance of intentions until they are realized, and the ability to set-up multistep plans and subgoals.
These additional capabilities can be acquired by adding to the architecture described above a more complex form of self-regulation, which requires a minor architectural modiWcation (however, it is a major evolutionary step); see Fig. 5. A coordinated inhibition of ongoing simulations (i.e. speciWcation of potential actions) going to the evaluator is necessary, as is an internalization of the activity of the comparator, which can then compare reference signals with simulated (and not perceived) events. In other words, it is necessary for an agent to stop deciding once a goal is set, in order to maintain commitment and to protect intentions from external inXuences. At the same time it is necessary that an imagined, self-generated event, and not a perceptual event, becomes the controlled variable; this procedure permits not only the self-generation of goals (like in the second stage), but also the recursive use of predictions to set subgoals, to correct and reWne plans until a satisfactory solution is found, or even to reason about problems without acting toward their solution. According to Bratman (1987), this combined capability of self-regulation and planning is

one of the hallmarks of intentional action; indeed, he describes intentions are terminators of practical reasoning about ends, and prompters of practical reasoning about means. In addition, this process gives an agent intertemporal coordination, or the ability to coordinate its own actions in the present and future, to pursue distal objectives.
Imagine that I have selected the (eVector-independent) goal to put some beer cans in the refrigerator, which is triggered by my goal of ‘inviting friends’. When I am near the fridge with both hands occupied, the typical unfolding from high-level to low-level schemas would fail. However, I can mentally simulate opening the fridge door with my foot (or by asking for your help, etc.). The (perceptual) result of this simulation (but not, say, of a simulation involving the mouth) is evaluated by the comparator as compliant with the goal, and becomes the desired state; this also means setting the subgoal ‘opening fridge with foot’. The desired state can then be Wlled in as input to the appropriate set of (eVector-dependent) inverse models, which are responsible for generating contextually appropriate motor commands to achieve the subgoal. Note that I can mentally reWne the plan in my mind before executing it; for example, I can try out mentally rotating my foot clockwise or counterclockwise for facilitating the opening. This is a multistep process in which I interactively produce simulations and use the comparator to judge them, therefore exerting control over my imagination. Mental simulations, decisions and action execution can be interactive. For example, I can start planning to put cans in a refrigerator, then open the refrigerator door, and only later on decide where to put the beer cans by simulating and evaluating multiple opportunities. Interactive simulations allow a bridging of the gap between higher level goals, which tend to be quite abstract (‘having cold beer’), and their proximal and opportunistic realization in interactive steps, which require the speciWcation of subgoals (put beer cans in the refrigerator, which in turn implies opening the refrigerator door, placing the cans, etc.). (Note

Fig. 5 Now the selector operates on imagination, too

123

572

Psychological Research (2009) 73:559–577

also that in order to ‘protect’ my intention, I must actively inhibit the preponderant action of drinking beer, especially if I am thirsty.)
It is important to remark that the coupling between mentally executed and externally executed actions is guaranteed by the fact that mental manipulations respect the aVordances of the environment although they are detached from the here-and-now. Barsalou (1999) provides an excellent example of this ability:
To the extent that simulations capture aVordances from perception and action, successful reasoning about physical situations can proceed in their absence [of sensorymotor experiences] [...]. Agents can draw inferences that go beyond perceived entities, and they can plan intelligently for the future. While sitting in a restaurant and wanting to hide from someone entering, one could simulate that a newspaper on the table aVords covering one’s face completely but that a matchbook does not. As a result of these simulations, the newspaper is selected to achieve this goal rather than the matchbook. Because the simulations captured the physical aVordances correctly, the selected strategy works.
Overall, the control of imagination, which requires the combined suppression of decisions and internalization of the activity of the comparator, permits the versatile use of ‘manipulable internal models’. This architecture can operate ‘mentally’ and partially detached from the immediate demands of the environment, and for this reason it has an increased capability to set up and achieve distal intentions goal-directed actions, and to think abstractly about problems and solutions. For example, I can think about cans and refrigerators also when these objects are not in front of me. Note, however, that our account of thinking is intended to address concrete forms of imagination and planning linked to our everyday actions, whereas other forms of abstract reasoning, such as those required to invent novel theories in physics, require also the mastering of linguistic and other symbolic abilities.
Future-directed intentions, and more complex self-regulatory mechanisms
Not only can humans (and perhaps few non human animals) formulate present-directed intentions, or those that occur in the context of the action to be taken, but they can also formulate future-directed intentions, which prescribe future conducts (e.g., ‘go to the cinema tomorrow’). Active maintenance in working memory is not a possible explanation for such intentions (Miller & Cohen, 2001); rather, they must be put in a memory for future actions, or a neural agenda, together with a mechanism for their future triggering depending on external conditions. Along these lines,

HoVmann et al. (2004) propose the idea of trigger anticipations, and Gollwitzer (1999) proposes the idea of implementation intentions. Both are essentially strategies for delegating control to anticipated perceptual cues which are actively monitored, and can trigger goal-directed responses automatically when opportune external conditions occur. Not only can intentions in the ‘neural agenda’ be triggered by external cues, but they can also be abandoned or revised depending on novel events that make replanning necessary. Imagine I decide to go to the mountains tomorrow. Later on I watch the weather forecasts, which predict rain. By simulating the consequences, I see that they conXict with my intention, and I can decide either to remain at home or to put an umbrella in the car. This complex example requires a combined capability to simulate and evaluate distal events, understand their causal relations, retain intentions and plans in memory and inhibit simulations and current actions. In the architecture described above, almost all these abilities are individually present; achieving their coordination is, however, the product of a long evolutionary process.
Another mechanism which could be implied in the passage from present-directed to future-directed intention is the suppression of internal inputs in addition to the suppression of external inputs. As illustrated in Fig. 5, an additional inhibitory mechanism could operate in the evaluative dimension by suppressing the current motivational context and immediate feelings and desires. This allows anticipatory planning, a sophisticated form of proactivity in which one acts in view of one’s own future needs and opportunities, and not only those immediately perceivable or felt, which is available to humans and few other species (Raby, Alexis, Dickinson, & Clayton, 2007) and represents another use of mental time travel (Suddendorf & Corballis, 2007). One example of such capability is going to the market even if one is not currently hungry. To do so requires suppressing the most immediate motivational context, as to activate simulations priming future motivations (thanks to the meshing of simulations with the motivational dimension).
The suppression of internal inputs is extremely risky, but it permits an agent to self-regulate its motivational state, too. For example, I can imagine my victory in a marathon, and this aVectively charged anticipation can change my motivational state, enabling me to continue running despite my fatigue, or to train several months before the marathon. Overall, inhibition of current motivations and mental simulations could act in concert to allow complex forms of selfregulation in favor of distal goals.
Conclusions
This paper is an attempt to describe the intentional mechanisms of a cognitive mind in a control-theoretic framework.

123

Psychological Research (2009) 73:559–577

573

We start from a system of behavioral regulation that is capable of instrumental action, and describe the acquisition of an autonomous mental life and mechanisms of self-regulation, arguing that taking intentional action and thinking make use of large portions of the same neural machinery. One crucial passage is from the control of internal variables to that of external variables, and Wnally of mental variables and simulations. The third step is also a passage from on-line to oV-line cognition, with the detachment of (goal) representations from the here-and-now of perception. We have highlighted how a key role in this passage is the development of increasingly advanced anticipatory capabilities, which lead to the construction of a mental life composed of endogenously generated simulations. In turn, this determines a need for self-regulation; for example, suppression of prepotentiated actions (to achieve endogenously generated goals), of the external environment (to harness imagination), and of current motivations (to act for future necessities). In this sense, we devise a reconciliation of the motor theories of cognition with theories of motivation and executive functions.
The cognitive leverage hypothesis
Until now we did not provide an evolutionary perspective, but simply presented ‘pictures’ of architectures with increasingly complex abilities. It is worth noting that organisms did not evolve for solving cognitive problems, but that the solution of problems of motor control and sociality (giving selection advantages) leveraged cognition, too. This is thus a story of successive adaptations and exaptations, which starts from the necessity to control the body (and hence to predict) and to satisfy multiple motivations, and leverages cognitive skills. We therefore propose that representational and cognitive capabilities emerged under the selection pressure of optimal adaptive control and successful social life as an elaboration of to the basic computational architecture supporting goal-directed action (whose essential elements are internal models), and still retain motor aspects.
Providing a complete description of all the steps of this passage could prove to be overly complicated, so here we can only make a rough sketch. We argue that anticipatory capabilities arose for the sake of action control: compensating delays, replacing missing input, etc. Representation, which is used here in the sense of emulation (Grush, 2004), is an exaptation of such mechanisms and provides the Wrst form of detachment from the current here-and-now, and a scaVolding for all cognition—in this sense we made the case that anticipation leveraged cognition (Pezzulo & Castelfranchi, 2007). Internal simulations, or oV-line internal modeling loops, arose for better planning under the selection pressure of multiple competing (individual and social)

motivations and were therefore exapted for oV-line thinking and the mental manipulation of representations. Executive functions, and in particular inhibition, are simply elaborations of the basic control-theoretic architecture that arose for resolving intertemporal choice problems under the selection pressures of sophisticated social life and intraspecies competition; along these lines, most authors argue that intentionality and executive control arose for social needs (Barkley, 2001; Rochat, 2007). However, it is important to remark that they exapted a ready-made functional and neural substrate, whose core components are internal models. This is why we argue that thinking is essentially an internal simulation of behavior and makes use of the same sensorymotor systems as those used for overt behavior (Cotterill, 2001; Hesslow, 2002). Successively, language capabilities could have leveraged on representational and simulative abilities of the motor system to provide increasingly rich abstraction and cognitive capabilities; see (Arbib, 2005).
It is worth noting that although cognition originates from and remains intimately coupled with situated action (since it is supported by sensorimotor skills), it is reductive to say that it is now only in the service of situated action. Cognition, and a true mental life, can be used Xexibly to generate imaginary actions and events that support distal goaldirected action. The capability to conceive and cope with distal goals provides the organism with a remarkable autonomy from the present situation (in terms of both external and internal contexts) in that they embed a representation not of how the world currently is, but of how the organism wants the world to be. This means, ultimately, that goaldirected organisms not only adapt to their environments, but can adapt the world to their goals and act in their environments to prepare appropriate contexts for their future goals—this is the basis for heavy modiWcations of their environments, including the massive production of artifacts and tools, produced by humans and few other animals. This autonomy and decoupling gives the ultimate behavioral Xexibility, but also potentially opens the doors to dangerous phenomena such as delusions, schizophrenia and out-ofbody experiences. This is due in particular to the risky maneuver of suppressing the external environment, which is required for oV-line cognition and mental operations.
Putative brain mechanisms
The control-theoretic view we have proposed has to be understood in a purely functional way. The components we indicate could not map into localized neural structures, and most likely they are realized by distributed processes in interconnected brain areas. Nonetheless recent studies highlight possible neural substrates for the interactive prediction and selection of behavior which is postulated by our model. In particular, Middleton and Strick (2000) describe a loop

123

574

Psychological Research (2009) 73:559–577

between the cerebellum, responsible for sensory prediction, and the basal ganglia, responsible for the selection and priming of stimuli dimensions. Along similar lines, Houk (2005) describes how ‘incomplete thoughts’ are Wrst selected by the basal ganglia and therefore ampliWed and reWned through cerebellar loops, and Cotterill (2001) describes the role of basal ganglia in inhibiting commands to (pre)motor areas, which are responsible for generating behavior and directing attention. Recently Cisek (2007) has also discussed a possible neural architecture for realizing action speciWcation and selection, and added to the picture the combined roles of the dorsal and ventral visual systems in specifying and biasing aVordances. (See also Fagg & Arbib (1998) for a discussion of this issue.) Evaluation, with its motivational and cognitive dimensions, could involve more complex neural circuits. For the sake of simplicity, we focused here only on the incentive salience of stimuli (Berridge, 2004), and on the idea of “as-if” loops in Damasio (1994), who proposes a putative brain circuit that could involve (at least) the prefrontal cortex, the cerebellum, and the amygdala, which has a role in decoding incentive value of stimuli. The neural substrate of executive functions and self-control capabilities, which most studies localize in (pre)frontal areas, is even more complex, and clearly outside the scope of this paper (but see Haggard, 2008). It is worth noting, however, that the kinds of inhibition discussed here have been recently described by Burgess, Dumontheil and Gilbert (2007) in their attentional gateway hypothesis of rostral prefrontal cortex.
Predictions of the model
Overall, our approach is compliant with a grounded view of cognition; see (Barsalou, 2008) for a recent review. Although empirical evidence continues to accumulate in favor of this view, there is still a lack of comprehensive frameworks in which to put all empirical phenomena in a coherent perspective, and especially to scale up to higher level cognitive functions. The conceptual framework we have elaborated in this paper is an attempt in this direction, which we hope can stimulate further research and thinking. We therefore conclude by highlighting some of its empirical predictions.
First, the distinguishing point of our simulation-based approach to planning, with respect to traditional AI techniques, is a (covert) recruitment of the motor system, rather than a search within static memory structures. Indeed, internal models do not represent action outcomes in a searchable table (or another static memory structure), but permit their production through re-enactment. This leads to diVerent empirical predictions, for example that deWcits in action execution and action planning should be related. A related prediction of the model is that the preparation of distal

intentions should be similar to the speciWcation of proximal actions; for example, like currently available aVordances prepotentiate actions, predicted aVordances that belong to a plan should prepotentiate its component actions. Similarly, just as selective attention is regulated for proximal action execution, it can be regulated to attend to future stimuli. These eVects could be revealed by extending experimental paradigms from the study of proximal actions to that of distal actions.
Second, in our model planning individual action and observing others’ actions are interrelated tasks and require the same schemas. Consequently, our model predicts that an agent can use its own actions and plans to understand others’ actions and plans, and that increased skill (with associated increased anticipatory capabilities) should determine a better understanding of similar actions when performed by others: these are two phenomena that have recently received some empirical conWrmation (Aglioti, Cesari, Romani, & Urgesi, 2008; Flanagan & Johansson, 2003).
Third, the relations between anticipatory and cognitive abilities, which we have highlighted throughout the paper, could be revealed by developmental studies. Indeed, recent studies indicate that cognitive and motor development are intimately interrelated, and not successive stages. Two particularly interesting hypotheses, which are compatible with our view, are that the development of predictive capabilities is a prerequisite for most behavioral and cognitive development (von Hofsten, 2004), and that the cognitive system could have inherited the predictive capabilities of the sensorimotor system, which therefore leveraged more advanced forms of cognition (Rosenbaum, Carlson, & Gilmore, 2001a).
Finally, according to our model executive functions are a specialization of older mechanisms for situated action control, and should preserve vestigial motor aspects which will likely be revealed through imaging studies (see Barkley, 2001 for a similar perspective).
Acknowledgments This work was supported by the European Community, project HUMANOBS: Humanoids That Learn Socio-Communicative Skills Through Observation (FP7-231453). The authors would like to thank Michael Arbib, Anna Borghi, and Elisabeth Pacherie for useful comments and criticisms.
References
Adams, J. A. (1971). A closed-loop theory of motor learning. Journal of Motor Behavior, 3, 111–149.
Aglioti, S. M., Cesari, P., Romani, M., & Urgesi, C. (2008). Action anticipation and motor resonance in elite basketball players. Natural Neuroscience, 11(9), 1109–1116.
Arbib, M. A. (1981). Perceptual structures and distributed motor control. In V. B. Brooks (Ed.) Handbook of physiology—the nervous

123

Psychological Research (2009) 73:559–577

575

system II. Motor control (pp. 1449–1480). Bethesda: American Physiological Society. Arbib, M. (2005). From monkey-like action recognition to human language: An evolutionary framework for neurolinguistics. Behavioral and Brain Sciences, 28, 105–121. Arbib, M., Bonaiuto, J., Jacobs, S., & Frey, S. (2009). Tool use and the distalization of the end-eVector (this issue). Baddeley, A., & Hitch, G. (1974). Working memory. In G. Bower (Ed.), The Psychology of Learning and Motivation (pp. 47–89). London: Academic. Balleine, B. W., & Dickinson, A. (1998). Goal-directed instrumental action: Contingency and incentive learning and their cortical substrates. Neuropharmacology, 37(4–5), 407–419. Bargh, J. A., & Chartrand, T. L. (1999). The unbearable automaticity of being. American Psychologist, 54, 462–479. Barkley, R. A. (2001). The executive functions and self-regulation: An evolutionary neuropsychological perspective. Neuropsychology Review, 11(1), 1–29. Barsalou, L. W. (1999). Perceptual symbol systems. Behavioral and Brain Sciences, 22, 577–600. Barsalou, L. (2008). Grounded cognition. Annual Review of Psychology, 59, 617–645. Berridge, K. (2004). Motivation concepts in behavioral neuroscience. Physiology and Behavior, 81(2), 179–209. Berthoz, A. (2000). The brain’s sense of movement. Cambridge: Harvard University Press. Blakemore, S. J., Goodbody, S. J., & Wolpert, D. M. (1998). Predicting the consequences of our own actions: The role of sensorimotor context estimation. The Journal of Neuroscience, 18(18), 7511– 7518. Botvinick, M. M. (2008). Hierarchical models of behavior and prefrontal function. Trends in Cognitive Sciences, 12(5), 201–208. Brass, M., Bekkering, H., Wohlschlger, A., & Prinz, W. (2000). Compatibility between observed and executed Wnger movements: Comparing symbolic, spatial and imitative cues. Brain and Cognition, 44, 124–143. Bratman, M. (1987). Intentions, plans, and practical reason. Cambridge: Harvard University Press. Bullock, D., & Grossberg, S. (1988). Neural dynamics of planned arm movements: Emergent invariants and speed-accuracy properties during trajectory formation. Psychol Rev, 95, 49–90. Burgess, N., & Hitch, G. (2005). Computational models of working memory: Putting long-term memory into context. Trends in Cognitive Sciences, 9, 535–541. Burgess, P. W., Dumontheil, I., & Gilbert, S. J. (2007). The gateway hypothesis of rostral prefrontal cortex (area 10) function. Trends in Cognitive Sciences, 11(7), 290–298. Castelfranchi, C. (2000). Through the agents’ minds: Cognitive mediators of social action. Mind & Society, 1, 109–140. Cisek, P. (2005). Neural representations of motor plans, desired trajectories, and controlled objects. Cognitive Processing, 6, 15–24. Cisek, P. (2007). Cortical mechanisms of action selection: The aVordance competition hypothesis. Philosophical transactions of the Royal Society of London. Series B, 362, 1585–1599. Cisek, P., & Kalaska, J. F. (2005). Neural correlates of reaching decisions in dorsal premotor cortex: SpeciWcation of multiple direction choices and Wnal selection of action. Neuron, 45(5), 801–814. Cotterill, R. (2001). Cooperation of the basal ganglia, cerebellum, sensory cerebrum and hippocampus: Possible implications for cognition, consciousness, intelligence and creativity. Progress in Neurobiology, 64, 1–33. Craighero, L., Fadiga, L., Rizzolatti, G., & Ulmita, C. (1999). Action for perception: A motor-visual attentional eVect. Journal of Experimental Psychology: Human Perception and Performance, 25, 1673–1692.

Craik, K. (1943). The nature of explanation. Cambridge: Cambridge University Press.
Damasio, A. R. (1994). Descartes’ error: emotion, reason and the human brain. New York: Grosset/Putnam.
Daw, N.D., Niv, Y., & Dayan, P. (2005). Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control. Nature Neuroscience, 8(12), 1704–1711.
Decety, J., & Grèzes, J. (2006). The power of simulation: Imagining one’s own and other’s behavior. Brain Research, 1079(1), 4–14.
Demiris, Y., & Khadhouri, B. (2005). Hierarchical attentive multiple models for execution and recognition (hammer). Robotics and Autonomous Systems Journal, 54, 361–369.
Desmurget, M., & Grafton, S. (2000). Forward modeling allows feedback control for fast reaching movements. Trends in Cognitive Sciences, 4, 423–431.
Diamond, A. (2000). Close interrelation of motor development and cognitive development and of the cerebellum and prefrontal cortex. Child Development, 71, 44–56.
Fadiga, L., Craighero, L., Buccino, G., & Rizzolatti, G. (2002). Speech listening speciWcally modulates the excitability of tongue muscles: A tms study. European Journal of Neuroscience, 15, 399– 402.
Fagg, A., & Arbib, M. (1998). Modeling parietal-premotor interactions in primate control of grasping. Neural Networks, 11(7–8), 1277– 1303.
Fagioli, S., Hommel, B., & Schubotz, R. I. (2007). Intentional control of attention: Action planning primes action-related stimulus dimensions. Psychological Research, 71(1), 22–29.
Fiebach, C. J., & Schubotz, R. I. (2006). Dynamic anticipatory processing of hierarchical sequential events: A common role for broca’s area and ventral premotor cortex across domains? Cortex, 42(4):499–502.
Flanagan, J., & Johansson, R. (2003). Action plans used in action observation. Nature, 424, 769–771.
Fogassi, L., Ferrari, P., Chersi, F., Gesierich, B., Rozzi, S., & Rizzolatti, G. (2005). Parietal lobe: From action organization to intention understanding. Science, 308, 662–667.
Friston, K. (2005). A theory of cortical responses. Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences, 360(1456), 815–836.
Frith, C. D., Blakemore, S. J., & Wolpert, D. M. (2000). Abnormalities in the awareness and control of action. Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences, 355(1404), 1771–1788.
Fuster, J. M. (1997). The prefrontal cortex: Anatomy, physiology, neuropsychology of the frontal lobe. Philadelphia: LippincottRaven.
Gallese, V. (2001). The ’shared manifold’ hypothesis. From mirror neurons to empathy. Journal of Consciousness Studies, 8, 5–87.
Gallese, V., & Metzinger, T. (2003). Motor ontology: The representational reality of goals, actions, selves. Philosophical Psychology, 13(3), 365–388.
Gallese, V., Keysers, C., & Rizzolatti, G. (2004). A unifying view of the basis of social cognition. Trends in Cognitive Sciences, 8(9), 396–403.
Gardenfors, P. (2004). Emulators as sources of hidden cognitive variables. The Behavioral and Brain Sciences, 27(3), 403.
Gardenfors, P. (2007). Mind-reading as control theory. European Review, 15(2), 223–240.
Gibson, J. (1979). The ecological approach to visual perception. Mahwah: Lawrence Erlbaum Associates, Inc.
Glenberg, A. (1997). What memory is for. Behavioral and Brain Sciences, 20, 1–55.
Gollwitzer, P. (1999). Implementation intentions: Strong eVects of simple plans. American Psychologist, 54, 493–503.

123

576

Psychological Research (2009) 73:559–577

Gregory, R. L. (1969). On how so little information controls so much behavior. In C. H. Waddington (Ed.), Towards a Theoretical Biology. 2, Sketches. Edinburgh: Edinburgh University Press.
Grush, R. (2004). The emulation theory of representation: Motor control, imagery, perception. Behavioral and Brain Sciences, 27(3), 377–96.
Haggard, P. (2008). Human volition: Towards a neuroscience of will. Nature Reviews Neuroscience, 9, 934–946.
Hamilton, A. F. d. C. & Grafton, S. T. (2007). The motor hierarchy: From kinematics to goals and intentions. In P. Haggard, Y. Rossetti, M. Kawato (Eds.), Sensorimotor foundations of higher cognition. NY: Oxford University Press.
Haruno, M., Wolpert, D., & Kawato, M. (2003). Hierarchical mosaic for movement generation. In T. Ono, G. Matsumoto, R. Llinas, A. Berthoz, H. Norgren, R. Tamura (Eds.), Excepta medica international coungress series. Amsterdam: Elsevier.
Hesslow, G. (2002). Conscious thought as simulation of behaviour and perception. Trends in Cognitive Sciences, 6, 242–247.
HoVmann, J., Stöcker, C., & Kunde, W. (2004). Anticipatory control of actions. International Journal of Sport and Exercise Psychology, 2, 346–361.
Hommel, B. (2000). The prepared reXex: Automaticity and control in stimulus-response translation. In S. Monsell, J. Driver (Eds.), Attention and performance XVIII: Control of cognitive processes (pp. 247–273). Cambridge: MIT Press.
Hommel, B., Musseler, J., Aschersleben, G., & Prinz, W. (2001). The theory of event coding (tec): A framework for perception and action planning. Behavioral and Brain Science, 24(5), 849–78.
Houk, J. C. (2005). Agents of the mind. Biological Cybernetics, 92(6), 427–437.
Hurley, S. (2008). The shared circuits model (scm): How control, mirroring, simulation can enable imitation, deliberation, mindreading. Behavioral and Brain Sciences, 31, 1–22.
Iacoboni, M., Molnar-Szakacs, I., Gallese, V., Buccino, G., Mazziotta, J. C., & Rizzolatti, G. (2005). Grasping the intentions of others with one’s own mirror neuron system. PLoS Biol, 3(3), e79.
Ito, M. (1993). Movement and thought: Identical control mechanisms by the cerebellum. Trends in Neurosciences, 16, 448–450.
Jacob, P., & Jeannerod, M. (2005). The motor theory of social cognition: A critique. Trends in Cognitive Sciences, 9(1), 21–25.
James, W. (1890). The principles of psychology. New York: Dover Publications.
Jeannerod, M. (1994). The representing brain: Neural correlates of motor intention and imagery. The Behavioral and Brain Sciences, 17:187–245.
Jeannerod, M. (1997). The cognitive neuroscience of action (pp. 173– 174). Oxford: Blackwell.
Jeannerod, M. (1999). To act or not to act: Perspectives on the representation of actions. Quarterly Journal of Experimental Psychology, 52A(1), 1–29.
Jeannerod, M. (2001). Neural simulation of action: A unifying mechanism for motor cognition. NeuroImage, 14, S103–S109.
Jeannerod, M. (2006). Motor cognition. NY: Oxford University Press. Jordan, J. S. (2003). Emergence of self and other in perception and
action. Consciousness and Cognition, 12, 633–646. Jordan, M. I., & Rumelhart, D. (1992). Forward models: Supervised
learning with a distal teacher. Cognitive Science, 16, 307–354. Kawato, M. (1999). Internal models for motor control and trajectory
planning. Current Opinion in Neurobiology, 9, 718–727. Kilner, J., Paulignan, Y., & Blakemore, S. (2003). An interference
eVect of observed biological movement on action. Current Biology, 13, 522–525. Koechlin, E., & SummerWeld, C. (2007). An information theoretical approach to prefrontal executive function. Trends Cogn Sci, 11(6), 229–235.

Konidaris, G., & Barto, A. (2007). Building portable options: Skill transfer in reinforcement learning. In Proceedings of the twentieth international joint conference on artiWcial intelligence (IJCAI07).
Kurby, C. A., & Zacks, J. M. (2008). Segmentation in the perception and memory of events. Trends in Cognitive Sciences, 12(2), 72– 79.
Land, M. F. (2006). Eye movements and the control of actions in everyday life. Progress in Retinal and Eye Research, 25, 296– 324.
Martin, A., Wiggs, C. L., Ungerleider, L. G., & Haxby, J. V. (1996). Neural correlates of category-speciWc knowledge. Nature, 379, 649–652.
McClure, S., Laibson, D., Loewenstein, G., & Cohen, J. (2004). Separate neural systems value immediate and delayed monetary rewards. Science, 304, 503–507.
McKinstry, C., Dale, R., & Spivey, M. J. (2008). Action dynamics reveal parallel competition in decision making. Psychological Science, 19(1), 22–24.
Mehta, B., & Schaal, S. (2002). Forward models in visuomotor control. Journal of Neurophysiology, 88, 942–53.
Miall, R. C. (2003). Connecting mirror neurons and forward models. Neuroreport, 14(17), 2135–2137.
Miall, R. C., & Wolpert, D. M. (1996). Forward models for physiological motor control. Neural Networks, 9(8), 1265–1279.
Miceli, M., & Castelfranchi, C. (2002). Modelling motivational representations. Cognitive Science Quarterly, 2, 233–247.
Middleton, F. A., & Strick, P. L. (2000). Basal ganglia output and cognition: Evidence from anatomical, behavioral, clinical studies. Brain Cognition, 42(2), 183–200.
Miller, E. K., & Cohen, J. D. (2001). An integrative theory of prefrontal cortex function. Annual Review of Neuroscience, 24, 167–202.
Miller, G. A., Galanter, E., & Pribram, K. H. (1960). Plans and the structure of behavior. New York: Holt, Rinehart and Winston.
Moller, R., & Schenck, W. (2008). Bootstrapping cognition from behavior—a computerized thought experiment. Cognitive Science, 32(3), 504–542.
Nishimoto, R., & Tani, J. (2009). Development process of functional hierarchy for actions and motor imagery: A constructivist view from synthetic neuro-robotics study (this issue).
Niv, Y., Joel, D., & Dayan, P. (2006). A normative perspective on motivation. Trends in Cognitive Science, 8, 375–381.
Oztop, E., Wolpert, D., & Kawato, M. (2005). Mental state inference using visual control parameters. Cognitive Brain Research, 22, 129–151.
Oztop, E., Kawato, M., & Arbib, M. (2006). Mirror neurons and imitation: A computationally guided review. Neural Network, 19(3), 254–271.
Pacherie, E. (2008). The phenomenology of action: A conceptual framework. Cognition, 107, 179–217.
Pezzulo, G. (2008a). Coordinating with the future: The anticipatory nature of representation. Minds and Machines, 18(2), 179–225.
Pezzulo, G. (2008b). A study of oV-line uses of anticipation. In M. Asada, J. Tani, J. Hallam, J.-A. Meyer (Eds.), Proceedings of SAB 2008. LNAI, vol 5040 (pp. 372–382). Berlin: Springer.
Pezzulo, G., & Castelfranchi, C. (2007). The symbol detachment problem. Cognitive Processing, 8(2), 115–131.
Pham, L. B., & Taylor, S. E. (1999). From thought to action: EVects of process- versus outcome-based mental simulations on performance. Personality and Social Psychology Bulletin, 25, 250–260.
Piaget, J. (1954). The construction of reality in the child. Ballentine. Powers, W. T. (1973). Behavior: The control of perception.
Hawthorne, NY: Aldine. Prinz, W. (1997). Perception and action planning. European Journal of
Cognitive Psychology, 9, 129–154.

123

Psychological Research (2009) 73:559–577

577

Raby, C. R., Alexis, D. M., Dickinson, A., & Clayton, N. S. (2007). Planning for the future by western scrub-jays. Nature, 445(7130), 919–921.
Redgrave, P., Prescott, T. J., & Gurney, K. (1999). The basal ganglia: A vertebrate solution to the selection problem? Neuroscience, 89, 1009–1023.
Rick, S., & Loewenstein, G. (2008). Intangibility in intertemporal choice. Philosophical transactions of the Royal Society of London. Series B, Biological sciences, 363(1511), 3813–3824.
Rizzolatti, G., & Arbib, M. A. (1998). Language within our grasp. Trends in Neurosciences, 21(5), 188–194.
Rizzolatti, G., & Craighero, L. (2004). The mirror-neuron system. Annual Review of Neuroscience, 27, 169–192.
Rizzolatti, G., Camarda, R., Fogassi, L., Gentilucci, M., Luppino, G., & Matelli, M. (1988). Functional organization of inferior area 6 in the macaque monkey. ii. area f5 and the control of distal movements. Experimental brain research. Experimentelle Hirnforschung. Expérimentation cérébrale, 71(3), 491–507.
Rizzolatti, G., Riggio, L., & Sheliga, B. (1994). Space and selective attention. In C. Umilta, M. Moscovitch (Eds.) Attention and performance XV (pp. 231–265). Cambridge, Mass: MIT Press.
Rochat, P. (2007). Intentional action arises from early reciprocal exchanges. Acta Psychologica, 124(1), 8–25.
Rolls, E. T. (1999). The brain and emotion. New York: Oxford University Press.
Rosenbaum, D. (1991). Human motor control. New York: Academic Press.
Rosenbaum, D. A., Carlson, R. A., & Gilmore, R. O. (2001a). Acquisition of intellectual and perceptual-motor skills. Annual Review of Psychology, 52, 453–70.
Rosenbaum, D. A., Meulenbroek, R. J., & Vaughan, J. (2001b). Planning reaching and grasping movements: Theoretical premises and practical implications. Motor Control, 2, 99–115.
Rosenblueth, A., Wiener, N., & Bigelow, J. (1943). Behavior, purpose and teleology. Philosophy of Science, 10(1), 18–24.
Scheier, M. F., & Carver, C. S. (2003). Self-regulatory processes and responses to health threats: EVects of optimism on well-being. In J. Suls, K. Wallston (Eds.), Social psychological foundations of health (pp. 395–428). Oxford: Blackwell.
Schmidt, R. A. (1975). A schema theory of discrete motor skill learning. Psychological Review, 82, 225–260.
Schubotz, R. I. (2007). Prediction of external events with our motor system: Towards a new framework. Trends in Cognitive Sciences, 11(5), 211–218.
Schultz, W. (1998). Predictive reward signal of dopamine neurons. Journal of Neurophysiology, 80, 1–27.

Stelmach, G., & Diggles, V. (1982). Control theories in motor behavior. Acta Psychologica, 50, 83–105.
Suddendorf, T., & Corballis, M. C. (2007). The evolution of foresight: What is mental time travel and is it unique to humans? Behavioral and Brain Sciences, 30(3), 299–313.
Synofzik, M., Thier, P., & Lindner, A. (2006). Movements depends on an adaptable prediction about the sensory action outcome. J Neurophysiology, 96, 1592–1601.
Tettamanti, M., Buccino, G., Saccuman, M. C., Gallese, V., Danna, M., Scifo, P., Fazio, F., Rizzolatti, G., Cappa, S. F., & Perani, D. (2005). Listening to action-related sentences activates frontoparietal motor circuits. Journal of Cognitive Neuroscience, 17(2), 273–281.
Tucker, M., & Ellis, R. (2004). Action priming by brieXy presented objects. Acta Psychologica, 116, 185–203.
Umiltà, M., Escola, L., Intskirveli, I., Grammont, F., Rochat, M., Caruana, F., Jezzini, A., Gallese, V., & Rizzolatti, G. (2008). How pliers become Wngers in the monkey motor system. Proceedings of the National Academy of Science, 105, 2209–2213.
von Helmholtz, H. (1867). Handbuch der physiologischen Optik. Leipzig: L. Voss.
von Hofsten, C. (2004). An action perspective on motor development. Trends in Cognitive Science, 8(6), 266–272.
von Holst, E., & Mittelstaedt, H. (1950). Das reaVerenzprinzip. Naturwissenschaften, 37:464–476.
Wilson, M., & Knoblich, G. (2005). The case for motor involvement in perceiving conspeciWcs. Psychological Bulletin, 131, 460–473.
Wohlschlager, A., Engbert, K., & Haggard, P. (2003a). Intentionality as a constituting condition for the own self-and other selves. Consciousness and Cognition, 12(4), 708–716.
Wohlschlager, A., Gattis, M., & Bekkering, H. (2003b). Action generation and action perception in imitation: An instance of the ideomotor principle. Philosophical Transactions of the Royal Society of London, 358, 501–515.
Wolpert, D. M., & Ghahramani, Z. (2004). Computational motor control. Science, 269, 1880–1882.
Wolpert, D. M., & Kawato, M. (1998). Multiple paired forward and inverse models for motor control. Neural Networks, 11(7–8), 1317–1329.
Wolpert, D. M., Doya, K., & Kawato, M. (2003). A unifying computational framework for motor control and social interaction. Philos Trans R Soc Lond B Biol Sci, 358(1431), 593–602.
Zacks, J. M., Speer, N. K., Swallow, K. M., Braver, T. S., & Reynolds, J. R. (2007). Event perception: A mind-brain perspective. Psychological Bulletin, 133(2), 273–293.

123

