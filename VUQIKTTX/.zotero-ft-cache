Available online at www.sciencedirect.com
ScienceDirect
Executive control and decision-making in the prefrontal cortex Philippe Domenech and Etienne Koechlin

The prefrontal cortex (PFC) subserves decision-making and executive control. Here we review recent empirical and modeling works with a focus on neuroimaging studies, which start unifying these two conceptual approaches of PFC function. We propose that the PFC comprises two arbitration systems: (1) a peripheral system comprising premotor/caudal PFC regions and orbitofrontal regions involved in the selection of actions based on perceptual cues and reward values, respectively, and embedded in behavioral sets associated with external contingencies inferred as being stable; (2) a core system comprising ventromedial, dorsomedial, lateral and polar PFC regions involved in superordinate probabilistic reasoning for arbitrating online between exploiting/adjusting previously learned behavioral sets and exploring/creating new ones for efÔ¨Åcient adaptive behavior in variable and open-ended environments.
Addresses Laboratoire de Neuroscience Cognitive, Ecole Normale Supe¬¥ rieure INSERM, Paris, France
Corresponding author: Koechlin, Etienne (etienne.koechlin@upmc.fr)
Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106 This review comes from a themed issue on Cognitive neuroscience Edited by Cindy Lustig and Howard Eichenbaum For a complete overview see the Issue and the Editorial Available online 25th October 2014 http://dx.doi.org/10.1016/j.cobeha.2014.10.007 2352-1546/# 2014 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/3.0/).
The prefrontal cortex is often described as subserving decision-making and executive control. Decision-making research focuses on the PFC function in action selection according to perceptual cues and reward values [1,2]. Executive control research focuses on the PFC function in learning and switching between behavioral rules or sets that guide action [1,3‚Äì10]. These two lines of research have often been carried out independently. Here we review recent Ô¨Åndings and outline a theoretical framework unifying these two conceptual approaches of PFC function.
From simple decisions to task sets There is converging evidence that the computation of expected rewards driving action selection primarily

involves the ventromedial PFC (vmPFC) [11‚Äì13]. The vmPFC, especially its ventral portion (often referred to as the medial orbitofrontal cortex), enables to convert distinct subjective reward scales into a ‚Äòcommon currency‚Äô scale for allowing value comparison [14‚Äì17] that drives selection. Reward values are generally associated with action outcomes rather than actions per se. Consistently, the vmPFC is involved in predicting action outcomes [18‚Äì21,22], suggesting that the vmPFC encodes actionoutcome associations for selecting actions according to reward values. By contrast, selecting actions according to perceptual cues involves the lateral premotor cortex [9,23‚Äì25]. However, when expected rewards and perceptual cues are not linked to speciÔ¨Åc actions, decisions are presumably made between more abstract action sets that may subsequently guide the selection of speciÔ¨Åc actions according to stimuli. In such situations, consistently, both reward-based and cue-based decisions engage the lateral prefrontal cortex (lPFC) [26,27], which subserves cognitive control, that is, the formation and selection of such action sets [3,9,23,24,28‚Äì32]. Importantly, abstract action sets spontaneously develop for controlling action selection even when their formation provides no immediate behavioral advantages [28,29]. Thus, lPFC activations often reported in simple choice tasks suggest that whenever possible, subjects build abstract action sets and primarily choose between these sets for subsequently selecting simple actions, especially in sequential decision tasks facilitating the formation of stable sets across trials.
Abstract action sets thus comprise multiple stimulusaction and (stimulus)-action-outcome associations, which are learned and continuously adjusted online for maximizing rewards. Computational modeling suggest that stimulus-action and (stimulus)-action-outcome associations are learned and adjusted through reinforcement and statistical learning respectively [33,34], while abstract action sets emerge through probabilistic clustering processes [29]. Collectively, these Ô¨Çexible representations invoked together for driving action selection while the same external situation perpetuates, constitute a consistent behavioral strategy also referred to as a task set (Figure 1).
Task sets and adaptive behavior Task sets are critical executive units for efÔ¨Åcient adaptive behavior in everyday environments featuring external situations that often change and may reoccur periodically

www.sciencedirect.com

Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106

102 Cognitive neuroscience

Figure 1 (a)

PM M

(b)
LPFC FPC S1 S2 S3

Task-Set i

Task-Set 1

Action-Set 1

A1

A1

O1

A2

A2

O2

A3

A3

O3

PreSMA dMPFC dACC
vmPFC mOFC

Action-Set n

S1

A1

A1

O1

S2

A2

A2

O2

S3

A3

A3

O3

Current Opinion in Behavioral Sciences
Prefrontal cortex and structures of executive representations. (A) The frontal lobes comprise the premotor (PM), lateral prefrontal (lPFC) and frontopolar (FPC) regions on the lateral side (top); on the medial side (bottom), the dorsomedial (dmPFC including the pre-SMA and dACC), the ventromedial (vmPFC) and orbitofrontal (mOFC) regions. (B) Task-sets are temporal abstraction including action sets which in turn comprise stimulus-action and action-outcome associations. Color matches across panels and illustrates the anatomical mapping of these executive representations.

and where new situations may always arise. Task sets are
formed and stored as mentally instantiating external
situations for possibly exploiting them when these situations reoccur [33]. This adaptive capacity requires
continuously arbitrating between exploiting/adjusting pre-
viously learned task sets vs. exploring/creating new ones.
The PFC has likely evolved to make this arbitration online [35]. The arbitration however is a complex prob-
abilistic reasoning problem, which optimal solution is actually computationally intractable [33]. Accordingly,
we recently proposed that the core PFC executive system

comprising the ventromedial, dorsomedial, lateral and frontopolar PFC regions has primarily evolved as implementing an approximate algorithmic solution to this problem [35]: the solution especially assumes that the executive system infers online the absolute reliability of the current task set driving ongoing behavior (i.e. the actor task set): this quantity measures the probability that given external evidence, this task set is still applicable to the situation or equivalently, that the situation remains unchanged (considering that the range of external situation is potentially inÔ¨Ånite). The concept of absolute

Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106

www.sciencedirect.com

Prefrontal executive control and decision-making Domenech and Koechlin 103

reliability generalizes the notion of expected/unexpected uncertainty [36] to open-ended environments and is related to the psychological notion of metacognition and conÔ¨Ådence [37].
The medial PFC: from exploitation to exploration We noted above that task sets comprise a forward model predicting action outcomes, and the vmPFC is likely to encode the forward model of the actor task set. fMRI studies further reveal that in reversal learning tasks, vmPFC activations vary with the probability that the current situation remains unchanged according to actual action outcomes [18]. Moreover, we recently observed that in conditions inducing subjects to build multiple task sets according to actual action outcomes, vmPFC activations (along with perigenual anterior cingulate activations) speciÔ¨Åcally correlate with the absolute reliability of the actor task set [38]. These results provide evidence that the vmPFC is speciÔ¨Åcally involved in inferring the actor task-set reliability according to the consistency between expected and actual action outcomes. In agreement with this hypothesis, vmPFC activations were also found to predict subjects‚Äô conÔ¨Ådence in making simple reward-based decisions [37] (Figure 2).
The notion of absolute reliability implies that task sets are inferred as being either reliable (i.e. more likely applicable
Figure 2

than non-applicable to the current situation) or unreliable (the converse) [33]. When the actor task set passes from the reliable to unreliable status, the current external situation has likely changed. Modeling and behavioral results show that in that event, subjects switch away from exploiting/adjusting the current actor set and start exploring by forming a new actor set built upon the collection of task sets stored in long-term memory [33,38]. fMRI results show that unlike the vmPFC, the dorsomedial PFC (dmPFC) comprising the dorsal anterior cingulate cortex (dACC) and the pre-supplementary motor area (pre-SMA) responds speciÔ¨Åcally to this algorithmic transition [38]. Consistently, neuronal recordings conÔ¨Årm that when animals switch from exploitation to exploration behaviors, neuronal ensembles in the dmPFC exhibit abrupt activity resetting [31,40,41]. Additional fMRI results in humans suggest that in foraging tasks, the dmPFC monitors the opportunity to switch from exploitation to exploration [42]. Altogether, these Ô¨Åndings suggest that while the vmPFC infers the actor absolute reliability from action outcomes, the dmPFC monitors the actor absolute reliability not only for regulating actor adjustments [39] but especially for detecting when the actor task set becomes unreliable and enforcing the switch from exploitation to exploration. This discrete, non-parametric transition consists of inhibiting the ongoing actor task set for creating a new actor task set driving behavior. According to electrophysiological recordings [43‚Äì45], the dACC may enforce the transition at the set level, while the pre-SMA may be involved in inhibiting its executive elements, that is, action sets and related stimulus-action associations.

From exploitation to exploration

From exploration to exploitation

Infers actor Task-Set Reliability vmPFC FPC

Infers alternative Task-Set Reliability

LPFC

Switch to alternative Task-Sets

Medial inference Track

Lateral inference Track

Switch away to
Task-Set creation

dmPFC

Action-Set selection PM

From a normative viewpoint, creating a new task set consists of mixing the task sets stored in long-term memory according to current external evidence and task-set internal models [33,35]: the new task set optimally reuses previous learned situations for driving behavior, when the actor task set becomes unreliable. Current empirical Ô¨Åndings suggest that this creation process involves the caudal LPFC and premotor cortex along with basal ganglia [23,38]. Newly created task sets driving behavior is initially inferred as being unreliable but through learning (see above), may subsequently become reliable. fMRI results show the latter event elicits ventral striatal along with premotor and caudal LPFC activations. These activations presumably reÔ¨Çect the consolidation of newly created task sets in long-term memory when they become reliable [38]. Exploration behaviors thus consist of creating and learning new task sets and perpetuate until the medial PFC infers these new task sets as becoming reliable.

Current Opinion in Behavioral Sciences
The PFC core executive system and probabilistic reasoning driving adaptive behavior. See text for details.

The lateral PFC: from exploration to exploitation
Behavioral results suggest that humans can infer the
absolute reliability of three or four task sets concurrently [33,38]: the current actor along with two or three

www.sciencedirect.com

Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106

104 Cognitive neuroscience

alternative task sets. The latter correspond to task sets previously inferred as being reliable and used as actor but no longer reliable. When subjects switch into exploration as described above, the former actor typically remains monitored as an alternative task set (which may be subsequently retrieved, see below). Several fMRI studies have pointed out the role of the lateral frontopolar PFC (FPC) in exploration [46‚Äì49]. Other fMRI studies show that the FPC is involved in holding on and monitoring alternative courses of action [19,20,50]. Recent results indicate that consistently, FPC activations more speciÔ¨Åcally correlate with the absolute reliability of two concurrent alternative task sets [38]. The FPC thus appears to keep track and infer the absolute reliability of a few alternative task sets, which notably occur during exploration periods (Figure 2).
Such alternative task sets make no contribution to ongoing behavior but may be subsequently retrieved for driving behavior [33,38]: As two task sets cannot be judged as being reliable simultaneously, any alternative task set becoming reliable is retrieved and replaces the current actor task set. This retrieval process enables the organism to switch out of exploration periods by rejecting newly created task sets. The retrieval process also enables exploration periods to be skipped by directly switching to an alternative task set, when the ongoing actor task set becomes unreliable. fMRI data show that consistent with its critical role in task-switching [12,24,51], the lPFC detects when one alternative taskset become reliable [38]: the lPFC presumably initiates the retrieval process that propagates from middle to caudal lPFC regions [38].
PFC functional architecture and adaptive behavior Altogether, these recent Ô¨Åndings suggest that the PFC comprises two parallel inferential tracks (Figure 2): (1) a medial track from the vmPFC to dmPFC arbitrating between exploiting/adjusting the current task set driving behavior vs. exploring/creating new task sets from longterm memory. While the vmPFC infers the reliability of the current actor task set in predicting action outcomes, the dmPFC detects when this task set becomes unreliable for inhibiting it and switching into exploration; (2) a lateral track from the FPC to lPFC arbitrating between exploring/learning new task sets vs. exploiting alternative task sets recently used as actor. While the FPC infers the reliability of these alternative task sets in predicting current action outcomes, the lPFC detects when one becomes reliable for retrieving it as actor. The lateral track thus enables to avoid switching or perseverating in exploration periods, when alternative behavioral strategies are judged as applicable to the current situation. Recent MRI-based anatomical studies [52,53,54] reveal that the human FPC region considered here has no equivalent in non-human primates, suggesting that this

adaptive faculty based on counterfactual inferences is unique to humans.
Our review outlines a theoretical framework, whereby simple choices primarily involve a ‚Äòperipheral‚Äô PFC system including the lateral premotor and medial orbitofrontal cortex. The latter drives the selection of motor responses in direct association with stimuli and expected rewards, respectively. The caudal lPFC has the capacity to abstract multiple stimulus-response and response-outcome associations into action sets. The caudal lPFC thus enables to collectively select multiple associations according to external cues and expected outcomes for carrying out behavioral plans. Action sets are associated with external situations perceived as featuring stable contingencies over time and mentally instantiated as discrete task sets. Task sets comprise action sets and constitute a temporal abstraction level aiming at efÔ¨Åcient adaptive behavior in everyday environments where external situations change and may reoccur periodically, and new situations may always arise. Accordingly, the ventromedial, dorsomedial, mid-lateral and frontopolar PFC form the core executive system inferring online the possible changes of situations and arbitrating between (1) adjusting and exploiting the current task set driving ongoing behavior, (2) switching to alternative task sets and (3) exploring/creating new ones.
Concluding remarks The notion of exploration is central to the framework outline here and consists of the deliberative, reversible decision to create a new task set. In contrast to the online reinforcement learning of task sets, task set creation is an ofÔ¨Çine, computationally costly process resetting the actor task set. The new actor task set is formed as the mixture of task sets stored in long-term memory based on external evidence according to task sets‚Äô internal models of external contingencies [35]. Interestingly, the ofÔ¨Çine creation vs. online learning of task sets corresponds to the theoretical distinction between model-based and model-free learning, respectively [34,56]. In model-based learning, indeed, action values are inferred from internal models of external contingencies while in model-free learning, action values are learned by interacting with the environment through reinforcement learning. A usual view is that both model-based and model-free reinforcement learning methods operate online concurrently, so that the continuous mixture of model-based and model-free action values drives behavior [34,56]. In the present view, however, task set creation occurs at speciÔ¨Åc time points when the actor task set that adjusts through reinforcement learning is inferred as becoming unreliable (and the alternative monitored task sets remain unreliable). Following its creation, the new actor task set is subsequently adjusted through reinforcement learning, so that the task sets driving behavior derives from intermittent, ofÔ¨Çine model-based creation that progressively and increasingly

Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106

www.sciencedirect.com

Prefrontal executive control and decision-making Domenech and Koechlin 105

incorporates online model-free learning. Both views account for empirical data suggesting that adaptive behavior forms a mixture of model-based and model-free adaptive processes [55]. The two views however differ in the way the two adaptive processes are combined over time. Disentangling these two theoretical views and understanding how the brain builds new task sets from those stored in long-term memory thus appear as central issues for future research.
ConÔ¨Çict of interest Nothing declared.
Acknowledgements
Supported by a European Research Council Grant to E.K. (ERC-2009-AdG #250106).
References and recommended reading
Papers of particular interest, published within the period of review, have been highlighted as:
 of special interest  of outstanding interest
1. Shadlen MN, Kiani R: Decision making as a window on cognition. Neuron 2013, 80:791-806.
2. Rushworth M, Noonan MP, Boorman ED, Walton ME: Frontal cortex and reward-guided learning and decision-making. Neuron 2011, 70:1054-1069.
3. Genovesio A, Wise SP, Passingham RE: Prefrontal-parietal function: from foraging to foresight. Trends Cogn Sci (Regul Ed) 2014, 18:72-81.
4. Kable JW, Glimcher PW: The neurobiology of decision: consensus and controversy. Neuron 2009:63.
5. Botvinick MM: Hierarchical reinforcement learning and decision making. Curr Opin Neurobiol 2012, 22:956-962.
6. Duncan J: The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour. Trends Cogn Sci (Regul Ed) 2010, 14:172-179.
7. Badre D: Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes. Trends Cogn Sci (Regul Ed) 2008, 12:193-200.
8. Sakai K: Task set and prefrontal cortex. Annu Rev Neurosci 2008, 31:219-245.
9. Koechlin E, SummerÔ¨Åeld C: An information theoretical approach to prefrontal executive function. Trends Cogn Sci (Regul Ed) 2007, 11:229-235.
10. Koechlin E, HyaÔ¨Ål A: Anterior prefrontal function and the limits of human decision-making. Science 2007, 318:594-598.
11. Clithero JA, Rangel A: Informatic parcellation of the network involved in the computation of subjective value. Social Cogn Affect Neurosci 2013:1-14 http://dx.doi.org/10.1093/scan/nst106.
12. Gla¬® scher J, Adolphs R, Damasio H, Bechara A, Rudrauf D, Calamia M, Paul LK, Tranel D: Lesion mapping of cognitive control and value-based decision making in the prefrontal cortex. Proc Natl Acad Sci USA 2012, 109:14681-14686.
13. Noonan MP, Walton ME, Behrens T, Sallet J, Buckley MJ, Rushworth M: Separate value comparison and learning mechanisms in macaque medial and lateral orbitofrontal cortex. Proc Natl Acad Sci USA 2010, 107:20547-20552.
14. McNamee D, Rangel A, O‚ÄôDoherty JP: Category-dependent and category-independent goal-value codes in human ventromedial prefrontal cortex. Nature Neurosci 2013, 16:479-485.

15. Strait CE, Blanchard TC, Hayden BY: Reward value comparison via mutual inhibition in ventromedial prefrontal cortex. Neuron 2014, 82:1357-1366.
16. Levy DJ, Glimcher PW: The root of all value: a neural common currency for choice. Curr Opin Neurobiol 2012, 22:1027-1038.
17. Barron HC, Dolan RJ, Behrens T: Online evaluation of novel choices by simultaneous representation of multiple memories. Nature Neurosci 2013, 16:1492-1498.
18. Hampton AN, Bossaerts P, O‚ÄôDoherty JP: The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J Neurosci 2006, 26:8360-8367.
19. Boorman ED, Woolrich MW, Rushworth M: How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action. Neuron 2009, 62:7333-7743.
20. Boorman ED, Rushworth M: Counterfactual choice and learning in a neural network centered on human lateral frontopolar cortex. PLoS Biol 2011, 9:e1001093.
21. Jones JL, Esber GR, McDannald MA, Gruber AJ, Hernandez A,  Mirenzi A, Schoenbaum G: Orbitofrontal cortex supports
behavior and learning using inferred but not cached values. Science 2012, 338:953-956. Adaptive behavior may depend upon cached values learned from direct experience, or inferred values computed online from internal forward models. To separate these two types of values, the authors Ô¨Årst trained rats to pair cues and then, associated rewards with one cue in some pairs (cached value). Rats exhibited similar conditioned behavior in response to reward-associated cues and reward-inferred cues. Infusing GABAergic agonists to inactivate OFC neurons disrupted conditioned responses only to reward-inferred cues. These Ô¨Åndings demonstrate that in rats, the OFC is required to infer values based on internal forward models.
22. Zhu L, Mathewson KE, Hsu M: Dissociable neural representations of reinforcement and belief prediction errors underlie strategic learning. Proc Natl Acad Sci USA 2012, 109:1419-1424.
23. Badre D, Kayser AS, D‚Äôesposito M: Frontal cortex and the discovery of abstract action rules. Neuron 2010, 66:315-326.
24. Azuar C, Reyes P, Slachevsky A, Volle E, Kinkingnehun S, Kouneiher F, Bravo E, Dubois B, Koechlin E, Levy R: Testing the model of caudo-rostral organization of cognitive control in the human with frontal lesions. Neuroimage 2014, 84:1053-1060.
25. Ding L, Gold JI: Neural correlates of perceptual decision making before, during, and after decision commitment in monkey frontal eye Ô¨Åeld. Cereb Cortex 2012, 22:1052-1067.
26. Cai X, Padoa-Schioppa C: Contributions of orbitofrontal and lateral prefrontal cortices to economic choice and the goodto-action transformation. Neuron 2014, 81:1140-1151.
27. Filimon F, Philiastides MG, Nelson JD, Kloosterman NA, Heekeren HR: How embodied is perceptual decision making? Evidence for separate processing of perceptual and motor decisions. J Neurosci 2013, 33:2121-2136.
28. Collins AGE, Cavanagh JF, Frank MJ: Human EEG uncovers latent generalizable rule structure during learning. J Neurosci 2014, 34:4677-4685.
29. Collins AGE, Frank MJ: Cognitive control over learning: creating, clustering, and generalizing task-set structure. Psychol Rev 2013, 120:190-229.
30. Stokes MG, Kusunoki M, Sigala N, Nili H, Gaffan D, Duncan J: Dynamic coding for cognitive control in prefrontal cortex. Neuron 2013, 78:364-375.
31. Durstewitz D, Vittoz NM, Floresco SB, Seamans JK: Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning. Neuron 2010, 66:438-448.
32. Buschman TJ, Denovellis EL, Diogo C, Bullock D, Miller EK: Synchronous oscillatory neural ensembles for rules in the prefrontal cortex. Neuron 2012, 76:838-846.
33. Collins AGE, Koechlin E: Reasoning, learning, and creativity  frontal lobe function and human decision-making. PLoS Biol
2012, 10:e1001293.

www.sciencedirect.com

Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106

106 Cognitive neuroscience

This study provides a detailed and comprehensive computational account of human adaptive behavior in variable and open-ended environments in terms of probabilistic reasoning, and its variations across individuals.
34. Doll BB, Simon DA, Daw ND: The ubiquity of model-based reinforcement learning. Curr Opin Neurobiol 2012, 22:1075-1081.
35. Koechlin E: An evolutionary computational theory of prefrontal  executive function in decision-making. Philos Trans R Soc
Lond, B: Biol Sci 2013, 369 http://dx.doi.org/10.1098/ rstb.2013.0474. The study describes the evolution of PFC function as the gradual addition of new inferential Bayesian capabilities from rodents to humans for dealing with a computationally intractable decision problem: exploring and learning new behavioral strategies vs. exploiting and adjusting previously learned ones through reinforcement learning.
36. Yu AJ, Dayan P: Uncertainty, neuromodulation, and attention. Neuron 2005, 46:681-692.
37. De Martino B, Fleming SM, Garrett N, Dolan RJ: ConÔ¨Ådence in value-based choice. Nat Neurosci 2013, 16:105-110.
38. Donoso M, Collins AGE, Koechlin E: Foundations of human  reasoning in the prefrontal cortex. Science 2014, 344:1481-1486. Using an algorithmic model of probabilistic reasoning describing how the human prefontal cortex drives adaptive behavior in uncertain and openended environments, this model-based fMRI study characterizes the algorithmic architecture of the prefrontal cortex, which is central to this review. The key Ô¨Åndings are that the anterior PFC monitors strategy absolute reliabilities along two concurrent inferential tracks in the PFC: (1) a ventro-medial to dorso-medial track arbitrating between exploiting/ adjusting the strategy in use vs. switching away for exploring/creating new behavioral strategies, and (2) a polar to lateral PFC track arbitrating between learning newly created strategies vs. exploiting alternative, previously learned strategies. The two tracks approximate optimal Bayesian solutions to the exploration-exploitation dilemma in open-ended environment by combining hypothesis-testing bearing upon newly created strategies, and probabilistic inference over monitored strategies.
39. Alexander WH, Brown JW: Medial prefrontal cortex as an  action-outcome predictor. Nat Neurosci 2011, 14:1338-1344. In the past decade, several competing accounts were proposed for medial PFC function. This study proposes a computational model unifying these accounts. The model assumes the medial PFC learns a forward model predicting the various outcomes associated with actions and tracks the discrepancies between expected and actual action outcomes. This simple model explains most empirical Ô¨Åndings supporting these previous accounts.
40. Karlsson MP, Tervo DGR, Karpova AY: Network resets in medial  prefrontal cortex mark the onset of behavioral uncertainty.
Science 2012, 338:135-139. Using an elegant variant of a probabilistic reversal learning task, this study shows abrupt transitions in rat medial PFC neural ensembles and phasic gamma-power peaks associated with switching away from exploitation behavior. These switches triggered exploration phases associated with the active resampling of environment contingencies.
41. Hayden BY, Pearson JM, Platt ML: Neuronal basis of sequential  foraging decisions in a patchy environment. Nat Neurosci 2011,
14:933-939. In this electrophysiology study, the authors developed an original virtual foraging task to study how monkeys decide to stop exploiting patches of resources to further explore their surrounding. They found that dACC neurons encoded the relative value of staying for exploiting the current

depleting patch, vs. switching away for exploring a new patch. This decision variable increased up to a threshold triggering exploration. These Ô¨Åndings reveal neuronal mechanisms in the dACC that trigger behavioral switches.
42. Kolling N, Mars RB, Rushworth M: Neural mechanisms of foraging. Science 2012, 336:95-98.
43. Bonini F, Burle B, Lie¬¥ geois-Chauvel C, Re¬¥ gis J, Chauvel P, Vidal F: Action monitoring and medial frontal cortex: leading role of supplementary motor area. Science 2014, 343:888-891.
44. Matsuzaka Y, Akiyama T, Tanji J, Mushiake H: Neuronal activity in the primate dorsomedial prefrontal cortex contributes to strategic selection of response tactics. Proc Natl Acad Sci USA 2012, 109:4633-4638.
45. Isoda M, Hikosaka O: Switching from automatic to controlled action by monkey medial frontal cortex. Nat Neurosci 2007, 10:240-248.
46. Daw ND, O‚ÄôDoherty JP, Dayan P, Seymour B, Dolan RJ: Cortical substrates for exploratory decisions in humans. Nature 2006, 441:876-879.
47. Cavanagh JF, Figueroa CM, Cohen MX, Frank MJ: Frontal theta reÔ¨Çects uncertainty and unexpectedness during exploration and exploitation. Cerebral Cortex 2012, 22:2575-2586.
48. Badre D, Doll BB, Long NM, Frank MJ: Rostrolateral prefrontal cortex and individual differences in uncertainty-driven exploration. Neuron 2012, 73:595-607.
49. Yoshida W, Ishii S: Resolution of uncertainty in prefrontal cortex. Neuron 2006, 50:781-789.
50. Charron S, Koechlin E: Divided representation of concurrent goals in the human frontal lobes. Science 2010, 328:360-363.
51. Badre D, Hoffman J, Cooney JW, D‚Äôesposito M: Hierarchical cognitive control deÔ¨Åcits following damage to the human frontal lobe. Nat Neurosci 2009, 12:515-522.
52. Sallet J, Mars RB, Noonan MP, Neubert F-X, Jbabdi S, O‚ÄôReilly JX, Filippini N, Thomas AG, Rushworth M: The organization of dorsal frontal cortex in humans and macaques. J Neurosci 2013, 33:12255-12274.
53. Koechlin E: Frontal pole function: what is speciÔ¨Åcally human? Trends Cogn Sci (Regul Ed) 2011, 15:241.
54. Neubert F-X, Mars RB, Thomas AG, Sallet J, Rushworth M:  Comparison of human ventral frontal cortex areas for
cognitive control and language with areas in monkey frontal cortex. Neuron 2014, 81:700-713. Using clustering techniques on anatomical and functional MRI connectivity data, this study characterizes homologies and discrepancies between human and monkey PFC regions. The authors especially found a lateral prefrontal region unique to humans in the frontal pole. See also ref. [52].
55. Daw ND, Gershman SJ, Seymour B, Dayan P, Dolan RJ: Modelbased inÔ¨Çuences on humans‚Äô choices and striatal prediction errors. Neuron 2011, 69:1204-1215.
56. Daw ND, Niv Y, Dayan P: Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control. Nat Neurosci 2005, 8:1704-1711.

Current Opinion in Behavioral Sciences 2015, 1:101‚Äì106

www.sciencedirect.com

