Title:          Navigation in Unknown Dynamic Environments Based on Deep Reinforcement Learning
Subject:        In this paper, we propose a novel Deep Reinforcement Learning (DRL) algorithm which can navigate non-holonomic robots with continuous control in an unknown dynamic environment with moving obstacles. We call the approach MK-A3C (Memory and Knowledge-based Asynchronous Advantage Actor-Critic) for short. As its first component, MK-A3C builds a GRU-based memory neural network to enhance the robot's capability for temporal reasoning. Robots without it tend to suffer from a lack of rationality in face of incomplete and noisy estimations for complex environments. Additionally, robots with certain memory ability endowed by MK-A3C can avoid local minima traps by estimating the environmental model. Secondly, MK-A3C combines the domain knowledge-based reward function and the transfer learning-based training task architecture, which can solve the non-convergence policies problems caused by sparse reward. These improvements of MK-A3C can efficiently navigate robots in unknown dynamic environments, and satisfy kinetic constraints while handling moving objects. Simulation experiments show that compared with existing methods, MK-A3C can realize successful robotic navigation in unknown and challenging environments by outputting continuous acceleration commands.
Keywords:       autonomous navigation; unknown environments; deep reinforcement learning; continuous control
Author:         Junjie Zeng, Rusheng Ju, Long Qin, Yue Hu, Quanjun Yin and Cong Hu
Creator:        LaTeX with hyperref package
Producer:       pdfTeX-1.40.18
CreationDate:   09/05/19 17:04:00
ModDate:        09/05/19 17:04:00
Tagged:         no
Form:           none
Pages:          18
Encrypted:      no
Page size:      595.276 x 841.89 pts (A4) (rotated 0 degrees)
File size:      1917096 bytes
Optimized:      no
PDF version:    1.5
