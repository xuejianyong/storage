Neuron
Review

The Expected Value of Control: An Integrative Theory of Anterior Cingulate Cortex Function

Amitai Shenhav,1 Matthew M. Botvinick,1 and Jonathan D. Cohen1,* 1Princeton Neuroscience Institute and Department of Psychology, Princeton University, Princeton, NJ 08540, USA *Correspondence: jdc@princeton.edu http://dx.doi.org/10.1016/j.neuron.2013.07.007

The dorsal anterior cingulate cortex (dACC) has a near-ubiquitous presence in the neuroscience of cognitive control. It has been implicated in a diversity of functions, from reward processing and performance monitoring to the execution of control and action selection. Here, we propose that this diversity can be understood in terms of a single underlying function: allocation of control based on an evaluation of the expected value of control (EVC). We present a normative model of EVC that integrates three critical factors: the expected payoff from a controlled process, the amount of control that must be invested to achieve that payoff, and the cost in terms of cognitive effort. We propose that dACC integrates this information, using it to determine whether, where and how much control to allocate. We then consider how the EVC model can explain the diverse array of ﬁndings concerning dACC function.

The dorsal anterior cingulate cortex (dACC), spanning the cingulate gyrus and sulcus from the plane of the anterior commissure to the genu of the corpus callosum (Figure 1), is one of the most heavily studied regions of the brain and yet remains one of the least clearly understood. Although there has recently been an explosion of research on the role of dACC in cognition and behavior, this has led to a proliferation of diverging theories concerning its function. The dACC has been proposed to play a key role in pain processing, performance monitoring, value encoding, decision making, emotion, learning, and motivation. A precise and coherent account of dACC function seems as elusive now as it did in the earliest days of theory development.
Two opposing tendencies appear to have slowed progress toward an integrated understanding of dACC function. One has been to base theoretical analyses on too narrow a subset of empirical ﬁndings, while another has been to embrace a wide range of empirical ﬁndings but to reduce them to a single basic computation at the cost of oversimplifying dACC function. Here, we propose an integrative account of dACC function that strives to avoid these pitfalls.
We build on one observation which appears to be widely and consistently agreed upon: that dACC is engaged by tasks that demand cognitive control. Broadly, this can be deﬁned as the set of mechanisms required to pursue a goal, especially when distraction and/or strong (e.g., habitual) competing responses must be overcome. Numerous meta-analyses of the neuroimaging literature have conﬁrmed the dACC’s involvement in controldemanding tasks (Nee et al., 2007; Niendam et al., 2012; Ridderinkhof et al., 2004; Shackman et al., 2011), and these have been supplemented by evidence of a causal relationship between dACC and cognitive control. For instance, using diffusion tensor imaging (DTI), Metzler-Baddeley and colleagues (2012) showed that older adults with lower white matter integrity in the anterior cingulum bundle (the white matter bundle projecting to/from dACC) performed more poorly on control-demanding tasks.
Despite the strong consensus that dACC is involved in cognitive control, there is little agreement about the speciﬁc func-

tion(s) it subserves. Here, we synthesize a number of existing proposals concerning the role of dACC into a single theoretical account and show how this can be reconciled with empirical ﬁndings concerning dACC function. Speciﬁcally, we propose that the dACC integrates information about the reward and costs that can be expected from a control-demanding task, in order to estimate a quantity we refer to as the expected value of control (EVC). Put simply, EVC represents the net value associated with allocating control to a given task. We propose that dACC estimates this quantity in order to determine whether it is worth investing control in a task, how much should be invested and, when several potential tasks are in contention, which is the most worthwhile. We assume that this information is used to select among competing tasks and allocate the appropriate amount of control to performance of the one selected. This proposal ascribes to dACC a speciﬁc decision making function regarding the allocation of control that is distinct from other control-related functions, such as the valuative ones that provide input to the decision and the regulative ones responsible for executing it; these are presumed to be subserved by other neural mechanisms.
We begin by establishing some foundational points concerning cognitive control and its constituent functions that are necessary for framing the EVC theory and our consideration of dACC. We then introduce the basic elements of the EVC theory. Finally, we review key ﬁndings and existing theoretical proposals from the dACC literature, relating these to the EVC theory.
The Computational Basis of Cognitive Control Processes that demand control are often distinguished from automatic processes, which involve associations that are sufﬁciently strong as to be resistant to distraction or interference (Botvinick and Cohen, 2013; Cohen et al., 1990; Norman and Shallice, 1986; Posner and Snyder, 1975; Shiffrin and Schneider, 1977). A classic illustration of the distinction between controlled and automatic processing is provided by the Stroop task. Participants are shown a color word and asked to name the color of the

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 217

Neuron
Review

Figure 1. Anatomy and Connectivity of the Dorsal Anterior Cingulate Cortex (dACC) (A and B) Cytoarchitectonic subdivisions of human (A) and macaque (B) medial prefrontal cortices. The cingulate sulcus (cgs) has been opened up in both. dACC typically refers to areas 24a–d and the dorsal extent of area 32 (320 in A, 32(s) in B). Panel (A) focuses speciﬁcally on paracingulate regions of the medial surface, and the color-coding reﬂects Vogt et al. (2004) four-region model. The region referred to as human dACC throughout the main text is the anterior portion of midcingulate cortex (aMCC), encompassing an area Picard and Strick (1996) referred to as the rostral cingulate zone (RCZ). (C) Cortical projections to regions of dACC (left; areas 24a–b in yellow, areas 24c–d in orange) and more posterior regions of dorsomedial PFC (right; supplementary and primary motor cortices in pink and purple, respectively) in the macaque (cf. panel B). Relative to the more posterior regions, projections to dACC are much more widespread and include regions of orbital and rostrolateral PFC, temporal and parietal cortices, and insula. (D and E) Patterns of resting-state functional connectivity estimated in human (D) and macaque (E) brains using fMRI. The colors in panel (D) label seven networks within which activity between the regions (of a given color) is highly correlated at rest. Under this parcellation scheme, regions of dACC span the frontoparietal network (orange; often referred to as the ‘‘control’’ network) and the ventral attention network (violet). (E) Parcellation of resting-state connectivity networks focused on the connectivity of cingulate cortex regions-of-interest with the rest of the brain. Patterns of connectivity for the ‘‘executive’’ network (shown in red) and the ‘‘attention-orienting’’ network (dark blue), particularly within lateral PFC, suggest potential homologs with human frontoparietal and ventral attention networks. However, exact boundaries and homologies between dACC across species remain ambiguous (see, e.g., Cole et al., 2009). (A) Reprinted from Palomero-Gallagher et al. (2009) by permission of John Wiley and Sons; (B) and (C) reprinted from Morecraft et al. (2012), copyright (2012), modiﬁed with permission from Elsevier; (D) cortical and striatal connectivity reprinted from Yeo et al. (2011) and Choi et al. (2012), respectively, with permission from The American Physiological Society; (E) reprinted from Hutchison et al. (2012), by permission of Oxford University Press.

font in which it is displayed. When the two dimensions disagree (e.g., ‘‘GREEN’’ written in red text), participants ﬁnd it harder to name the color than when the two agree (e.g., ‘‘RED’’ written in red text). However, this interference effect does not occur when the task is, instead, to simply read the word. This difference between task conditions is explained by assuming that word reading is automatic (allowing the word to be processed even when the task is color naming), whereas color naming is controlled (preventing the color from being processed unless the task is to do so). This explanation is reinforced by the observation that, when presented with a conﬂict stimulus in the

absence of a speciﬁc task instruction, people invariably read the word, illustrating the automatic, or ‘‘default,’’ nature of verbal responses to words. Verbally responding to the color requires an instruction and/or intention to do so, at least in the presence of conﬂicting word information. A Simple Model of Cognitive Control A computational model of the mechanisms underlying the Stroop task is shown in Figure 2A (Cohen et al., 1990). The model takes the form of a neural network, with units encoding stimulus features projecting forward to intermediate (associative) units, and then to output units representing verbal responses. The

218 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Figure 2. The Expected Value of Control (EVC) model applied to the Stroop task (A) A model of the Stroop task illustrating the three major components of cognitive control: speciﬁcation, regulation, and monitoring. Thickness of the connections indicate the strength of the pathway, and size of the units denotes the amplitude of the signal along each processing pathway. The ﬁgure also illustrates how the model can be extended to include conﬂict monitoring that, in turn, can be used to specify the strength of the control signal needed to support processing in the task-relevant pathway. Note that the model ascribes to dACC roles in monitoring and speciﬁcation, and to the lPFC a role in regulation. (B) The EVC model. Control signal speciﬁcation involves choosing a control signal that maximizes EVC. For illustration, we diagram here the dimensions of speciﬁcation relevant to performing the Stroop color-naming task (illustrated in A). The objective is to select a control signal that maximizes the EVC. This, in turn, requires comparison of signals that differ in their identity (here, activation of the word-reading versus color-naming control units) and their intensity (represented in the ﬁgure by meters). In both cases, the EVC estimation takes into account both the costs of each candidate signal and its expected payoffs and expected outcomes (arrow weights indicate transition probabilities). Although identity and intensity are segregated here for the purposes of illustration, they are fully integrated in the EVC estimation as speciﬁed in Equation 1 and likely reﬂect the operation of a common set of mechanisms (see ‘‘Default Override’’ section). Moreover, unlike specifying the intensity of a given control signal (right), the process of specifying control signal identities (left) does not require mutual exclusivity (i.e., multiple control signal identity-intensity pairings can be simultaneously speciﬁed as a single array).

automaticity of the response to words is captured by strong connection weights along the pathway from word identity to verbal response. These also make it the default response (i.e., the response generated in the absence of any instruction). However, without any additional apparatus, the model would not be able to respond to the color of a conﬂict stimulus. To address this, the model also includes a set of control units that represent the current task. When the unit representing the color naming task is active, this provides top-down support for units in the pathway from color to verbal response, priming these units and thereby permitting a response to the color even when there is conﬂicting information arriving along the word pathway. Thus, in this context, color naming can be considered to be a controlled process to the extent that a correct response to the color depends on activation of the color naming task unit.
The model shown in Figure 2A also includes a unit that serves a ‘‘conﬂict monitoring’’ function, responding to coactivation of the network’s response units (see Botvinick et al., 2001). Such conﬂict is an indicator of inadequate control. For example, if the color naming task unit is insufﬁciently activated, then activation of the response to the color will be weaker and compete less effectively with activation of the response to a conﬂicting word, allow-

ing the latter to become more active. This coactivation will have two potentially adverse consequences for behavior. At best it will slow responding, since the correct response unit must overcome inhibitory competition from the incorrect one. At worst it will produce an error. These dangers can be ameliorated by increasing the activity of the color naming task unit. Thus, conﬂict serves as an indicator of the need for additional allocation of control. Three Component Functions of Cognitive Control This simple model of the Stroop task and conﬂict monitoring is of course not intended as a comprehensive model of cognitive control. However, the architecture of the model illustrates three core component functions of cognitive control (Figure 2A).
Regulation. The sine qua non feature of control is its capacity to govern or inﬂuence lower level information-processing mechanisms, a function we refer to as regulation. In the language of engineering, activity of a task unit represents a control signal, which determines the parameters for more basic processes (in this case, the sensitivity of the associative units in the corresponding pathway). Note that this signal has two deﬁning characteristics: its identity and its intensity (the strength of the signal, both in literal terms—e.g., level of activation of the task unit—and in terms of its impact on information processing). Control signals

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 219

Neuron
Review

can determine a wide range of processing parameters, including thresholds and/or biases for responding (governing speed-accuracy tradeoffs; Bogacz et al., 2006; Wiecki and Frank, 2013), templates for attention or memory search (Desimone and Duncan, 1995; Olivers et al., 2011; Polyn et al., 2009), and modulators of emotion (Johns et al., 2008; McClure et al., 2006). In each case, a distinction can be made between signal identity (the parameter targeted) and signal intensity (the degree to which the parameter is displaced from its default value).
Speciﬁcation. In order for regulation to occur, a critical step is for an appropriate control signal to be chosen: Control requires a decision on which, if any, controlled task(s) should be undertaken, and on how intensively it (or they) should be pursued. We refer to this decision-making function as control signal speciﬁcation, which must determine the identity and intensity of the desired control signal(s). In principle, it is possible to specify more than one identity-intensity pairing, and thereby more than one task (see Figure 2). However, in practice there are strict capacity constraints on control, and thus in this Review we focus on the simplest and most common circumstance, involving speciﬁcation of a single identity-intensity pairing (i.e., a single control demanding task). Importantly, control signal speciﬁcation should be distinguished from regulation which consists of implementing the speciﬁed control signal so as to actually effect the changes in information processing required for the task. This distinction between speciﬁcation (the decision process) and regulation (that mediates its effects) is central to the EVC theory. While both are essential components of the control system, the EVC theory ascribes to dACC a role in speciﬁcation but not regulation, as we discuss below.
Monitoring. In order to specify the appropriate control signal and deploy regulative functions in an adaptive manner, the system must have access to information about current circumstances and how well it is serving task demands. Detecting and evaluating these requires a monitoring mechanism. The conﬂict-detection component in the Stroop model provides one example of such a monitoring function and how it can guide speciﬁcation: the occurrence of response conﬂict indicates that insufﬁcient control is being allocated to the current task (see Botvinick, 2007; Botvinick et al., 2001, 2004). In this instance, conﬂict indicates the need to re-specify control signal intensity. However, conﬂict is just one among many signals that can indicate the need to adjust intensity. Others include response delays, errors, negative feedback, and the sensation of pain. These signals all carry information about performance within a task and how to specify control signal intensity. Monitoring must also consider information relevant to the speciﬁcation of control signal identity; that is, to task choice. Such information can come from external sources (e.g., explicit instructions, cues indicating new opportunities for reward, or the sudden appearance of a threat) or internal ones (e.g., diminishing payoffs from the current task indicating it is no longer worth performing, recollection of another task that needs to be performed, etc.). In all of these cases, monitoring must be responsive to, but should be distinguished from, the sensory and valuative processes that represent the actual information relevant to speciﬁcation. Thus, just as we distinguish between speciﬁcation and regulation on the efferent side of control, we distinguish between monitoring and valuation on

the afferent side. In each case, the EVC theory ascribes to dACC a role in the former, but not the latter. Optimization, Motivation, and the Cost of Cognitive Control Early research on control focused on regulative and monitoring mechanisms, but growing attention is being paid to the problem of control-signal speciﬁcation. Work in this area has been driven increasingly by ideas from research on reward-based decision making and reinforcement learning. One emerging trend has involved reframing control-signal speciﬁcation as an optimization problem, shaped by learning or planning mechanisms that serve to maximize long-term expected reward (Bogacz et al., 2006; Dayan, 2012; Hazy et al., 2007; O’Reilly and Frank, 2006; Todd et al., 2008; Yu et al., 2009). Under this view, cognitive control can be deﬁned as the set of mechanisms responsible for conﬁguring behavior in order to maximize the attainment of reward. This deﬁnition accords well with the deﬁnition of control in other ﬁelds, most notably control theory in engineering. From this perspective, cognitive control can be viewed not only as adaptive, but also as motivated.
An emphasis on motivation also aligns with the ubiquitous observation that the exertion of cognitive control carries an inherent subjective cost. From the earliest deﬁnitions, controlled processing was described as effortful, and like physical effort, mental effort is assumed to carry intrinsic disutility. That is, people spontaneously seek to minimize it. Recent empirical work bears out this assumption, linking effort speciﬁcally to the exertion of cognitive control (Kool and Botvinick, 2012; Kool et al., 2010). Human decision makers show a bias against tasks demanding topdown control, and within certain bounds they will delay task goals or even forego reward in order to avoid such tasks (Dixon and Christoff, 2012; Kool et al., 2010; Westbrook et al., 2013). These effects imply an intrinsic ‘‘cost of control,’’ which scales with the intensity of the control required to perform the task (Dixon and Christoff, 2012; Kool et al., 2010). These ideas, combined with the idea that control signals are speciﬁed based on the reward potential of the task they support, suggest that the allocation of control is driven by a cost-beneﬁt analysis, weighing potential payoffs against attendant costs, including those inherently associated with the exertion of control itself. The Neural Substrates of Cognitive Control Previous work has established links between components of the Stroop model and speciﬁc neural structures involved in cognitive control. In particular, lateral prefrontal cortex (lPFC) together with associated structures (e.g., basal ganglia and brainstem dopaminergic nuclei) have been proposed to implement the regulative component of the model (Braver and Cohen, 2000; Cohen and Servan-Schreiber, 1992; Frank et al., 2001; Miller and Cohen, 2001), while dACC has been proposed to implement the monitoring component (Botvinick, 2007; Botvinick et al., 2001; Botvinick et al., 2004). According to this mapping, the key step of control-signal speciﬁcation arises in the communication from dACC to lPFC (Botvinick et al., 2001; Kerns et al., 2004). That is, the model assigns to the dACC responsibility for monitoring and speciﬁcation, evaluating current demands for control and using the relevant information to decide how to allocate control. The speciﬁed control signals are then implemented by lPFC and associated structures, which are assumed to be responsible for

220 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

the regulative function of control—that is, actually effecting the changes in processing required to perform the task. The EVC model elaborates this proposal, structuring it in a normative description of how both the identity and the intensity of control signals are determined and placing new emphasis on optimization (i.e., reward maximization) in understanding the relationship, within dACC, between monitoring and speciﬁcation.

Control-Signal Speciﬁcation Based on the Expected

Value of Control

The operation of cognitive control, as we have characterized it, in-

volves deciding what control signal should be selected (i.e., its

identity) and how vigorously this control signal should be engaged

(i.e., its intensity) (Figure 2B). We propose that the brain makes this

two-part decision in a rational or normative manner to maximize

expected future reward. To make this idea precise, we will ex-

press the choice of what and how much to control in formal terms,

borrowing approaches from reinforcement learning and optimal

control theory to analogous problems of motor action selection.

We begin by deﬁning a control signal to be an array variable

with two components: identity (e.g., ‘‘respond to color’’ or

‘‘respond to word’’) and intensity. Determining the expected

value of each control signal requires integration over two sources

of value-related information. First, it must consider the overall

payoff that can be expected from engaging a given control

signal, taking into account both positive and negative outcomes

that could result from performing the corresponding task. Sec-

ond, as discussed above, it must take into account the fact

that there is an intrinsic cost to engaging control itself, which

scales with the intensity of the signal required. Taken together,

these two components determine what we will refer to as the ex-

pected value of control (EVC), which can be formalized as follows

(see also Figures 2B, 4A, and 4B):

" X
EVCðsignal; stateÞ = Prðoutcomeijsignal; stateÞ

i

#

, ValueðoutcomeiÞ À CostðsignalÞ

where ImmediateReward can be either positive or negative (for example, in the case of an error, monetary loss or pain; the term ‘‘reward’’ is borrowed from reinforcement learning models but can be understood more colloquially as ‘‘worth’’). Note that the maximization of EVC in the ﬁnal term is over all feasible control signals (indexed by i), with outcome serving in place of the current state. The estimation of outcome value thus folds in the EVC of control signals implemented in future states. The parameter g is a discount factor, between zero and one, controlling how much the current decision weighs future rewards relative to more immediate ones. The signiﬁcance of this ﬁnal term is that it links outcome value (and thus the EVC) not only to immediate reward, but also to predictable future events and their associated reward.
The ﬁnal term in Equation 1 captures the intrinsic cost of control, which is presumed to be a monotonic function of control-signal intensity (although for a richer model, see Kool and Botvinick, 2012). In sum, Equation 1 says that the EVC of any candidate control signal is the sum of its anticipated payoffs (weighted by their respective probabilities) minus the inherent cost of the signal (a function of its intensity).
Control-signal speciﬁcation involves the identiﬁcation of a combination of signal identity and intensity (or set of these, as noted above) that will yield the greatest value. We propose that the control system accomplishes this by comparing the EVC across a set of candidate control signals, and seeking the optimum:

signalÃ)maxi½EVCðsignali; stateÞ

(Equation 3)

Once it has been speciﬁed, the optimal control signal (signal*) is implemented and maintained by mechanisms responsible for the regulative component of control, which guide information processing in the service of task performance. This continues until a change in the current state—detected through monitoring—indicates that the previously speciﬁed control signal is no longer optimal (either in terms of identity or intensity), and a new signal* should be speciﬁed.

(Equation 1)
As indicated by the arguments on the left-hand side, the EVC is a function of two variables, signal and state. Signal refers to a speciﬁc control signal (e.g., designating a particular task representation and its intensity). State refers to the current situation, spanning both environmental conditions and internal factors (e.g., motivational state, task difﬁculty, etc.). On the right-hand side, outcomes refer to subsequent states that result from the application of a particular control signal in the context of the current state, each with a particular probability (Pr); for example, the occurrence of a correct response or of an error. Since outcomes are themselves states, the terms ‘‘state’’ and ‘‘outcome’’ in Equation 1 can also be thought of as ‘‘current state’’ and ‘‘future state.’’ The Value of an outcome is deﬁned recursively as follows:
ValueðoutcomeÞ = ImmediateRewardðoutcomeÞ + gmaxi½EVCðsignali; outcomeÞ (Equation 2)

An EVC Model of Dorsal Anterior Cingulate Function Drawing upon the theoretical constructs laid out above, we suggest that dACC function can be understood in terms of monitoring and control-signal speciﬁcation. Speciﬁcally, we propose that the dACC monitors control-relevant information, using this to estimate the EVC of candidate control signals, selecting an optimum from among these, and outputting the result to other structures that are directly responsible for the regulative function of control (such as lPFC). Critically, we propose that the dACC’s output serves to specify both the identity and intensity dimensions of the optimal control signal. Thus, the dACC inﬂuences both the speciﬁc content of control (e.g., what tasks should be performed or parameters should be adjusted) and also, by way of intensity, the balance between controlled and automatic processing, taking into account the inherent cost of a control signal of the speciﬁed intensity.
The EVC model shares elements both with our own and other theories concerning the mechanisms underlying cognitive control and action selection, as we shall emphasize. The value of

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 221

Neuron
Review

the EVC model lies not in the novelty of its individual ingredients, but in its explicit formalization of these ingredients in a way that allows for their integration within a single coherent framework. The theory helps synthesize central concepts in theories of cognitive control—the distinction between controlled and automatic processing, and the relationship between the monitoring and speciﬁcation functions of control, the relevance of both identity and intensity in control signal speciﬁcation, and the costs of control—into an overarching account that is mechanistically explicit, computationally coherent, and that does justice to the wide array of ﬁndings that have been reported concerning dACC function.
Monitoring Functions of the dACC: Supporting the Calculation of EVC Estimates of EVC require two key pieces of information: the current state (i.e., information concerning current task demands, processing capacity, and motivational state) and the value of potential outcomes that may occur given each candidate control signal, taking into account their likelihood of occurrence and anticipated worth.
The EVC model proposes that dACC monitors such presentstate and outcome-value information, garnered from other regions (such as orbitofrontal, ventromedial prefrontal, and insular cortex), as a basis for computing and maximizing the EVC. A range of empirical evidence is consistent with the idea that dACC is responsive to each of these two types of information. dACC and the Monitoring of State Information Computing the intensity and the identity of the optimal control signal requires different types of information about present state. For example, the presence of conﬂict may indicate the need to increase the intensity of the control signal, whereas an unexpected environmental cue may indicate the need to change the identity of the control signal (e.g., to perform a more rewarding task). The evidence strongly suggests that dACC is sensitive to state information that serves both of these needs.
State information relevant to control signal intensity: conﬂict monitoring. As noted above, conﬂict can provide important information about the demands of the current task and the intensity of control that should be allocated. Increasing control intensity will generally improve performance. However, specifying the optimal control-signal must also take into account the cost of control, which also increases with intensity (Equation 1). That is, control signals should be just strong enough to accomplish task objectives but no stronger (Figure 4). Given this, it is critical to determine the control demands of a task. Explicit outcomes provide one source of such information (e.g., feedback concerning performance); however, such information is not always available. Conﬂicts that arise during processing represent a source of internally available information useful for this purpose. As illustrated by the Stroop model, conﬂict during processing can provide an indication of the need to allocate additional control, much as an overt error would do. In fact, conﬂict can sometimes serve as an earlier, and potentially more sensitive, signal of the need for control than explicit error feedback (Yeung et al., 2004).
Both empirical and computational modeling work strongly support the role of dACC in conﬂict monitoring. The ﬁrst imaging study of the Stroop task (Pardo et al., 1990) reported dACC

activity in response to conﬂict stimuli. A number of subsequent studies provided additional evidence that dACC activity is speciﬁcally associated with the presence of conﬂict in processing (Carter et al., 1998, 2000) and that it can be dissociated from the regulative functions of control (Botvinick et al., 1999; Egner and Hirsch, 2005a, 2005b; Kerns, 2006; Kerns et al., 2004; MacDonald et al., 2000; however, see Figure 3 and the section ‘‘Interactions with lPFC and Subcortical Structures Involved in Regulation’’). These studies focused on tasks that involved conﬂict among competing responses, using classic paradigms such as the Stroop task, Simon task, and Eriksen ﬂanker task (see meta-analyses in Laird et al., 2005; Nee et al., 2007; Ridderinkhof et al., 2004). However, subsequent studies have extended the association between dACC and conﬂict processing to a much wider range of tasks, showing that it is also sensitive to conﬂicts that arise in perceptual discriminations (Ho et al., 2009; Krebs et al., 2012; Woolgar et al., 2011), language processing (Barch et al., 2000; Snyder et al., 2011), value-based decisions (Blair et al., 2006; Marsh et al., 2007; Pochon et al., 2008), moral judgments (Greene et al., 2004), social judgment (Cunningham et al., 2004), memory retrieval (Guerin and Miller, 2011), and strategy selection (Venkatraman et al., 2009).
The majority of evidence linking dACC to conﬂict monitoring has come from human neuroimaging studies. However, two recent studies have used direct neuronal recordings to test this relationship. In one study (Sheth et al., 2012), patients awaiting cingulotomy performed a Stroop-like interference task. fMRI identiﬁed conﬂict-related activity in a dACC region targeted for surgical resection. During the surgery itself, single-unit recording within the same region revealed ﬁring-rate responses to conﬂict, providing unusually direct evidence for dACC involvement in conﬂict monitoring (Figure 3).
Another study provided evidence for neuronal responses to conﬂict in the macaque (Amemori and Graybiel, 2012). In this experiment, monkeys made choices between receiving a small reward or a larger one paired with an aversive stimulus (air puff to the eye). Neuronal responses in pregenual ACC—a region potentially homologous to conﬂict-associated regions of human dACC (see Figure 1E; Hutchison et al., 2012)—tracked the subjective similarity of a given set of option values (and thus decision conﬂict). Variation in decision conﬂict accounted for variance in the ﬁring rate of neurons in this area independently of reward, air puff magnitude, overall expected utility, or response time.
Computational modeling work has provided convergent support for the idea that dACC activity is responsive to the degree of conﬂict elicited by the task (Botvinick et al., 2001). Models of conﬂict monitoring have accounted not only for task conditions that elicit dACC activity, but also the dynamics of that activity (Cockburn and Frank, 2011; Yeung et al., 2004).
The idea that conﬂict monitoring provides an internal index of task difﬁculty is also consistent with the ubiquitous observation that dACC activity is closely associated with the cognitive demands of a task (Botvinick, 2007; Duncan, 2010; Nachev et al., 2007; Paus et al., 1998; Venkatraman and Huettel, 2012). This includes demands that are increased by responses that are sequential or depend on complex rule structure versus simple and isolated ones (e.g., Kouneiher et al., 2009; Shima and Tanji, 1998); novel versus familiar or habitual responses (e.g.,

222 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Figure 3. The Relationship of Conﬂict Adaptation Effects in Human dACC to Control Monitoring versus Speciﬁcation (A) Measuring from single units in human dACC, Sheth et al. (2012) found a parametric effect of current trial conﬂict (example neuron shown), an effect that has been widely reported in neuroimaging studies (see ‘‘dACC and the Monitoring of State Information’’ section). Left and right sides of this ﬁgure plot ﬁring rate changes aligned to stimulus and response onsets, respectively. Note that this effect alone can be indicative of either monitoring of demands and/or speciﬁcation of different intensities of control accordingly. (B) Left: this group also found evidence of conﬂict adaptation (Gratton et al., 1992), with high-conﬂict (incongruent) trials requiring greater control, and therefore exhibiting longer RTs, when following a low-conﬂict (congruent) trial (cI) than when following another incongruent trial (iI). Right: this behavioral effect was abolished after these individuals underwent cingulotomy. (C) Previous fMRI studies have tied sequential adjustment effects to a particular pattern of responses in dACC: greater activity on cI than iI trials. This pattern has been observed in numerous experiments using different tasks and manipulations, including Botvinick et al., 1999 (left), Carter et al., 2000 (center), and Kerns et al., 2004 (right). It has been interpreted as reﬂecting a monitoring function, since greater dACC activity was observed under conditions of high conﬂict but low control. (D) Strikingly, single unit recording data from Sheth et al. (2012) show the opposite pattern, with higher ﬁring rates on iI than cI trials, a pattern consistent with control-signal speciﬁcation. The presence of both monitoring and speciﬁcation signals in dACC is consistent with the EVC theory. Determining why one function manifests in fMRI and the other in single-unit recording presents an important challenge for further research, and the EVC model may be of use in guiding such investigations. (A), (B), and (D) reprinted by permission from Macmillan Publishers Ltd: Nature, Sheth et al. (2012), copyright (2012). (C) (Left) reprinted by permission from Macmillan Publishers Ltd: Nature, Botvinick et al. (1999), copyright (1999); (center) from Carter et al. (2000), copyright (2000) National Academy of Sciences, USA; (right) from Kerns et al. (2004), with permission from AAAS.

Procyk et al., 2000); larger versus smaller option sets (e.g., Barch et al., 2000; Marsh et al., 2007; Snyder et al., 2011); the accumulation of evidence over the course of making a decision (e.g., Gluth et al., 2012; Landmann et al., 2007); or the requirement for internally generated responses versus externally cued/

guided ones (e.g., Fleming et al., 2012; Shima and Tanji, 1998; Walton et al., 2004).
Despite the wealth of evidence that dACC is responsive to conﬂicts in processing, this idea has not been without controversy (Cole et al., 2009; Ito et al., 2003; Mansouri et al.,

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 223

Neuron
Review

2009; Nachev, 2011; Nakamura et al., 2005). Early debates focused on whether dACC is responsive to conﬂict versus explicit failures in performance (i.e., errors) and/or negative feedback. There now seems to be general consensus that, consistent with the EVC model, dACC is responsive to both (e.g., Nee et al., 2011). However, recently it has been suggested that dACC activity reﬂects ‘‘time-on-task’’ irrespective of conﬂict, errors, or even error likelihood (Grinband et al., 2011b) and that it is more closely tied to task maintenance or attention that endures over the course of even simple tasks. However, the theoretical analyses that have led to this conclusion have been challenged (Brown, 2011; Yeung et al., 2011; see also Grinband et al., 2011a). Furthermore, we note that their interpretation of dACC function, more closely aligned with the regulative component of control, is difﬁcult to square with much of the literature we will review in the remaining sections. For instance, it fails to account for dACC responses to the value of outcomes or for conditions in which dACC activity is uncorrelated, or even negatively correlated with, RT (e.g., Cavanagh et al., 2011; Gluth et al., 2012; Guerin and Miller, 2011; Sheth et al., 2012; van Maanen et al., 2011). In contrast, while the EVC model predicts that dACC responses reﬂecting its monitoring function may correlate with RT, it also predicts conditions under which this should not necessarily occur, as discussed further below.
State Information Relevant to Control Signal Identity. So far, our consideration has focused on state information relevant to deciding how much control to allocate; that is, the speciﬁcation of control signal intensity. However, knowledge concerning the current situation or state is equally important for deciding which task(s) to pursue, that is, the speciﬁcation of control signal identity. The dACC sits in an ideal location for gathering such state information (Morecraft et al., 2012; Shackman et al., 2011; Weston, 2012; Figure 1C). Inputs from cortical areas associated with high-level perception give it immediate access to information about external task cues, and inputs from structures such as the amygdala and insula give it access to information about motivational states that may favor particular lines of behavior. Although the impact of such inputs on dACC activity has been relatively little studied, the information they carry would be of obvious relevance to selection among control signal identities. Consistent with this, dACC appears to differentiate representations of signal identity, including representations of response rules (Dixon and Christoff, 2012; Durstewitz et al., 2010; Johnston et al., 2007; Matsuzaka et al., 2012; Womelsdorf et al., 2010), task sets (Forstmann et al., 2006; Haynes et al., 2007), and speciﬁc actions (Hampton and O’Doherty, 2007; Isomura et al., 2003; for reviews see Morecraft and Tanji, 2009; Rushworth et al., 2004; Sakai, 2008). Taken together, such ﬁndings support the idea that the dACC registers state information directly relevant to the speciﬁcation of control-signal identity.
dACC Monitoring of Outcome Information. Estimation of the EVC requires not only information about the present state, but also information about potential outcomes and, critically, the positive or negative value associated with those outcomes. In order to be sensitive to such information, the dACC should register both the anticipated value of outcomes ahead of their occurrence and their value when they actually occur.

Negative-Valued Outcomes. Numerous neuroimaging ﬁndings have demonstrated dACC responses to negative outcomes. These range from the most concrete, such as pain (reviewed in Shackman et al., 2011), errors in task performance (e.g., Brown and Braver, 2005; Holroyd and Coles, 2002), monetary loss (Blair et al., 2006; Kahnt et al., 2009; Liu et al., 2011), and the presentation of threatening stimuli (e.g., Mobbs et al., 2010), to more abstract outcomes such as social rejection (Eisenberger and Lieberman, 2004; Kawamoto et al., 2012), a loss by a favored sports team (Cikara et al., 2011), pain experienced by another individual (Botvinick et al., 2005; Lamm et al., 2011), and even the hypothetical death of strangers (Shenhav and Greene, 2010). These ﬁndings are paralleled by direct neuronal recordings in nonhuman species, which have demonstrated responses in dACC to errors (Amiez et al., 2005; Ito et al., 2003; Niki and Watanabe, 1979; Totah et al., 2009), losses or less-than-anticipated gains (Ito et al., 2003; Kennerley et al., 2011), and cues predictive of aversive outcomes (Gabriel and Orona, 1982; Amemori and Graybiel, 2012).
Conﬂict, in addition to its role in signaling task difﬁculty, may itself constitute an aversive outcome (Botvinick, 2007; Fritz and Dreisbach, 2013; Hirsh et al., 2012). Amemori and Graybiel (2012) provided evidence in support of this assertion, showing that patterns of activity for ACC neurons that coded positively for conﬂict functionally clustered with those that coded for magnitude of punishment.
Positive-Valued Outcomes. There is also a growing accumulation of ﬁndings indicating that dACC is responsive to positive outcomes. Direct neuronal recordings have consistently identiﬁed responses to rewarding events, often among units interdigitated with those responsive to negative outcomes. This includes neurons responsive to the magnitude and probability of reward, including to hypothetical reward (for a recent review see Wallis and Kennerley, 2011). Human neuroimaging studies have also provided evidence for reward-related signals in dACC (Knutson et al., 2005; Kouneiher et al., 2009; meta-analysis in Bartra et al., 2013).
Control Relevance of Outcome Value. A simple interpretation of the ﬁndings above might be that dACC responds to the value of any event. However, the EVC model makes a more speciﬁc claim: dACC should be selectively responsive to the value of events that are relevant to the allocation of control. To engage dACC, a valenced event need not necessarily pertain to the current task, but it should pertain to some potential controldemanding task that could currently be executed. Although this prediction has not been well-tested in the literature, there is evidence that dACC is more sensitive to outcomes when they are tied to actions, or stimuli that demand an action, than when they are only tied to nonimperative stimuli (for reviews see Rangel and Hare, 2010; Rushworth et al., 2011; Wallis and Kennerley, 2011). Furthermore, there is evidence that dACC responses to outcomes diminish when there is a decline in demand for control. For example, fMRI studies have shown that dACC engagement falls progressively with extended practice on a cognitive task (Chein and Schneider, 2005, 2012). Similarly, feedback-related dACC activity is observed in tasks that require subjects to search for the correct response from a set of options, but is diminished when they are allowed to repeat

224 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

the correct response a number of times before outcome contingencies change (reviewed in Khamassi et al., 2010). Landmann and colleagues (2007) found the same pattern of dACC activity in a task for which participants had to progressively discover the correct sequence of button presses, also through trial and error (see also Procyk et al., 2000). They showed that dACC activity was greater during search than after discovery of the correct sequence, and that during search it correlated with the amount of information carried by feedback at each step of the current sequence (e.g., whether positive feedback was being given for a correct response that had just been discovered, which elicited strong dACC activity, or to a part of the sequence that had already been solved, which elicited weaker dACC activity).
Note that, insofar as the dACC takes account of control-relevant outcome information in estimating EVC, it should therefore predict subsequent shifts in control based on such information. There is robust evidence for such a link, as will be discussed below.
Reward-Prediction Error Signals. As articulated in Equation 2, the value term in the EVC expression refers not only to the immediate reward associated with an outcome, but also to the expected future reward. This is important, because it allows control-signal speciﬁcation to be based on delayed outcomes. Readers familiar with reinforcement learning will recognize this particular formulation of value from that context (Sutton and Barto, 1998). In reinforcement learning models, estimates of state value are typically shaped not directly by raw representations of reward, but instead by reward-prediction errors (PE), signals indicating the extent to which experienced outcomes are better or worse than expected.
A number of ﬁndings indicate the occurrence of PE signals in the dACC. The earliest evidence came from EEG recordings demonstrating an event related potential (ERP) with a frontomedial source that occurs in response to negative outcomes. This was dubbed the feedback-related negativity (FRN; Miltner et al., 1997), referring to its occurrence in response to negative feedback such as the indication of an error in task performance or a monetary loss following a gamble (Gehring and Willoughby, 2002). Critically, the FRN has been found to be sensitive to the expectations established by local context (Holroyd et al., 2004a; Jessup et al., 2010; Nieuwenhuis et al., 2005b). For example, in a gambling task, when the range of outcomes is from negative to neutral, the FRN is observed for losses but not neutral outcomes. However, when outcomes range from neutral to positive, the FRN is now observed for neutral outcomes, but not gains. Thus, expectations established by context dictate whether the FRN is elicited by a neutral outcome (see also Jessup et al., 2010). This provides strong evidence that the FRN reﬂects a PE, rather than a direct representation of absolute reward. Although the source of the FRN has not been deﬁnitively localized to dACC, neuroimaging studies have demonstrated activity in dACC under conditions that mimic those in which the FRN is observed (Holroyd et al., 2004b).
The FRN is closely related to another commonly observed ERP, the error related negativity (ERN). This occurs following errors in speeded response trials even when explicit feedback is not provided. There is direct evidence that the ERN has its

source in the dACC: Simultaneous recording of EEG and fMRI has shown that the magnitude of the ERN correlates with the BOLD signal from dACC on a trial-by-trial basis (Debener et al., 2005). As suggested earlier, direct neuronal recordings from regions of dACC have also revealed error-related responses in humans (Wang et al., 2005), monkeys (Emeric et al., 2008; Ito et al., 2003), and rats (Narayanan and Laubach, 2008) (however, see Cole et al., 2009 for discussion of homology). One inﬂuential interpretation of the ERN is that it reﬂects negative PEs (associated with the commission of an error) that are used to drive learning in the service of improving action selection (Holroyd and Coles, 2002). The EVC model is consistent with this hypothesis. However, it has been proposed that the ERN can also reﬂect post-response conﬂict, under conditions in which error information is not immediately available (Yeung et al., 2004). In this context, the ERN may reﬂect the role of dACC in conﬂict monitoring and control-signal speciﬁcation, as discussed above.
In addition to these EEG ﬁndings, evidence for positive and negative PEs in dACC has been found with both direct neuronal recordings (Kennerley et al., 2011; Matsumoto et al., 2007; Quilodran et al., 2008) and fMRI (Amiez et al., 2012; Kahnt et al., 2011). Interestingly, this has suggested that dACC can also respond to PEs in an unsigned manner—that is, comparably to both positive and negative PEs. This has been shown through direct neuronal recordings (Bryden et al., 2011; Hayden et al., 2011a) and is consistent with EEG and fMRI studies showing elevated dACC activity in response to surprising outcomes (Cavanagh et al., 2012; Landmann et al., 2007; Nee et al., 2011; Wessel et al., 2012) and, more generally, following unanticipated shifts in task contingencies (Alexander and Brown, 2011; Behrens et al., 2007; Bland and Schaefer, 2011). These observations have inspired a recent model of dACC function by Alexander and Brown (2011), which suggests that dACC stores predicted associations between stimuli and responseoutcome (RO) conjunctions, and signals any violations of these predicted S-RO relationships. Although this proposal is potentially compatible with the EVC model, the latter makes more direct contact with data concerning the consequences of surprise signaling, as we discuss further on.
Speciﬁcation Function of the dACC: Maximizing the Expected Value of Control The EVC model proposes that information provided by monitoring is used to determine when and how control signals should be adjusted in order to maximize the opportunity for reward, by specifying the optimal control-signal identity and intensity. While the mechanisms implementing speciﬁcation along each of these dimensions may be tightly coupled or even the same, different circumstances may rely differentially upon these two dimensions of speciﬁcation. For example, switching between two controldemanding tasks would rely more heavily on selecting signal identity, while responding to increasing demands of the current task by augmenting control would rely more heavily on adjustments of intensity (Figure 2B).
The literature provides evidence that dACC is engaged in both types of speciﬁcation, though most studies have focused on only one or the other. Accordingly, most theories have tended to ascribe to dACC a role in either task selection (identity

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 225

Neuron
Review

speciﬁcation) or modulation of control (intensity speciﬁcation). The EVC model integrates these accounts, proposing that they refer to different dimensions of the same function. Accordingly, dACC should be responsive to circumstances that engage either or both. In the two sections that follow, we review the literature concerning the association of dACC with each of these two dimensions of control speciﬁcation. Speciﬁcation of Control Signal Identity Among the earliest theories of dACC function were ones that proposed a role in action selection (Devinsky et al., 1995; Matsumoto et al., 2003; Rangel and Hare, 2010; Rushworth et al., 2007; Rushworth et al., 2004). More recent theories have elaborated this idea to include task selection (Holroyd and Yeung, 2012; Kouneiher et al., 2009; O’Reilly, 2010). These are commensurate with the role of dACC in the speciﬁcation of control signal identity proposed by the EVC model. Some evidence for this comes from studies showing dACC selectivity for different control signal identities, including rules and task sets. However, the EVC model also requires that control signals be speciﬁed based on their expected value. This predicts that the dACC should exhibit responses that are both selective for a particular line of behavior and sensitive to the value of outcomes associated with that behavior. This prediction is consistent with the ﬁndings of several recent studies.
For example, when monkeys were required to choose between targets in a visual saccade task, overlapping populations of dACC neurons were found to encode the value and direction of the saccade chosen on a given trial (Cai and Padoa-Schioppa, 2012; Hayden and Platt, 2010). Kaping and colleagues (2011) demonstrated similar effects in a task involving covert shifts of visual attention, rather than explicit eye movements. In their study, a colored ﬁxation cue at the start of each trial indicated which of two subsequently presented colored visual stimuli should be attended. The monkeys were then rewarded if they correctly reported whether the stimulus with the corresponding color rotated clockwise or counterclockwise. The amount of reward earned by a correct response was signaled by the color of the initial ﬁxation cue. As in previous studies, overlapping neuronal populations in rostral dACC were found to encode the target of the attentional shifts and the value of those targets, independently of any overt saccade used to report movement direction.
These ﬁndings are consistent with a role for dACC in specifying control signal identity based on its expected value. However, an alternative interpretation is possible: they could instead reﬂect the state and/or outcome monitoring functions of dACC without reﬂecting a role in speciﬁcation. Weighing against this more restrictive interpretation is the observation that activity of dACC neurons in the studies described above typically anticipated switches between actions and/or tasks (though see Cai and Padoa-Schioppa, 2012). Similarly, Womelsdorf and colleagues (2010) have shown that local ﬁeld potentials (LFPs) in the theta band observed within macaque dACC could discriminate which of two stimulus-response mapping rules (pro- versus anti-saccade) would be used prior to appearance of the stimulus. Furthermore, this rule selectivity was absent prior to error trials, consistent with the hypothesis that activity in dACC was required to specify the identity of the task-appropriate control

signal. Interestingly, when rule-selective activity reemerged prior to a correct trial following an error, the selectivity was seen earlier than on correct trials that followed a previous correct one (see also Johnston et al., 2007). A subsequent study from this group used a similar task to provide causal support for this control speciﬁcation role (Phillips et al., 2011). They found that stimulating dACC during the response preparation period signiﬁcantly facilitated antisaccade performance (accelerating responses without increasing error rate), but had a less consistent inﬂuence on prosaccade performance, a complement to the impairments (slowing) previously found in human dACC lesion patients performing an antisaccade task (Gaymard et al., 1998).
Additional evidence consistent with identity speciﬁcation comes from one of the most comprehensive analyses to date of human patients with focal brain lesions (Gla¨ scher et al., 2012). This study combined data from four different set-shifting tasks into a single ‘‘cognitive control factor’’ and found that the poorest performance along this factor was associated with lesions in rostral dACC. These ﬁndings are consistent with a causal role for dACC in specifying control identities. It is also consistent with its role in specifying the intensity of those control signals. Speciﬁcation of Control Signal Intensity Motivation. A role in specifying control intensity is consistent with the earliest observations regarding dACC function, which ascribed to it a function in ‘‘motivation,’’ driven in part by the observation that medial frontal damage can lead to gross deﬁcits in motivated behavior (e.g., abulia; see Holroyd and Yeung, 2012). More recent proposals have suggested that dACC motivates or ‘energizes’ action or task engagement based on current incentives (Holroyd and Yeung, 2012; Kouneiher et al., 2009; Stuss and Alexander, 2007). In support of this, circumscribed lesions that encompass dACC produce longer overall reaction times (e.g., Alexander et al., 2007; Fellows and Farah, 2005), and higher false alarm rates (e.g., Løvstad et al., 2012; Tsuchida and Fellows, 2009). These are consistent with a role for dACC in specifying control intensity.
Adaptive Adjustments in Control Intensity. Beyond this broad relationship to motivation, the EVC model makes the more speciﬁc proposal that the dACC is responsible for adjusting the intensity of control adaptively based on task demands. That is, not only must the control system determine what task is best to perform, but also the amount of control that must be allocated to that task so as to optimize EVC. This follows from the assumption that control is costly, as discussed earlier (see Figure 4). There is longstanding evidence for adaptive adjustments in control in the behavioral literature, for example changes in the speed-accuracy tradeoff observed following errors in simple decision tasks (see Danielmeier and Ullsperger, 2011). Gratton et al. (1992) suggested that such adaptive adjustments extend to the allocation of attention, showing that the response to an incongruent stimulus is faster when it follows another incongruent stimulus than when it follows a congruent one. This was interpreted as evidence of an enhancement of attention to the task-relevant dimension in response to the interference produced by a prior incongruent one.
In computational work, Botvinick et al. (2001) demonstrated that the behavioral effects described above could be explained

226 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Figure 4. The Inﬂuence of Incentives and Task Difﬁculty on Control Allocation and dACC Activity The EVC model predicts shifts in control intensity in response to changes in task incentives (A) and in task difﬁculty (B). In each case, control intensity is speciﬁed based on a maximization of the EVC (blue curves). As indicated in Equations 1 and 2, the EVC depends, in turn, on both the expected payoffs and costs for candidate control signals (see also Figure 2B). Payoffs (green curves) can vary with signal intensity due to resulting changes in task performance. For example, a stronger control signal might yield more accurate performance, and therefore greater payoffs. However, the inherent cost of control (red curves) also rises with control signal intensity. (A) An increase in task incentives affects the payoff curve. Here, we consider a laboratory scenario in which monetary reward for each correct response shifts from a lower amount (dashed green curve) to a higher amount (solid). When integrated with cost information (red curve), this results in a shift in the EVC function (dashed blue curve to solid blue curve), and a resulting shift in the signal intensity that maximizes the EVC (dashed to solid black arrow). (B) An increase in task difﬁculty reduces the expected payoff for any given control signal intensity (shift from dashed to solid green curve). In the present scenario this is due to a reduction in the probability, for any given signal intensity, of a correct response. The shift in the payoff curve, when integrated with cost (red curve), again yields a change in the EVC function (dashed to solid blue) and a shift in the EVC-maximizing control signal intensity (dashed to solid black arrow). (C and D) Kouneiher and colleagues (2009) found that dACC activity tracked both of these EVC-relevant variables. They had participants perform a letter discrimination task and showed that dACC activity increased with the overall incentive level for the current block (C), whether or not the higher incentive was available for the current trial (Standard trials did not offer additional incentives for correct performance but Bonus trials did). They also found that dACC was modulated by the difﬁculty of a given trial (D); Default trials always had the same response mapping, obviating any additional letter discrimination, Task trials required using a letter discrimination rule based on the letter color, and this color-rule mapping was either stable throughout the session (Baseline/Contextual) or varied by block (Episodic). See the ‘‘dACC and the Cost of Cognitive Control’’ and ‘‘The Cascade of Control‘‘ sections for additional details. (C) and (D) reprinted by permission from Macmillan Publishers Ltd: Nature Neuroscience, Kouneiher et al. (2009), copyright (2009).

by a mechanism that monitors conﬂict elicited by lapses in performance and/or interference and uses this to adjust the intensity of the task-relevant control signals in order to maintain task performance. However, the EVC model makes a stronger claim: that such adjustments serve to optimize the allocation of control. A modest, but growing corpus of work has begun to address this stronger claim and its relation to dACC function.
Optimization of Control Intensity. The most extensive analyses of control optimization have focused on simple two-alternative choice tasks, such as those used to demonstrate adaptive changes in the speed-accuracy tradeoff mentioned above. Such tasks have been modeled extensively using simple accumulator models, in which the intensity of the control signal inﬂuences two parameters of the decision process: the decision threshold and initial bias. Together, these determine the speed-accuracy tradeoff. Botvinick et al. (2001) showed that monitoring response conﬂict in such models and using this to adjust the intensity of the control signal accurately accounted for adaptive changes in the speed-accuracy tradeoff observed in behavior. In that model, the intensity of the control signal determined the decision threshold. More recently, formal analyses by Bogacz et al. (2006) have shown that there is an optimal threshold (i.e., speed-accuracy tradeoff) that maximizes reward rate for a given set of task conditions, and similarly for initial bias. Furthermore, behavioral studies show that participants adapt

their behavior to changes in task conditions in ways that often approximate adoption of the optimal threshold and bias (reviewed in Cohen and Holmes, 2013). While most work addressing optimality of control has focused on adjustments of threshold and/or bias in simple two-alternative forced-choice tasks, at least one theoretical effort has addressed the optimal allocation of attention in a conﬂict task. Yu et al. (2009) determined the optimal strength with which attention should be allocated to the target stimulus in the Erisken ﬂanker task. They showed that this could be approximated by within-trial adjustments in the strength of attention based on conﬂict monitoring, and that this in turn accurately reproduced the dynamics of attentional allocation observed in the task.
Role of dACC in Adaptive Adjustments of Control Intensity. The ﬁndings of these theoretical and behavioral studies are consistent with the idea that the intensity of the control signal is adjusted to maximize EVC. The EVC model proposes that dACC mediates these adjustments, by monitoring for the conditions that require them, and specifying the necessary adjustments for others systems responsible for implementing them. This makes two predictions: ﬁrst, that dACC should be responsive to conditions indicating the need to adjust control intensity; and, second, that it should be associated with the engagement of neural systems responsible for implementing these adjustments (i.e., the regulative function of control).

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 227

Neuron
Review

There is extensive evidence in support of the ﬁrst prediction, indicating that dACC is responsive to conditions requiring adjustments of threshold and/or response bias, such as increases in time pressure and changes in prior probabilities (Bogacz et al., 2010; Forstmann et al., 2008, 2010; Ivanoff et al., 2008; Mulder et al., 2012; van Maanen et al., 2011); as well as conditions requiring changes in the degree of attention, such as the cases of processing conﬂict described earlier.
There is also evidence in support of the second prediction. Several studies have shown that dACC interacts directly with structures proposed to implement changes of threshold, such as the subthalamic nucleus (Aron et al., 2007; Aron and Poldrack, 2006; Cavanagh et al., 2011; Jahfari et al., 2011; Wiecki and Frank, 2013), as well as those thought to inﬂuence response biases, such as dorsal striatum (Bogacz et al., 2010; Jahfari et al., 2011; Wiecki and Frank, 2013). There is also evidence that dACC is associated with adjustments in the strength of attention in conﬂict tasks. Several human neuroimaging studies have demonstrated a direct association between dACC responses to conﬂict on one trial, and subsequent increases in the activity of regions thought to be responsible for regulating attention and corresponding improvements in performance on the next trial (e.g., Cavanagh et al., 2009; Kerns, 2006; Kerns et al., 2004; King et al., 2010; MacDonald et al., 2000). In a recent study, Danielmeier and colleagues (2011) used a variant of the Simon task to study the relationship of dACC responses to conﬂict, performance, and activity in stimulus-speciﬁc regions of visual cortex. As had previously been found, dACC activity associated with errors predicted response slowing on the subsequent trial. Critically, however, it also predicted the degree to which activity increased in task-relevant and decreased in task-irrelevant processing regions, consistent with an increase in the control signal following errors. EEG studies have provided similar evidence, linking indicators of dACC responses (such as the ERN) to sequential adjustments in behavior following conﬂict and/or errors (Crottaz-Herbette and Menon, 2006; Forster et al., 2011). Such effects can also be found within a given trial. For example, Sohn et al. (2007) found that when participants were explicitly informed about the amount of conﬂict likely to arise on a given trial of a problem-solving task, anticipatory dACC activity predicted how efﬁciently conﬂict was resolved on that trial (see also Aarts et al., 2008). Finally, studies in nonhuman species have also provided evidence that responses in dACC predict changes in the amount of attention subsequently paid to a given stimulus or task dimension (Bryden et al., 2011; Narayanan and Laubach, 2008; Totah et al., 2009).
These studies provide convergent evidence for a correlation of responses in dACC with subsequent changes in performance and task-speciﬁc neural activity indicative of adjustments in the intensity of control. Sheth et al. (2012) provided evidence that dACC contributes causally to these adjustments. Patients about to undergo cingulotomy were studied using both fMRI and intracranial recordings while performing a conﬂict task. Preoperatively, participants exhibited the standard conﬂict adaptation effects in both behavior (e.g., faster RTs on high-conﬂict trials that followed a high-conﬂict versus a low-conﬂict trial; Figure 3B, left) and neuronal activity (differential dACC ﬁring rates for this same contrast; though see Figures 3C and 3D for

discussion of a surprising divergence from previous neuroimaging ﬁndings). Importantly, following cingulotomy this adaptation effect was no longer apparent, consistent with a causal role for this region in adaptively inﬂuencing control intensities (Figure 3B, right).
Attention for Learning. Another context in which the dACC appears to play a role in specifying control intensity relates to its responses to surprising events. Research demonstrating unsigned PE signals in dACC has highlighted a potential connection with the Pearce-Hall model of learning, in which surprising outcomes trigger an intensiﬁcation of attention that in turn facilitates learning. To test this, Bryden and colleagues (2011) had rats poke their nose into a port to receive an odor instructing them where to obtain a reward, and found that rats were faster to poke their nose into this port on trials that followed a surprising outcome (increases or decreases from expected reward). Critically, they found that responses in dACC to surprise on the preceding trial predicted the degree to which the animal hastened or slowed this orienting response on the trial that followed. Also consistent with an ‘‘attention for learning’’ account, Behrens and colleagues (2007) showed that dACC responses to changes in task contingencies—speciﬁcally, to their volatility, which reﬂects the expected frequency of surprise—were associated with more robust learning. Such ﬁndings, and the attention-forlearning account overall, are consistent with the EVC model of dACC, insofar as the signals driving top-down attention and/or increases in learning rates may be considered as control signals. Default Override Thus far, we have treated the speciﬁcation of identity and intensity separately. In reality, however, the identity and intensity of the control signal must be jointly speciﬁed (see Figure 2). For example, to perform color naming in the Stroop task, the control system must specify both the identity of the control signal (the color naming task), as well as the intensity needed to overcome any conﬂict from the word. Such circumstances are representative of a broader class of conditions often described as default override. In general, this refers to situations in which the task to be performed is less automatic than the default behavior in that circumstance; that is, the behavior that would normally occur in absence of control and is the source of conﬂict. Under such circumstances, adequate control is needed to override the default response, and execute the speciﬁed task (see, e.g., Shah and Oppenheimer, 2008).
Some of the earliest neuroimaging studies of cognitive control established a role for dACC in overriding default behavior (e.g., Paus et al., 1993). The dACC’s involvement in overriding defaults has been seen not only when the participant is explicitly instructed to perform the nondefault behavior, but also when they voluntarily make a choice that runs counter to current task- or context-deﬁned defaults, including choices to go against gain versus loss frames (De Martino et al., 2006), against the status quo (Fleming et al., 2010), against Pavlovian response-outcome associations (Cavanagh et al., 2013), or against a group decision (Tomlin et al., 2013). Three additional circumstances that involve default override, and that have begun to attract considerable attention, are exploration, foraging, and intertemporal choice.
Exploration. This refers to behavior that favors information gathering with the prospect that this will yield greater future

228 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

reward, over the pursuit of behavior with known and usually more immediate reward (i.e., exploitation). People generally exhibit a strong bias toward the pursuit of more immediate reward, so exploitation can be considered the default. Choosing to explore therefore requires overriding this default, and thus allocating control. Accordingly, the EVC model predicts that exploration should engage dACC (for related accounts, see Aston-Jones and Cohen, 2005; Khamassi et al., 2010). This prediction was borne out in a study carried out by Daw et al. (2006). Participants chose among four options providing probabilistic reward that varied gradually over time. Initially they sampled the different options (exploration) to determine which currently provided the greatest mean payoff, after which they repeatedly selected that one (exploitation) until it began to decline in value, or they suspected others may have increased in value. At that point, they chose to sample the other options again (exploration). Decisions to explore were associated with increased dACC activity. This association between dACC and exploratory behavior has been replicated in humans (Amiez et al., 2012; Cavanagh et al., 2012) and also demonstrated in monkeys (Procyk et al., 2000; Quilodran et al., 2008) and rodents (Karlsson et al., 2012).
Foraging. Like exploration, foraging involves searching for an alternative source of reward. However, in this case it typically involves an initial cost and is also usually driven by knowledge of the reward structure of the environment (whereas exploration is directed at acquiring such knowledge). Nevertheless, like exploration, foraging involves overriding current pursuit of more immediate reward to pursue an alternative that promises greater future reward, and thus relies on the allocation of control. Accordingly, the EVC model predicts that foraging should also engage the dACC. This prediction is supported by a number of studies. For instance, Kolling et al. (2012) had participants make a series of choices between pairs of options that yielded probabilistic payoffs with known means. However, before each choice, participants were given the opportunity to switch the pair of options in front of them to a different pair that could yield higher average reward, but at a cost for the switch. This was designed to be analogous to situations in which an animal’s decision to forage carries a near term cost but a potential longterm beneﬁt. Activity in dACC was found to closely track the extent to which the mean value of the alternative options was greater than that of the current options, and to correlate with the decision to switch option sets in such cases (see also Boorman et al., 2013; Rushworth et al., 2012; Wunderlich et al., 2009). This is consistent with the EVC model, which predicts that dACC should track the value of control-demanding behavior and its selection over the current default. Animal studies have provided convergent ﬁndings. For example, Hayden et al. (2011b) found that macaque dACC neurons also track the value of foraging, and Li et al. (2012) found that dACC-lesioned rats forage for food substantially less than nonlesioned animals, while continuing to engage normally in other habitual or automatic behavior.
Intertemporal Choice. Finally, it is worth noting that, insofar as both exploration and foraging involve the comparative evaluation of longer term versus immediate payoffs, they both involve intertemporal choice. One universally observed ﬁnding in the literature on intertemporal choice is that people (like all other

species) exhibit a strong immediacy bias. That is, they favor rewards that are immediate, even when later ones are worth considerably more. In this respect, behavior associated with immediate reward can be considered the default behavior in general, and thus should require control to be overcome. Consistent with this view, neuroimaging studies of intertemporal choice, beyond those focused on exploration or foraging, suggest that patient behavior (i.e., choices for longer term over immediate reward) rely on neural mechanisms associated with cognitive control (Figner et al., 2010; McClure et al., 2007; McClure et al., 2004), including the dACC. In these cases, as in general, the EVC model proposes that the role of dACC is to determine the EVC of the control-demanding behavior, and specify the control signal needed to pursue it. This assumes that it has access to information about the value of the options in contention that is represented in other structures, such as ventral regions of mPFC (Floresco et al., 2008; Haber and Knutson, 2010; Pre´ vost et al., 2010; Rangel and Hare, 2010; Rushworth et al., 2011).
dACC and the Cost of Cognitive Control The expected value of a control-demanding behavior depends not only on the reward it promises, but also on the expenditures needed to procure that reward; that is, it depends on the cost of control (Cost(signal) in Equation 1). As reviewed earlier, behavioral evidence supports the idea that the exertion of control is associated with subjective disutility manifest as the avoidance of control-demanding tasks (Kool and Botvinick, 2012; Kool et al., 2010). The EVC model proposes that the dACC registers the costs of control in a manner that is proportional to the intensity of control and that it speciﬁes control signals in a way that is sensitive to such costs. This proposal generates several predictions concerning dACC function and its relation to behavior. Costs of Control and Control Intensity First, and most simply, the dACC should be sensitive to demands for control and/or to the intensity of the current control signal. As reviewed in the preceding sections, there is abundant evidence in support of this prediction. Second, the dACC should encode the exertion of control as costly. Evidence consistent with this idea has come from several recent studies. For example, Botvinick and colleagues (2009a) found that, during performance of a cognitively demanding task, a greater dACC response predicted decreased subsequent responses in nucleus accumbens to monetary reward, interpreted as ‘‘payment’’ for the task. This effect is consistent with cognitive effort discounting; that is, a reduction in the subjective value attached to a reward based on cognitive costs borne to attain it. Other studies have shown that dACC responses to such costs predict subsequent decisions about control. In one, Magno and colleagues (2006) presented participants with a series of attentionally demanding search arrays and, for each array, gave them the choice to identify the presence or absence of a target or to indicate that they would like to forgo the search on that trial. They found that dACC activity was highest on trials the participant actively chose to forgo rather than engage for potential reward (or loss). Similarly, McGuire and Botvinick (2010) found that the degree to which performance of a cognitively demanding task engaged dACC predicted the extent to which that same task

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 229

Neuron
Review

would later be avoided. Collectively, these ﬁndings are consistent not only with dACC encoding of control costs, but also with a role for dACC in cost-sensitive control signal speciﬁcation.
Figure 4 illustrates how the optimal control signal intensity predicted by the EVC model is determined by the relationships of control costs and payoffs to control signal intensity. These relationships determine the function relating EVC to intensity, and the optimum occurs at a point where the slope of that function is zero. Under plausible assumptions about the shape of the payoff and cost functions (see Kool and Botvinick, 2012), the optimal control signal intensity will rise with the magnitude of task incentives (see Figures 4A and 4B). This predicts that dACC activity should grow both with task difﬁculty and with the stakes associated with task performance. This dual effect was reported by Kouneiher and colleagues (2009), who had participants perform a series of trials in which a colored letter cued them to perform a letter discrimination task or to simply press a single key unrelated to letter identity (‘‘default’’ trials). Each trial was also cued with whether or not a correct response would carry a monetary bonus, and the value of these bonuses differed by trial block. The authors found that dACC activity increased with the difﬁculty of the trial as well as with the average stakes for the trial block (regardless of whether a bonus was available on a particular trial; see Figures 4C and 4D). Control Signal Intensity and Willingness to Pay The prediction of a monotonic relationship between controlsignal intensity and the cost of control means that the output of the dACC can be interpreted in either of two ways: as directly reﬂecting the speciﬁed intensity of the current control signal, or as indirectly reﬂecting the cost that has been licensed for this control signal. The latter follows from the assumption of the EVC model that the dACC speciﬁes the optimal control signal; accordingly, its intensity should indicate the amount of control that was determined to be ‘‘worth’’ the expected payoff. This relationship between intensity and cost can be understood by analogy to the economic concept known as willingness-to-pay, which refers to the amount worth trading for a good. Recent work has characterized orbitofrontal cortex as carrying a willingness-to-pay signal during economic choice (Levy and Glimcher, 2012; Padoa-Schioppa, 2011; Plassmann et al., 2007). The EVC theory suggests that the output of dACC can be thought of as a willingness-to-pay signal in the currency of cognitive control.
Thinking of dACC output in these terms provides another way of understanding impairments of cognition and behavior following medial frontal damage. As discussed above, this is commonly associated with acquired apathy or an inability/lack of energy to perform willed actions, as well as subtler deﬁcits such as response slowing, perseverative errors, and failures to speed or slow current trial performance based on information from the previous trial (e.g., Stuss, 2011; Stuss and Alexander, 2007). All of these may reﬂect a failure to specify the required ‘‘willingness-to-pay’’ for initiating effortful control, particularly when the incentives for doing so are minimal. Other Forms of Costs In considering the costs of executing controlled behavior, we have focused on the cost of control itself, but this reﬂects only one possible cost that must be factored into computing EVC. Other costs—such as any physical effort involved—are equally

relevant. The EVC model predicts that dACC should be responsive to such costs as well. There is an abundance of evidence that dACC is responsive to the physical effort required by an action and revises its estimate of expected reward downward in order to reﬂect the cost of exerting this effort (e.g., Croxson et al., 2009; Hillman and Bilkey, 2010, 2012; Walton et al., 2007). Neurons in dACC have been found to track the effort demands of a prospective action, whether this involves lever presses (Kennerley et al., 2011; Kennerley et al., 2009) or physical obstacles that need to be overcome along a path (Cowen et al., 2012; Hillman and Bilkey, 2010). The same has been found in human neuroimaging studies when varying, for instance, how many visuomotor targets would need to be detected on a task (Croxson et al., 2009) or how much force needs to be exerted on a handgrip (Pre´ vost et al., 2010). As with cognitive demands, the dACC also signals the degree to which these motor requirements reduce the value of an action. That is, dACC activity signals the overall value of potential actions.
The Cascade of Control: dACC in Relation to Other Control-Related Structures The proposal that dACC integrates information relevant to evaluating EVC places it at the heart of a broader network of systems that support control-demanding behaviors. Speciﬁcally, it places it at the juncture between structures involved in valuation from which it receives input, and structures responsible for regulation to which it provides its output. Importantly, the EVC model makes a clear distinction between these functions and those of monitoring and control signal speciﬁcation that the dACC is proposed to subserve. Nevertheless, the full span of control functions is likely to reﬂect a continuous cascade of processing, from valuation to monitoring and estimation of EVC, to control signal speciﬁcation and ﬁnally regulation. Thus, in practice it may be difﬁcult to dissociate these individual functions. It is not surprising, therefore, that structures commonly associated with valuation and regulation have been found to coactivate and/or share structural and functional connectivity with dACC (Figure 1; Beckmann et al., 2009; Haber and Knutson, 2010; Morecraft et al., 2012; Power and Petersen, 2013; Seeley et al., 2007; Touroutoglou et al., 2012; Vincent et al., 2008; Yeo et al., 2011). In fact, ﬁnding evidence for dissociations of function among these structures has been something of a challenge for this area of research. In this section, we review the literature addressing such efforts, and what it has to say about the division of labor between dACC and other structures that have been implicated in valuation and the implementation of cognitive control. Interactions with Insula, Ventral PFC, Striatal, and Midbrain Structures Involved in Valuation The EVC model makes a fundamental distinction between the primary representation of value—whether of internal signals or external ones—and the monitoring of these for use in estimating the EVC of candidate control signals. The model proposes that dACC subserves the latter, while it assumes that the primary representation of value is subserved by other structures that project to dACC, including other cortical areas (e.g., insula, amygdala, and ventral/medial regions of PFC) and subcortical ones (e.g., basal ganglia and dopaminergic midbrain structures).

230 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Insula and Detection of Affective Salience. One of the regions most commonly coactivated with dACC is the anterior insula, and these two regions share robust reciprocal connections. While some have suggested that the insula might take part in a regulative role in maintaining task sets (Dosenbach et al., 2006), others have proposed that the interaction between insula and dACC may reﬂect a sequential process of registering motivationally salient stimuli that engender adaptive adjustments of processing. On this account, the insula supports representations of affective/motivational signiﬁcance. These are then conveyed to the dACC in order to appropriately modify processing to inﬂuence internal autonomic states as well as changes in overt behavior, including emotional expressions (Bush et al., 2000; Craig, 2009; Medford and Critchley, 2010; Shackman et al., 2011; Singer et al., 2009; Ullsperger et al., 2010). The dACC can also register the extent to which these affective/autonomic states interfere with ongoing task performance and therefore require additional cognitive control. This division of labor is supported by differences in the patterns of connectivity of insula and dACC with other regions, and evidence that the insula is more consistently tied to the conscious experience of emotion while the dACC is more closely tied to overt responses to emotioneliciting stimuli. These observations have led Craig (2002, 2009) to refer to the insula and dACC as ‘‘limbic sensory’’ and ‘‘limbic motor’’ cortices, respectively.
This division of labor between primary valuation and adaptive responding is generally consistent with the EVC model. However, the model distinguishes between the function of dACC in specifying adaptations, and their implementation by other structures that actually regulate processing. The model also asserts that the dACC’s involvement should be speciﬁc to adaptations that involve controlled but not automatic responses. This includes situations in which automatic responses to emotionally salient events must be overridden or overcome.
Ventral PFC, Amygdala, Striatum, Midbrain, and Valuation. In addition to inputs from the insula, the dACC also receives extensive inputs from OFC/vmPFC, the amygdala, and the dopaminergic midbrain. Along with the striatum, these are all areas that have been consistently implicated in the representation of value and/or prediction error signals. Thus, inputs from these areas are consistent with the state and outcome monitoring functions of dACC proposed by the EVC model. Furthermore, the dACC projects to both ventral and dorsomedial regions of the striatum (Choi et al., 2012; Haber and Knutson, 2010). As noted earlier, fMRI evidence implicates the dACC in modulating reward signals in ventral striatum, effectively deducting the cost of cognitive control. Interactions with lPFC and Subcortical Structures Involved in Regulation The EVC model also distinguishes sharply between controlsignal speciﬁcation and direct regulation of information processing. Speciﬁcally, the model proposes that the dACC is responsible for the decision process—evaluating EVC and using this to specify the optimal control signal—while the speciﬁed control signal itself is implemented in other structures that are responsible for the top-down regulation of processing. At the broadest level, a distinction can be made between two kinds of regulative functions: One type that identiﬁes and supports

the execution of speciﬁc tasks, and is subserved primarily by cortical structures together with parts of the basal ganglia; and another that sets processing parameters more broadly by global modulation of processing and is subserved primarily by subcortical structures.
lPFC and task-speciﬁc regulation. Perhaps the structure most commonly associated with cognitive control is lPFC. A widely held view of lPFC function is that it supports the active maintenance of task representations that bias processing in pathways of posterior cortex responsible for executing speciﬁc control-demanding tasks, consistent with a regulative function in control (see Figure 2A; Miller and Cohen, 2001). Thus, according to the EVC model, lPFC can be seen as implementing the control signal to support a given task, as speciﬁed by dACC. There is a growing consensus about this distribution of functions between dACC and lPFC (Banich, 2009; Cavanagh et al., 2009; Holroyd and Yeung, 2012; Johnston et al., 2007; Kerns et al., 2004; Kouneiher et al., 2009; MacDonald et al., 2000; O’Reilly, 2010; Ridderinkhof et al., 2007; Rothe´ et al., 2011; Venkatraman and Huettel, 2012).
Given the close relationship between speciﬁcation and regulation, it is perhaps not surprising that lPFC is another region frequently coactivated with dACC in control-demanding tasks (Duncan, 2010; Niendam et al., 2012). For example, sustained activity during task performance has been observed in both dACC and lPFC. While this may reﬂect the role of lPFC in active maintenance (i.e., regulation), for dACC it could reﬂect its role in continuous online evaluation of interference or changes in payoff and corresponding adjustments in control signal intensity that drive the level of activity in lPFC. Conversely, lPFC has often been found to track response conﬂict (Laird et al., 2005; Nee et al., 2007), though this would be expected if it is responsible for augmenting control in response to the dACC’s detection of conﬂict and re-speciﬁcation of control signal intensity. While these interpretations of the ﬁndings are consistent with the division of labor proposed by the EVC model, some investigators have taken a different view.
One widely considered account suggests that the dACC itself plays a regulative function in cognitive control, in addition to or instead of the roles in monitoring and speciﬁcation proposed by the EVC model (e.g., Danielmeier et al., 2011; Dosenbach et al., 2006; Posner et al., 1988; Power and Petersen, 2013; Weissman et al., 2005). For example, Dosenbach and colleagues (2008; 2006) have argued that the dACC and anterior insula comprise a core network for task-set maintenance, responsible for sustaining attention to a task over extended periods (see also Holroyd and Yeung, 2012). In support of this, they analyzed imaging data from a large number of participants performing a diverse array of cognitive tasks. They showed that dACC and anterior insula are the only two regions that exhibit not only phasic responses to salient events, but also tonically increased responses throughout task performance consistent with a maintenance (i.e., regulative) function (but see Sridharan et al., 2008). Further evidence that dACC may support a regulative function comes from studies such as that of Danielmeier and colleagues (2011), in which dACC is shown to predict changes in attention in the absence of lPFC involvement (although, again, this could also be viewed as reﬂecting speciﬁcation rather than regulation).

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 231

Neuron
Review

The tight coupling between speciﬁcation and regulation may make it difﬁcult to produce qualitative dissociations in responses between dACC and lPFC. This may be especially so for ﬁndings from methods with limited temporal resolution, such as fMRI. One approach to this challenge is to look for quantitative biases in effects, using methods with better temporal resolution. A study by Johnston and colleagues (2007) provided such evidence from single-unit recordings in monkeys. The animals were trained to ﬁxate a cue for over a second prior to performing a pro- or antisaccade to a stimulus. Neurons were found in both dACC and lPFC that, during this prestimulus preparatory period, exhibited selectivity for the task rule that would be implemented on the upcoming trial (as in Womelsdorf et al., 2010). Importantly, they found that dACC task selectivity was greater and onset earlier than lPFC immediately following a task switch, but that this relationship reversed (i.e., dACC task selectivity gradually weakened and began later than lPFC) with more trials using the same rule associations. This pattern would seem to be consistent with a role for dACC in control signal speciﬁcation, and for lPFC in maintenance of the control signal in the service of regulation.
Another recent study has provided even ﬁner-grained evidence for a dissociation between the speciﬁcation and regulation functions of control. Measuring local ﬁeld potentials (LFPs) in both the dACC and lPFC of macaques, Rothe´ and colleagues (2011) showed that transient increases in the high-gamma LFP within dACC signaled salient events (errors and ﬁrst correct feedback; see also Quilodran et al., 2008), that were followed shortly by more sustained responses in lPFC. Moreover, while high-gamma activity was always correlated between the two regions, the lag in activity between them was only found for feedback during search periods and not when the animal was allowed to repeat the behavior for the same reward. This is consistent with the engagement of dACC in response to events calling for a re-evaluation and speciﬁcation of the control signal, and the engagement of lPFC for the representation and maintenance of that signal once speciﬁed, in the service of regulating controlled behavior.
Despite the challenges involved, some human imaging studies have also produced evidence for dissociations of responses in dACC and lPFC. For example, MacDonald and colleagues (2000) showed that dACC was more sensitive to response conﬂict and less so to the implementation of task set instructions, whereas the reverse was true for lPFC. Furthermore, while many studies have found that activity in dACC is consistently associated with the occurrence of an event that triggers adaptive responding, activity in lPFC appears to be more closely associated with the adaptations that occur after such events (e.g., Egner and Hirsch, 2005a, 2005b; Kerns, 2006; Kerns et al., 2004). Additional evidence for this dissociation comes from the study by Kouneiher and colleagues (2009), in which participants switched between two task rules. While the authors found that regions of dACC tracked the incentives for control, they found that lPFC discriminated the task required for the current trial. Furthermore, functional connectivity analyses showed that the connectivity between dACC and lPFC varied with incentive level.
The ﬁndings above are largely consistent with the division of labor between dACC and lPFC proposed by the EVC model, but they are not deﬁnitive. One alternative is that topographic

dissociations exist within dACC itself, such that some subregions support speciﬁcation and others regulation. Consistent with this possibility, ﬁndings both from humans (Orr and Weissman, 2009) and macaques (Kaping et al., 2011) have suggested that patterns of sustained activity can be localized to separate regions within dACC than transient responses signaling salient events. In both studies, a more anterior region of dACC was associated with transient responses (consistent with monitoring and speciﬁcation), whereas a more posterior region was associated with sustained responses (consistent with regulation). However, as Kaping and colleagues point out for their ﬁndings, and as noted above, sustained dACC responses could alternatively represent continuous online evaluation of interference or changes in payoff and/or corresponding adjustments required in the intensity of the control signal, consistent with monitoring and/or speciﬁcation rather than regulation. Clearly, this is an area that is in need of continued, detailed study.
Basal Ganglia and Task-Speciﬁc Regulation. There is longstanding evidence that much of prefrontal cortex (including lPFC) is reciprocally connected to the basal ganglia (and thalamus) in a series of topographically organized loops and that these structures are commonly engaged, together with prefrontal cortex, in cognitive control tasks (see Figure 1D; Choi et al., 2012; Scimeca and Badre, 2012). Frank and colleagues (Frank et al., 2001; O’Reilly and Frank, 2006; Wiecki and Frank, 2013) have proposed that these corticostriatal loops may serve as a gating mechanism, regulating action implementation as well as updating of control representations in prefrontal cortex (for related models, also see Bogacz et al., 2010; O’Reilly et al., 2002; Reynolds and O’Reilly, 2009; Rougier et al., 2005). A similar gating mechanism could play an intermediary role between the dACC’s selection of candidate control signals and their implementation by lPFC (e.g., through dorsal striatum). Though speculative, such a mechanism might account for cases in which the response latency between the two regions is longer than expected for a direct corticocortical projection (e.g., over 100 ms in the study by Rothe´ and colleagues).
Subcortical Structures and Global Regulation. Thus far, our discussion of the relationship between speciﬁcation and regulation has focused on circumstances in which control is responsible for selecting and supporting the execution of a particular task, but there are also instances in which control must specify other parameters of processing—for example, response threshold in simple decision tasks or the bias to explore rather exploit. It has been proposed that these forms of regulation are implemented by subcortical structures, through more global modulatory mechanisms. Such global inﬂuences are presumed to interact with the task-speciﬁc ones discussed above, to jointly select a particular processing pathway (lPFC), and the parameters that will apply to it (subcortical mechanisms). For the latter, the EVC model proposes a similar division of labor as for the former, with dACC responsible for monitoring and speciﬁcation, and the relevant subcortical structures responsible for regulation. The literature is largely consistent with this prediction.
For example, Frank and colleagues (Cavanagh et al., 2011; Frank, 2006; Wiecki and Frank, 2013) have proposed that projections from dACC to STN specify the threshold for evidence accumulation before initiating a motor or cognitive response and that

232 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

efferents from STN implement this threshold. To test this, Cavanagh and colleagues (2011) used scalp and intracortical EEG to measure dACC and STN activity in patients with Parkinson’s disease while undergoing deep brain stimulation (DBS) to the STN. On each trial, patients chose between pairs of stimuli that they had learned to associate with either similar or different rewards (high- and low-conﬂict trials, respectively). Activity in both dACC and STN tracked the level of decision conﬂict for a given choice. Furthermore, greater dACC activity associated with high conﬂict trials predicted slower more accurate responses (reﬂecting a higher threshold). In contrast, when DBS was applied to STN (interfering with its function), responses on these trials became more impulsive and error prone (reﬂecting lower decision thresholds), and the relationship between dACC activity and slower responding was lost. Taken together, these ﬁndings provide support for the role of dACC in specifying adaptive adjustments in threshold that are then implemented by STN.
Similarly, Aston-Jones and Cohen (2005) have proposed that dACC is involved in monitoring behavioral outcomes and deciding when it is appropriate to explore versus exploit, and that this is conveyed to LC which implements the decision by means of its broad modulatory projections to the thalamus and neocortex. This division of labor is consistent with strong anatomic connections from dACC to LC and is also supported by imaging studies implicating dACC in the decision to explore, as well as recent behavioral and psychophysiological studies suggesting a role for LC in mediating these decisions by regulating the balance between exploration and exploitation (Gilzenrat et al., 2010; Jepma and Nieuwenhuis, 2011; Murphy et al., 2011; Nieuwenhuis et al., 2005a).
The projections of dACC to subcortical modulatory structures, together with its efferents to other cortical areas, puts the dACC in a position to specify control signals of a variety of types, and over a variety of domains of processing, from signals required to regulate speciﬁc tasks (e.g., in lPFC) to broader, modulatory ones needed to inﬂuence a wide range of tasks (e.g., in STN and LC). This centralized responsibility for specifying such a wide range of control signals may also explain why dACC appears to be so consistently associated with cognitive control, and more so than other candidate structures like lPFC (e.g., Danielmeier et al., 2011; Dosenbach et al., 2006). Insofar as most of those other structures are responsible for regulation, they are dedicated either to the support of speciﬁc tasks or to speciﬁc modulatory forms of control. Accordingly, they will be engaged only when the demands for control involve that particular regulative function. In contrast, as the central hub in control speciﬁcation, the dACC would be expected to be engaged in any circumstance demanding the speciﬁcation of a control signal. Control Hierarchies Several recent studies have proposed that separate regions within the lPFC might encode information pertinent to different levels of task structure, with higher-level processes engaging more anterior regions (Badre and D’Esposito, 2009; Koechlin et al., 2003; though see Crittenden and Duncan, 2012; Reynolds et al., 2012). Similar proposals have been made regarding the organization of dACC. For example, Kouneiher and colleagues (2009) showed that regions within dACC and pre-SMA differentially encode task incentives for a block of trials versus individual

trials within a block. Furthermore, the patterns of connectivity between dACC and lPFC were found to be modulated by motivation type, with anterior regions of dACC and lPFC being engaged by block-level incentives and more posterior regions exhibiting a similar pattern for trial-level incentives.
Evidence that the dACC is topographically organized to represent the motivation for control at different levels of temporal abstraction is broadly consistent with a proposal by Holroyd and Yeung (2011, 2012), according to which the dACC is specifically involved in the control of superordinate, temporally extended, actions. This account is theoretically motivated by hierarchical reinforcement learning (HRL; Botvinick et al., 2009b) and has found support in the recent ﬁnding that prediction error signals speciﬁcally anticipated by HRL are observed within dACC (Ribas-Fernandes et al., 2011). A related account suggests that representations within dACC may be organized by the level of abstraction or complexity of a task (Venkatraman and Huettel, 2012; see Nachev et al., 2008, for an analogous account). For example, Venkatraman and colleagues (2009) showed that progressively anterior regions of dACC signaled increasingly complex task demands, from conﬂicts between speciﬁc motor actions at the posterior extent to conﬂicts between high-level strategies at the anterior extent. This group has further shown that these regions within dACC show differential patterns of resting-state functional connectivity with lPFC regions that Koechlin and colleagues (Koechlin et al., 2003; Kouneiher et al., 2009) have shown to be involved in regulative aspects of control at similarly increasing levels of temporal abstractness (Taren et al., 2011; Venkatraman and Huettel, 2012; Venkatraman et al., 2009).
The EVC model does not speak directly to the issue of hierarchical organization of control. According to the EVC model, the dACC should be engaged by control-demanding behaviors irrespective of their level of abstractness or temporal extent, whether these involve individual motor actions, more abstract strategies, or temporally extended tasks. The primary determinant of dACC engagement is whether the behavior involves processes that cannot rely fully on prespeciﬁed parameters—that is, that are not automatic. In this respect, the EVC model provides a role for dACC in a broader range of control-demanding behaviors than is predicted by theories linking it to more hierarchically organized or temporally extended behaviors. Furthermore, in addition to the idea that dACC is involved in specifying task identity, the EVC model integrates the idea that dACC is also involved in specifying control intensity, a function not typically addressed by the theories discussed above.
The ﬁndings by Venkatraman et al. (2009) are intriguing in part because they lend credence to an implicit assumption of the EVC model: that cognitive control signals are analogous to motor control signals and therefore undergo a similar process of optimization. Anatomic studies have revealed increasingly motorrelated cytoarchitecture and patterns of connectivity as one traverses dorsomedial PFC from anterior dACC to pre-SMA and SMA (Figure 1C; Morecraft et al., 2012; Nachev et al., 2008; Vogt et al., 2003). This suggests that, rather than supporting a heterogeneity of functions, these regions may serve a similar set of functions applied over a range of abstractness of control signals. Accordingly, while we have focused on the evaluation

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 233

Neuron
Review

of cognitive control signals in the EVC model, the same notation has been applied in different areas of the action selection and motor control literature. The EVC term itself generalizes what is referred to as a Q-value in the reinforcement learning literature (mapping the value of an action in a given state; Balleine et al., 2008; Sutton and Barto, 1998), and previous work has already described how the strength (i.e., vigor) of a motor action can be weighed against the attendant physical effort costs (Niv, 2007; Niv et al., 2006).
Conclusions The challenge of understanding the role of the dACC in cognition and behavior is daunting. The experimental evidence accumulated to date contains a remarkable diversity of ﬁndings that have lent themselves to a wide range of interpretations. Here, we have proposed an account of dACC function that attempts to accommodate this diversity, while at the same time organizing it into a coherent picture. In particular, we have proposed that the dACC leverages a wide range of information in order to estimate the EVC, a quantity integrating the expected payoffs and costs of candidate control signals. Based on the results of this computation, the dACC speciﬁes both the identity and intensity of the control signals that maximize estimated EVC. These are then implemented by regulatory structures that are responsible for actually effecting the changes in information processing in the rest of the brain required to perform the speciﬁed task(s).
The EVC model owes many of its components to previous theoretical proposals, both from our own labs and from others. By ﬁtting these pieces together, and accommodating some new ones within a single integrative account, we hope that the EVC model provides a useful theoretical reference point for future research. Like any model, it raises new questions alongside the ones it attempts to answer: how is a set of candidate control signals initially learned? How might the EVC be feasibly (and perhaps only approximately) estimated by neural mechanisms? If cognitive control is inherently costly, what exact form does the cost function assume? And what costs might attach to the estimation of EVC itself? Finally, how are the component functions proposed by the model implemented and organized within the neural architecture of the dACC? Given the fast pace of research in this area, we feel conﬁdent that the next few years will yield data pertinent to these questions, and to the expected value of the EVC model itself.
ACKNOWLEDGMENTS
This work is supported by the C.V. Starr Foundation (A.S.), the National Institute of Mental Health R01MH098815-01 (M.M.B), and the John Templeton Foundation. The opinions expressed in this publication are those of the authors and do not necessarily reﬂect the views of the John Templeton Foundation.
REFERENCES
Aarts, E., Roelofs, A., and van Turennout, M. (2008). Anticipatory activity in anterior cingulate cortex can be independent of conﬂict and error likelihood. J. Neurosci. 28, 4671–4678.
Alexander, W.H., and Brown, J.W. (2011). Medial prefrontal cortex as an action-outcome predictor. Nat. Neurosci. 14, 1338–1344.

Alexander, M.P., Stuss, D.T., Picton, T., Shallice, T., and Gillingham, S. (2007). Regional frontal injuries cause distinct impairments in cognitive control. Neurology 68, 1515–1523.
Amemori, K.-I., and Graybiel, A.M. (2012). Localized microstimulation of primate pregenual cingulate cortex induces negative decision-making. Nat. Neurosci. 15, 776–785.
Amiez, C., Joseph, J.-P., and Procyk, E. (2005). Anterior cingulate error-related activity is modulated by predicted reward. Eur. J. Neurosci. 21, 3447–3452.
Amiez, C., Sallet, J., Procyk, E., and Petrides, M. (2012). Modulation of feedback related activity in the rostral anterior cingulate cortex during trial and error exploration. Neuroimage 63, 1078–1090.
Aron, A.R., and Poldrack, R.A. (2006). Cortical and subcortical contributions to Stop signal response inhibition: role of the subthalamic nucleus. J. Neurosci. 26, 2424–2433.
Aron, A.R., Behrens, T.E.J., Smith, S., Frank, M.J., and Poldrack, R.A. (2007). Triangulating a cognitive control network using diffusion-weighted magnetic resonance imaging (MRI) and functional MRI. J. Neurosci. 27, 3743–3752.
Aston-Jones, G., and Cohen, J.D. (2005). An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance. Annu. Rev. Neurosci. 28, 403–450.
Badre, D., and D’Esposito, M. (2009). Is the rostro-caudal axis of the frontal lobe hierarchical? Nat. Rev. Neurosci. 10, 659–669.
Balleine, B.W., Daw, N.D., and O’Doherty, J.P. (2008). Multiple forms of value learning and the function of dopamine. In Neuroeconomics: Decision Making and the Brain, P. Glimcher, C.F. Camerer, E. Fehr, and R.A. Poldrack, eds. (London: Academic Press), pp. 367–385.
Banich, M.T. (2009). Executive function: the search for an integrated account. Curr. Dir. Psychol. Sci. 18, 89–94.
Barch, D.M., Braver, T.S., Sabb, F.W., and Noll, D.C. (2000). Anterior cingulate and the monitoring of response conﬂict: evidence from an fMRI study of overt verb generation. J. Cogn. Neurosci. 12, 298–309.
Bartra, O., McGuire, J.T., and Kable, J.W. (2013). The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value. Neuroimage 76, 412–427.
Beckmann, M., Johansen-Berg, H., and Rushworth, M.F.S. (2009). Connectivity-based parcellation of human cingulate cortex and its relation to functional specialization. J. Neurosci. 29, 1175–1190.
Behrens, T.E.J., Woolrich, M.W., Walton, M.E., and Rushworth, M.F.S. (2007). Learning the value of information in an uncertain world. Nat. Neurosci. 10, 1214–1221.
Blair, K.S., Marsh, A.A., Morton, J., Vythilingam, M., Jones, M., Mondillo, K., Pine, D.C., Drevets, W.C., and Blair, J.R. (2006). Choosing the lesser of two evils, the better of two goods: specifying the roles of ventromedial prefrontal cortex and dorsal anterior cingulate in object choice. J. Neurosci. 26, 11379–11386.
Bland, A.R., and Schaefer, A. (2011). Electrophysiological correlates of decision making under varying levels of uncertainty. Brain Res. 1417, 55–66.
Bogacz, R., Brown, E., Moehlis, J., Holmes, P., and Cohen, J.D. (2006). The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks. Psychol. Rev. 113, 700–765.
Bogacz, R., Wagenmakers, E.-J., Forstmann, B.U., and Nieuwenhuis, S. (2010). The neural basis of the speed-accuracy tradeoff. Trends Neurosci. 33, 10–16.
Boorman, E.D., Rushworth, M.F., and Behrens, T.E. (2013). Ventromedial prefrontal and anterior cingulate cortex adopt choice and default reference frames during sequential multi-alternative choice. J. Neurosci. 33, 2242–2253.
Botvinick, M.M. (2007). Conﬂict monitoring and decision making: reconciling two perspectives on anterior cingulate function. Cogn. Affect. Behav. Neurosci. 7, 356–366.
Botvinick, M.M., and Cohen, J.D. (2013). The computational and neural basis of cognitive control: charted territory and new frontiers. Cogn. Sci., in press.

234 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Botvinick, M., Nystrom, L.E., Fissell, K., Carter, C.S., and Cohen, J.D. (1999). Conﬂict monitoring versus selection-for-action in anterior cingulate cortex. Nature 402, 179–181.
Botvinick, M.M., Braver, T.S., Barch, D.M., Carter, C.S., and Cohen, J.D. (2001). Conﬂict monitoring and cognitive control. Psychol. Rev. 108, 624–652.
Botvinick, M.M., Cohen, J.D., and Carter, C.S. (2004). Conﬂict monitoring and anterior cingulate cortex: an update. Trends Cogn. Sci. 8, 539–546.
Botvinick, M., Jha, A.P., Bylsma, L.M., Fabian, S.A., Solomon, P.E., and Prkachin, K.M. (2005). Viewing facial expressions of pain engages cortical areas involved in the direct experience of pain. Neuroimage 25, 312–319.
Botvinick, M.M., Huffstetler, S., and McGuire, J.T. (2009a). Effort discounting in human nucleus accumbens. Cogn. Affect. Behav. Neurosci. 9, 16–27.
Botvinick, M.M., Niv, Y., and Barto, A.C. (2009b). Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective. Cognition 113, 262–280.
Braver, T.S., and Cohen, J.D. (2000). On the control of control: the role of dopamine in regulating prefrontal function and working memory. In Attention and Performance XVIII; Control of Cognitive Processes, S. Monsell and J. Driver, eds. (Cambridge, MA: MIT Press), pp. 713–737.
Brown, J.W. (2011). Medial prefrontal cortex activity correlates with time-ontask: what does this tell us about theories of cognitive control? Neuroimage 57, 314–315.
Brown, J.W., and Braver, T.S. (2005). Learned predictions of error likelihood in the anterior cingulate cortex. Science 307, 1118–1121.
Bryden, D.W., Johnson, E.E., Tobia, S.C., Kashtelyan, V., and Roesch, M.R. (2011). Attention for learning signals in anterior cingulate cortex. J. Neurosci. 31, 18266–18274.
Bush, G., Luu, P., and Posner, M.I. (2000). Cognitive and emotional inﬂuences in anterior cingulate cortex. Trends Cogn. Sci. 4, 215–222.
Cai, X., and Padoa-Schioppa, C. (2012). Neuronal encoding of subjective value in dorsal and ventral anterior cingulate cortex. J. Neurosci. 32, 3791–3808.
Carter, C.S., Braver, T.S., Barch, D.M., Botvinick, M.M., Noll, D., and Cohen, J.D. (1998). Anterior cingulate cortex, error detection, and the online monitoring of performance. Science 280, 747–749.
Carter, C.S., Macdonald, A.M., Botvinick, M.M., Ross, L.L., Stenger, V.A., Noll, D., and Cohen, J.D. (2000). Parsing executive processes: strategic vs. evaluative functions of the anterior cingulate cortex. Proc. Natl. Acad. Sci. USA 97, 1944–1948.
Cavanagh, J.F., Cohen, M.X., and Allen, J.J.B. (2009). Prelude to and resolution of an error: EEG phase synchrony reveals cognitive control dynamics during action monitoring. J. Neurosci. 29, 98–105.
Cavanagh, J.F., Wiecki, T.V., Cohen, M.X., Figueroa, C.M., Samanta, J., Sherman, S.J., and Frank, M.J. (2011). Subthalamic nucleus stimulation reverses mediofrontal inﬂuence over decision threshold. Nat. Neurosci. 14, 1462–1467.
Cavanagh, J.F., Figueroa, C.M., Cohen, M.X., and Frank, M.J. (2012). Frontal theta reﬂects uncertainty and unexpectedness during exploration and exploitation. Cereb. Cortex 22, 2575–2586.
Cavanagh, J.F., Eisenberg, I., Guitart-Masip, M., Huys, Q., and Frank, M.J. (2013). Frontal theta overrides pavlovian learning biases. J. Neurosci. 33, 8541–8548.
Chein, J.M., and Schneider, W. (2005). Neuroimaging studies of practicerelated change: fMRI and meta-analytic evidence of a domain-general control network for learning. Brain Res. Cogn. Brain Res. 25, 607–623.
Chein, J.M., and Schneider, W. (2012). The brain’s learning and control architecture. Curr. Dir. Psychol. Sci. 21, 78–84.
Choi, E.Y., Yeo, B.T.T., and Buckner, R.L. (2012). The organization of the human striatum estimated by intrinsic functional connectivity. J. Neurophysiol. 108, 2242–2263.
Cikara, M., Botvinick, M.M., and Fiske, S.T. (2011). Us versus them: social identity shapes neural responses to intergroup competition and harm. Psychol. Sci. 22, 306–313.

Cockburn, J., and Frank, M.J. (2011). Reinforcement learning, conﬂict monitoring, and cognitive control: An integrative model of cingulate-striatal interactions and the ERN. In Neural Basis of Motivational and Cognitive Control, M.F.S. Rushworth and N. Yeung, eds. (Cambridge: MIT Press), pp. 311–331.
Cohen, J.D., and Holmes, P. (2013). Optimality and some of its discontents. Trends Cogn. Sci., in press.
Cohen, J.D., and Servan-Schreiber, D. (1992). Context, cortex, and dopamine: a connectionist approach to behavior and biology in schizophrenia. Psychol. Rev. 99, 45–77.
Cohen, J.D., Dunbar, K., and McClelland, J.L. (1990). On the control of automatic processes: a parallel distributed processing account of the Stroop effect. Psychol. Rev. 97, 332–361.
Cole, M.W., Yeung, N., Freiwald, W.A., and Botvinick, M.M. (2009). Cingulate cortex: diverging data from humans and monkeys. Trends Neurosci. 32, 566–574.
Cowen, S.L., Davis, G.A., and Nitz, D.A. (2012). Anterior cingulate neurons in the rat map anticipated effort and reward to their associated action sequences. J. Neurophysiol. 107, 2393–2407.
Craig, A.D. (2002). How do you feel? Interoception: the sense of the physiological condition of the body. Nat. Rev. Neurosci. 3, 655–666.
Craig, A.D.B. (2009). How do you feel—now? The anterior insula and human awareness. Nat. Rev. Neurosci. 10, 59–70.
Crittenden, B.M., and Duncan, J. (2012). Task difﬁculty manipulation reveals multiple demand activity but no frontal lobe hierarchy. Cereb. Cortex. Published online November 6, 2012. http://dx.doi.org/10.1093/cercor/bhs333.
Crottaz-Herbette, S., and Menon, V. (2006). Where and when the anterior cingulate cortex modulates attentional response: combined fMRI and ERP evidence. J. Cogn. Neurosci. 18, 766–780.
Croxson, P.L., Walton, M.E., O’Reilly, J.X., Behrens, T.E.J., and Rushworth, M.F.S. (2009). Effort-based cost-beneﬁt valuation and the human brain. J. Neurosci. 29, 4531–4541.
Cunningham, W.A., Johnson, M.K., Raye, C.L., Chris Gatenby, J., Gore, J.C., and Banaji, M.R. (2004). Separable neural components in the processing of black and white faces. Psychol. Sci. 15, 806–813.
Danielmeier, C., and Ullsperger, M. (2011). Post-error adjustments. Front Psychol 2, 233.
Danielmeier, C., Eichele, T., Forstmann, B.U., Tittgemeyer, M., and Ullsperger, M. (2011). Posterior medial frontal cortex activity predicts post-error adaptations in task-related visual and motor areas. J. Neurosci. 31, 1780–1789.
Daw, N.D., O’Doherty, J.P., Dayan, P., Seymour, B., and Dolan, R.J. (2006). Cortical substrates for exploratory decisions in humans. Nature 441, 876–879.
Dayan, P. (2012). How to set the switches on this thing. Curr. Opin. Neurobiol. 22, 1068–1074.
De Martino, B., Kumaran, D., Seymour, B., and Dolan, R.J. (2006). Frames, biases, and rational decision-making in the human brain. Science 313, 684–687.
Debener, S., Ullsperger, M., Siegel, M., Fiehler, K., von Cramon, D.Y., and Engel, A.K. (2005). Trial-by-trial coupling of concurrent electroencephalogram and functional magnetic resonance imaging identiﬁes the dynamics of performance monitoring. J. Neurosci. 25, 11730–11737.
Desimone, R., and Duncan, J. (1995). Neural mechanisms of selective visual attention. Annu. Rev. Neurosci. 18, 193–222.
Devinsky, O., Morrell, M.J., and Vogt, B.A. (1995). Contributions of anterior cingulate cortex to behaviour. Brain 118, 279–306.
Dixon, M.L., and Christoff, K. (2012). The decision to engage cognitive control is driven by expected reward-value: neural and behavioral evidence. PLoS ONE 7, e51637.
Dosenbach, N.U.F., Visscher, K.M., Palmer, E.D., Miezin, F.M., Wenger, K.K., Kang, H.C., Burgund, E.D., Grimes, A.L., Schlaggar, B.L., and Petersen, S.E. (2006). A core system for the implementation of task sets. Neuron 50, 799–812.

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 235

Neuron
Review

Dosenbach, N.U., Fair, D.A., Cohen, A.L., Schlaggar, B.L., and Petersen, S.E. (2008). A dual-networks architecture of top-down control. Trends Cogn. Sci. 12, 99–105.
Duncan, J. (2010). The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour. Trends Cogn. Sci. 14, 172–179.
Durstewitz, D., Vittoz, N.M., Floresco, S.B., and Seamans, J.K. (2010). Abrupt transitions between prefrontal neural ensemble states accompany behavioral transitions during rule learning. Neuron 66, 438–448.
Egner, T., and Hirsch, J. (2005a). Cognitive control mechanisms resolve conﬂict through cortical ampliﬁcation of task-relevant information. Nat. Neurosci. 8, 1784–1790.
Egner, T., and Hirsch, J. (2005b). The neural correlates and functional integration of cognitive control in a Stroop task. Neuroimage 24, 539–547.
Eisenberger, N.I., and Lieberman, M.D. (2004). Why rejection hurts: a common neural alarm system for physical and social pain. Trends Cogn. Sci. 8, 294–300.
Emeric, E.E., Brown, J.W., Leslie, M., Pouget, P., Stuphorn, V., and Schall, J.D. (2008). Performance monitoring local ﬁeld potentials in the medial frontal cortex of primates: anterior cingulate cortex. J. Neurophysiol. 99, 759–772.
Fellows, L.K., and Farah, M.J. (2005). Is anterior cingulate cortex necessary for cognitive control? Brain 128, 788–796.
Figner, B., Knoch, D., Johnson, E.J., Krosch, A.R., Lisanby, S.H., Fehr, E., and Weber, E.U. (2010). Lateral prefrontal cortex and self-control in intertemporal choice. Nat. Neurosci. 13, 538–539.
Fleming, S.M., Thomas, C.L., and Dolan, R.J. (2010). Overcoming status quo bias in the human brain. Proc. Natl. Acad. Sci. USA 107, 6005–6009.
Fleming, S.M., Huijgen, J., and Dolan, R.J. (2012). Prefrontal contributions to metacognition in perceptual decision making. J. Neurosci. 32, 6117–6125.
Floresco, S.B., St Onge, J.R., Ghods-Shariﬁ, S., and Winstanley, C.A. (2008). Cortico-limbic-striatal circuits subserving different forms of cost-beneﬁt decision making. Cogn. Affect. Behav. Neurosci. 8, 375–389.
Forster, S.E., Carter, C.S., Cohen, J.D., and Cho, R.Y. (2011). Parametric manipulation of the conﬂict signal and control-state adaptation. J. Cogn. Neurosci. 23, 923–935.
Forstmann, B.U., Brass, M., Koch, I., and von Cramon, D.Y. (2006). Voluntary selection of task sets revealed by functional magnetic resonance imaging. J. Cogn. Neurosci. 18, 388–398.
Forstmann, B.U., Dutilh, G., Brown, S., Neumann, J., von Cramon, D.Y., Ridderinkhof, K.R., and Wagenmakers, E.-J. (2008). Striatum and pre-SMA facilitate decision-making under time pressure. Proc. Natl. Acad. Sci. USA 105, 17538–17542.
Forstmann, B.U., Anwander, A., Scha¨ fer, A., Neumann, J., Brown, S., Wagenmakers, E.-J., Bogacz, R., and Turner, R. (2010). Cortico-striatal connections predict control over speed and accuracy in perceptual decision making. Proc. Natl. Acad. Sci. USA 107, 15916–15920.
Frank, M.J. (2006). Hold your horses: a dynamic computational role for the subthalamic nucleus in decision making. Neural Netw. 19, 1120–1136.
Frank, M.J., Loughry, B., and O’Reilly, R.C. (2001). Interactions between frontal cortex and basal ganglia in working memory: a computational model. Cogn. Affect. Behav. Neurosci. 1, 137–160.
Fritz, J., and Dreisbach, G. (2013). Conﬂicts as aversive signals: conﬂict priming increases negative judgments for neutral stimuli. Cogn. Affect. Behav. Neurosci. 13, 311–317.
Gabriel, M., and Orona, E. (1982). Parallel and serial processes of the prefrontal and cingulate cortical systems during behavioral learning. Brain Res. Bull. 8, 781–785.
Gaymard, B., Rivaud, S., Cassarini, J.F., Dubard, T., Rancurel, G., Agid, Y., and Pierrot-Deseilligny, C. (1998). Effects of anterior cingulate cortex lesions on ocular saccades in humans. Exp. Brain Res. 120, 173–183.
Gehring, W.J., and Willoughby, A.R. (2002). The medial frontal cortex and the rapid processing of monetary gains and losses. Science 295, 2279–2282.

Gilzenrat, M.S., Nieuwenhuis, S., Jepma, M., and Cohen, J.D. (2010). Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function. Cogn. Affect. Behav. Neurosci. 10, 252–269.
Gla¨ scher, J., Adolphs, R., Damasio, H., Bechara, A., Rudrauf, D., Calamia, M., Paul, L.K., and Tranel, D. (2012). Lesion mapping of cognitive control and value-based decision making in the prefrontal cortex. Proc. Natl. Acad. Sci. USA 109, 14681–14686.
Gluth, S., Rieskamp, J., and Bu¨ chel, C. (2012). Deciding when to decide: timevariant sequential sampling models explain the emergence of value-based decisions in the human brain. J. Neurosci. 32, 10686–10698.
Gratton, G., Coles, M.G., and Donchin, E. (1992). Optimizing the use of information: strategic control of activation of responses. J. Exp. Psychol. Gen. 121, 480–506.
Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M., and Cohen, J.D. (2004). The neural bases of cognitive conﬂict and control in moral judgment. Neuron 44, 389–400.
Grinband, J., Savitskaya, J., Wager, T.D., Teichert, T., Ferrera, V.P., and Hirsch, J. (2011a). Conﬂict, error likelihood, and RT: response to Brown & Yeung et al. Neuroimage 57, 320–322.
Grinband, J., Savitskaya, J., Wager, T.D., Teichert, T., Ferrera, V.P., and Hirsch, J. (2011b). The dorsal medial frontal cortex is sensitive to time on task, not response conﬂict or error likelihood. Neuroimage 57, 303–311.
Guerin, S.A., and Miller, M.B. (2011). Parietal cortex tracks the amount of information retrieved even when it is not the basis of a memory decision. Neuroimage 55, 801–807.
Haber, S.N., and Knutson, B. (2010). The reward circuit: linking primate anatomy and human imaging. Neuropsychopharmacology 35, 4–26.
Hampton, A.N., and O’Doherty, J.P. (2007). Decoding the neural substrates of reward-related decision making with functional MRI. Proc. Natl. Acad. Sci. USA 104, 1377–1382.
Hayden, B.Y., and Platt, M.L. (2010). Neurons in anterior cingulate cortex multiplex information about reward and action. J. Neurosci. 30, 3339–3346.
Hayden, B.Y., Heilbronner, S.R., Pearson, J.M., and Platt, M.L. (2011a). Surprise signals in anterior cingulate cortex: neuronal encoding of unsigned reward prediction errors driving adjustment in behavior. J. Neurosci. 31, 4178–4187.
Hayden, B.Y., Pearson, J.M., and Platt, M.L. (2011b). Neuronal basis of sequential foraging decisions in a patchy environment. Nat. Neurosci. 14, 933–939.
Haynes, J.-D., Sakai, K., Rees, G., Gilbert, S., Frith, C., and Passingham, R.E. (2007). Reading hidden intentions in the human brain. Curr. Biol. 17, 323–328.
Hazy, T.E., Frank, M.J., and O’reilly, R.C. (2007). Towards an executive without a homunculus: computational models of the prefrontal cortex/basal ganglia system. Philos. Trans. R. Soc. Lond. B Biol. Sci. 362, 1601–1613.
Hillman, K.L., and Bilkey, D.K. (2010). Neurons in the rat anterior cingulate cortex dynamically encode cost-beneﬁt in a spatial decision-making task. J. Neurosci. 30, 7705–7713.
Hillman, K.L., and Bilkey, D.K. (2012). Neural encoding of competitive effort in the anterior cingulate cortex. Nat. Neurosci. 15, 1290–1297.
Hirsh, J.B., Mar, R.A., and Peterson, J.B. (2012). Psychological entropy: a framework for understanding uncertainty-related anxiety. Psychol. Rev. 119, 304–320.
Ho, T.C., Brown, S., and Serences, J.T. (2009). Domain general mechanisms of perceptual decision making in human cortex. J. Neurosci. 29, 8675–8687.
Holroyd, C.B., and Coles, M.G.H. (2002). The neural basis of human error processing: reinforcement learning, dopamine, and the error-related negativity. Psychol. Rev. 109, 679–709.
Holroyd, C.B., and Yeung, N. (2011). An integrative theory of anterior cingulate cortex function: Option selection in hierarchical reinforcement learning. In Neural Basis of Motivational and Cognitive Control, R.B. Mars, J. Sallet, M.F.S. Rushworth, and N. Yeung, eds. (Cambridge, MA: MIT Press), pp. 333–349.

236 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Holroyd, C.B., and Yeung, N. (2012). Motivation of extended behaviors by anterior cingulate cortex. Trends Cogn. Sci. 16, 122–128.
Holroyd, C.B., Larsen, J.T., and Cohen, J.D. (2004a). Context dependence of the event-related brain potential associated with reward and punishment. Psychophysiology 41, 245–253.
Holroyd, C.B., Nieuwenhuis, S., Yeung, N., Nystrom, L., Mars, R.B., Coles, M.G.H., and Cohen, J.D. (2004b). Dorsal anterior cingulate cortex shows fMRI response to internal and external error signals. Nat. Neurosci. 7, 497–498.
Hutchison, R.M., Womelsdorf, T., Gati, J.S., Leung, L.S., Menon, R.S., and Everling, S. (2012). Resting-state connectivity identiﬁes distinct functional networks in macaque cingulate cortex. Cereb. Cortex 22, 1294–1308.
Isomura, Y., Ito, Y., Akazawa, T., Nambu, A., and Takada, M. (2003). Neural coding of ‘‘attention for action’’ and ‘‘response selection’’ in primate anterior cingulate cortex. J. Neurosci. 23, 8002–8012.
Ito, S., Stuphorn, V., Brown, J.W., and Schall, J.D. (2003). Performance monitoring by the anterior cingulate cortex during saccade countermanding. Science 302, 120–122.
Ivanoff, J., Branning, P., and Marois, R. (2008). fMRI evidence for a dual process account of the speed-accuracy tradeoff in decision-making. PLoS ONE 3, e2635.
Jahfari, S., Waldorp, L., van den Wildenberg, W.P.M., Scholte, H.S., Ridderinkhof, K.R., and Forstmann, B.U. (2011). Effective connectivity reveals important roles for both the hyperdirect (fronto-subthalamic) and the indirect (frontostriatal-pallidal) fronto-basal ganglia pathways during response inhibition. J. Neurosci. 31, 6891–6899.
Jepma, M., and Nieuwenhuis, S. (2011). Pupil diameter predicts changes in the exploration-exploitation trade-off: evidence for the adaptive gain theory. J. Cogn. Neurosci. 23, 1587–1596.
Jessup, R.K., Busemeyer, J.R., and Brown, J.W. (2010). Error effects in anterior cingulate cortex reverse when error likelihood is high. J. Neurosci. 30, 3467–3472.
Johns, M., Inzlicht, M., and Schmader, T. (2008). Stereotype threat and executive resource depletion: examining the inﬂuence of emotion regulation. J. Exp. Psychol. Gen. 137, 691–705.
Johnston, K., Levin, H.M., Koval, M.J., and Everling, S. (2007). Top-down control-signal dynamics in anterior cingulate and prefrontal cortex neurons following task switching. Neuron 53, 453–462.
Kahnt, T., Park, S.Q., Cohen, M.X., Beck, A., Heinz, A., and Wrase, J. (2009). Dorsal striatal-midbrain connectivity in humans predicts how reinforcements are used to guide decisions. J. Cogn. Neurosci. 21, 1332–1345.
Kahnt, T., Grueschow, M., Speck, O., and Haynes, J.-D. (2011). Perceptual learning and decision-making in human medial frontal cortex. Neuron 70, 549–559.
Kaping, D., Vinck, M., Hutchison, R.M., Everling, S., and Womelsdorf, T. (2011). Speciﬁc contributions of ventromedial, anterior cingulate, and lateral prefrontal cortex for attentional selection and stimulus valuation. PLoS Biol. 9, e1001224.
Karlsson, M.P., Tervo, D.G.R., and Karpova, A.Y. (2012). Network resets in medial prefrontal cortex mark the onset of behavioral uncertainty. Science 338, 135–139.
Kawamoto, T., Onoda, K., Nakashima, K.i., Nittono, H., Yamaguchi, S., and Ura, M. (2012). Is dorsal anterior cingulate cortex activation in response to social exclusion due to expectancy violation? An fMRI study. Front. Evol. Neurosci. 4, 1.
Kennerley, S.W., Dahmubed, A.F., Lara, A.H., and Wallis, J.D. (2009). Neurons in the frontal lobe encode the value of multiple decision variables. J. Cogn. Neurosci. 21, 1162–1178.
Kennerley, S.W., Behrens, T.E.J., and Wallis, J.D. (2011). Double dissociation of value computations in orbitofrontal and anterior cingulate neurons. Nat. Neurosci. 14, 1581–1589.
Kerns, J.G. (2006). Anterior cingulate and prefrontal cortex activity in an FMRI study of trial-to-trial adjustments on the Simon task. Neuroimage 33, 399–405.

Kerns, J.G., Cohen, J.D., MacDonald, A.W., 3rd, Cho, R.Y., Stenger, V.A., and Carter, C.S. (2004). Anterior cingulate conﬂict monitoring and adjustments in control. Science 303, 1023–1026.
Khamassi, M., Wilson, C.R.E., Rothe´ , M., Quilodran, R., Dominey, P.F., and Procyk, E. (2010). Meta-learning, cognitive control, and physiological interactions between medial and lateral prefrontal cortex. In Neural Bases of Motivational and Cognitive Control, R. Mars, J. Sallet, M.F.S. Rushworth, and N. Yeung, eds. (Cambridge, MA: MIT Press), pp. 351–370.
King, J.A., Korb, F.M., von Cramon, D.Y., and Ullsperger, M. (2010). Post-error behavioral adjustments are facilitated by activation and suppression of taskrelevant and task-irrelevant information processing. J. Neurosci. 30, 12759– 12769.
Knutson, B., Taylor, J., Kaufman, M., Peterson, R., and Glover, G. (2005). Distributed neural representation of expected value. J. Neurosci. 25, 4806– 4812.
Koechlin, E., Ody, C., and Kouneiher, F. (2003). The architecture of cognitive control in the human prefrontal cortex. Science 302, 1181–1185.
Kolling, N., Behrens, T.E.J., Mars, R.B., and Rushworth, M.F.S. (2012). Neural mechanisms of foraging. Science 336, 95–98.
Kool, W., and Botvinick, M.M. (2012). A labor/leisure tradeoff in cognitive control. J. Exp. Psychol. Gen. Published online December 10, 2012. http://dx.doi. org/10.1037/a0031048.
Kool, W., McGuire, J.T., Rosen, Z.B., and Botvinick, M.M. (2010). Decision making and the avoidance of cognitive demand. J. Exp. Psychol. Gen. 139, 665–682.
Kouneiher, F., Charron, S., and Koechlin, E. (2009). Motivation and cognitive control in the human prefrontal cortex. Nat. Neurosci. 12, 939–945.
Krebs, R.M., Boehler, C.N., Roberts, K.C., Song, A.W., and Woldorff, M.G. (2012). The involvement of the dopaminergic midbrain and cortico-striatalthalamic circuits in the integration of reward prospect and attentional task demands. Cereb. Cortex 22, 607–615.
Laird, A.R., McMillan, K.M., Lancaster, J.L., Kochunov, P., Turkeltaub, P.E., Pardo, J.V., and Fox, P.T. (2005). A comparison of label-based review and ALE meta-analysis in the Stroop task. Hum. Brain Mapp. 25, 6–21.
Lamm, C., Decety, J., and Singer, T. (2011). Meta-analytic evidence for common and distinct neural networks associated with directly experienced pain and empathy for pain. Neuroimage 54, 2492–2502.
Landmann, C., Dehaene, S., Pappata, S., Jobert, A., Bottlaender, M., Roumenov, D., and Le Bihan, D. (2007). Dynamics of prefrontal and cingulate activity during a reward-based logical deduction task. Cereb. Cortex 17, 749–759.
Levy, D.J., and Glimcher, P.W. (2012). The root of all value: a neural common currency for choice. Curr. Opin. Neurobiol. 22, 1027–1038.
Li, F., Li, M., Cao, W., Xu, Y., Luo, Y., Zhong, X., Zhang, J., Dai, R., Zhou, X.-F., Li, Z., and Li, C. (2012). Anterior cingulate cortical lesion attenuates food foraging in rats. Brain Res. Bull. 88, 602–608.
Liu, X., Hairston, J., Schrier, M., and Fan, J. (2011). Common and distinct networks underlying reward valence and processing stages: a meta-analysis of functional neuroimaging studies. Neurosci. Biobehav. Rev. 35, 1219–1236.
Løvstad, M., Funderud, I., Meling, T., Kra¨ mer, U.M., Voytek, B., Due-Tønnessen, P., Endestad, T., Lindgren, M., Knight, R.T., and Solbakk, A.K. (2012). Anterior cingulate cortex and cognitive control: neuropsychological and electrophysiological ﬁndings in two patients with lesions to dorsomedial prefrontal cortex. Brain Cogn. 80, 237–249.
MacDonald, A.W., 3rd, Cohen, J.D., Stenger, V.A., and Carter, C.S. (2000). Dissociating the role of the dorsolateral prefrontal and anterior cingulate cortex in cognitive control. Science 288, 1835–1838.
Magno, E., Foxe, J.J., Molholm, S., Robertson, I.H., and Garavan, H. (2006). The anterior cingulate and error avoidance. J. Neurosci. 26, 4769–4773.
Mansouri, F.A., Tanaka, K., and Buckley, M.J. (2009). Conﬂict-induced behavioural adjustment: a clue to the executive functions of the prefrontal cortex. Nat. Rev. Neurosci. 10, 141–152.

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 237

Neuron
Review

Marsh, A.A., Blair, K.S., Vythilingam, M., Busis, S., and Blair, R.J.R. (2007). Response options and expectations of reward in decision-making: the differential roles of dorsal and rostral anterior cingulate cortex. Neuroimage 35, 979–988.
Matsumoto, K., Suzuki, W., and Tanaka, K. (2003). Neuronal correlates of goalbased motor selection in the prefrontal cortex. Science 301, 229–232.
Matsumoto, M., Matsumoto, K., Abe, H., and Tanaka, K. (2007). Medial prefrontal cell activity signaling prediction errors of action values. Nat. Neurosci. 10, 647–656.
Matsuzaka, Y., Akiyama, T., Tanji, J., and Mushiake, H. (2012). Neuronal activity in the primate dorsomedial prefrontal cortex contributes to strategic selection of response tactics. Proc. Natl. Acad. Sci. USA 109, 4633–4638.
McClure, S.M., Laibson, D.I., Loewenstein, G., and Cohen, J.D. (2004). Separate neural systems value immediate and delayed monetary rewards. Science 306, 503–507.
McClure, S.M., Botvinick, M.M., Yeung, N., Greene, J.D., and Cohen, J.D. (2006). Conﬂict monitoring in cognition-emotion competition. In Handbook of Emotion Regulation, J.J. Gross, ed. (New York: Guilford), pp. 1–45.
McClure, S.M., Ericson, K.M., Laibson, D.I., Loewenstein, G., and Cohen, J.D. (2007). Time discounting for primary rewards. J. Neurosci. 27, 5796–5804.
McGuire, J.T., and Botvinick, M.M. (2010). Prefrontal cortex, cognitive control, and the registration of decision costs. Proc. Natl. Acad. Sci. USA 107, 7922– 7926.
Medford, N., and Critchley, H.D. (2010). Conjoint activity of anterior insular and anterior cingulate cortex: awareness and response. Brain Struct. Funct. 214, 535–549.
Metzler-Baddeley, C., Jones, D.K., Steventon, J., Westacott, L., Aggleton, J.P., and O’Sullivan, M.J. (2012). Cingulum microstructure predicts cognitive control in older age and mild cognitive impairment. J. Neurosci. 32, 17612– 17619.
Miller, E.K., and Cohen, J.D. (2001). An integrative theory of prefrontal cortex function. Annu. Rev. Neurosci. 24, 167–202.
Miltner, W.H.R., Braun, C.H., and Coles, M.G.H. (1997). Event-related brain potentials following incorrect feedback in a time-estimation task: evidence for a ‘‘generic’’ neural system for error detection. J. Cogn. Neurosci. 9, 788–798.
Mobbs, D., Yu, R., Rowe, J.B., Eich, H., FeldmanHall, O., and Dalgleish, T. (2010). Neural activity associated with monitoring the oscillating threat value of a tarantula. Proc. Natl. Acad. Sci. USA 107, 20582–20586.
Morecraft, R.J., and Tanji, J. (2009). Cingulofrontal interactions and the cingulate motor areas. In Cingulate Neurobiology and Disease, B.A. Vogt, ed. (Oxford: Oxford University Press), pp. 113–144.
Morecraft, R.J., Stilwell-Morecraft, K.S., Cipolloni, P.B., Ge, J., McNeal, D.W., and Pandya, D.N. (2012). Cytoarchitecture and cortical connections of the anterior cingulate and adjacent somatomotor ﬁelds in the rhesus monkey. Brain Res. Bull. 87, 457–497.
Mulder, M.J., Wagenmakers, E.-J., Ratcliff, R., Boekel, W., and Forstmann, B.U. (2012). Bias in the brain: a diffusion model analysis of prior probability and potential payoff. J. Neurosci. 32, 2335–2343.
Murphy, P.R., Robertson, I.H., Balsters, J.H., and O’connell, R.G. (2011). Pupillometry and P3 index the locus coeruleus-noradrenergic arousal function in humans. Psychophysiology 48, 1532–1543.
Nachev, P. (2011). The blind executive. Neuroimage 57, 312–313.
Nachev, P., Wydell, H., O’neill, K., Husain, M., and Kennard, C. (2007). The role of the pre-supplementary motor area in the control of action. Neuroimage 36(Suppl 2 ), T155–T163.
Nachev, P., Kennard, C., and Husain, M. (2008). Functional role of the supplementary and pre-supplementary motor areas. Nat. Rev. Neurosci. 9, 856–869.
Nakamura, K., Roesch, M.R., and Olson, C.R. (2005). Neuronal activity in macaque SEF and ACC during performance of tasks involving conﬂict. J. Neurophysiol. 93, 884–908.

Narayanan, N.S., and Laubach, M. (2008). Neuronal correlates of post-error slowing in the rat dorsomedial prefrontal cortex. J. Neurophysiol. 100, 520–525.
Nee, D.E., Wager, T.D., and Jonides, J. (2007). Interference resolution: insights from a meta-analysis of neuroimaging tasks. Cogn. Affect. Behav. Neurosci. 7, 1–17.
Nee, D.E., Kastner, S., and Brown, J.W. (2011). Functional heterogeneity of conﬂict, error, task-switching, and unexpectedness effects within medial prefrontal cortex. Neuroimage 54, 528–540.
Niendam, T.A., Laird, A.R., Ray, K.L., Dean, Y.M., Glahn, D.C., and Carter, C.S. (2012). Meta-analytic evidence for a superordinate cognitive control network subserving diverse executive functions. Cogn. Affect. Behav. Neurosci. 12, 241–268.
Nieuwenhuis, S., Gilzenrat, M.S., Holmes, B.D., and Cohen, J.D. (2005a). The role of the locus coeruleus in mediating the attentional blink: a neurocomputational theory. J. Exp. Psychol. Gen. 134, 291–307.
Nieuwenhuis, S., Heslenfeld, D.J., von Geusau, N.J., Mars, R.B., Holroyd, C.B., and Yeung, N. (2005b). Activity in human reward-sensitive brain areas is strongly context dependent. Neuroimage 25, 1302–1309.
Niki, H., and Watanabe, M. (1979). Prefrontal and cingulate unit activity during timing behavior in the monkey. Brain Res. 171, 213–224.
Niv, Y. (2007). Cost, beneﬁt, tonic, phasic: what do response rates tell us about dopamine and motivation? Ann. N Y Acad. Sci. 1104, 357–376.
Niv, Y., Daw, N.D., and Dayan, P. (2006). How fast to work: Response vigor, motivation and tonic dopamine. Adv. Neural Inf. Process. Syst. 18, 1019.
Norman, D.A., and Shallice, T. (1986). Attention to action: willed and automatic control of behavior. In Consciousness and Self-Segulation: Vol. 4. Advances in Research and Theory, R.J. Davidson, G.E. Schwartz, and D. Shapiro, eds. (New York: Plennum Press), pp. 1–18.
O’Reilly, R.C. (2010). The what and how of prefrontal cortical organization. Trends Neurosci. 33, 355–361.
O’Reilly, R.C., and Frank, M.J. (2006). Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia. Neural Comput. 18, 283–328.
O’Reilly, R.C., Noelle, D.C., Braver, T.S., and Cohen, J.D. (2002). Prefrontal cortex and dynamic categorization tasks: representational organization and neuromodulatory control. Cereb. Cortex 12, 246–257.
Olivers, C.N., Peters, J., Houtkamp, R., and Roelfsema, P.R. (2011). Different states in visual working memory: when it guides attention and when it does not. Trends Cogn. Sci. 15, 327–334.
Orr, J.M., and Weissman, D.H. (2009). Anterior cingulate cortex makes 2 contributions to minimizing distraction. Cereb. Cortex 19, 703–711.
Padoa-Schioppa, C. (2011). Neurobiology of economic choice: a good-based model. Annu. Rev. Neurosci. 34, 333–359.
Palomero-Gallagher, N., Vogt, B.A., Schleicher, A., Mayberg, H.S., and Zilles, K. (2009). Receptor architecture of human cingulate cortex: evaluation of the four-region neurobiological model. Hum. Brain Mapp. 30, 2336–2355.
Pardo, J.V., Pardo, P.J., Janer, K.W., and Raichle, M.E. (1990). The anterior cingulate cortex mediates processing selection in the Stroop attentional conﬂict paradigm. Proc. Natl. Acad. Sci. USA 87, 256–259.
Paus, T., Petrides, M., Evans, A.C., and Meyer, E. (1993). Role of the human anterior cingulate cortex in the control of oculomotor, manual, and speech responses: a positron emission tomography study. J. Neurophysiol. 70, 453–469.
Paus, T., Koski, L., Caramanos, Z., and Westbury, C. (1998). Regional differences in the effects of task difﬁculty and motor output on blood ﬂow response in the human anterior cingulate cortex: a review of 107 PET activation studies. Neuroreport 9, R37–R47.
Phillips, J.M., Johnston, K., and Everling, S. (2011). Effects of anterior cingulate microstimulation on pro- and antisaccades in nonhuman primates. J. Cogn. Neurosci. 23, 481–490.

238 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

Neuron
Review

Picard, N., and Strick, P.L. (1996). Motor areas of the medial wall: a review of their location and functional activation. Cereb. Cortex 6, 342–353.
Plassmann, H., O’Doherty, J.P., and Rangel, A. (2007). Orbitofrontal cortex encodes willingness to pay in everyday economic transactions. J. Neurosci. 27, 9984–9988.
Pochon, J.-B., Riis, J., Sanfey, A.G., Nystrom, L.E., and Cohen, J.D. (2008). Functional imaging of decision conﬂict. J. Neurosci. 28, 3468–3473.
Polyn, S.M., Norman, K.A., and Kahana, M.J. (2009). A context maintenance and retrieval model of organizational processes in free recall. Psychol. Rev. 116, 129–156.
Posner, M.I., and Snyder, C.R.R. (1975). Attention and cognitive control. In Information Processing and Cognition: The Loyola Symposium, R.L. Solso, ed. (Hillsdale, NJ: Erlbaum Associates).
Posner, M.I., Petersen, S.E., Fox, P.T., and Raichle, M.E. (1988). Localization of cognitive operations in the human brain. Science 240, 1627–1631.
Power, J.D., and Petersen, S.E. (2013). Control-related systems in the human brain. Curr. Opin. Neurobiol. 23, 223–228.
Pre´ vost, C., Pessiglione, M., Me´ te´ reau, E., Cle´ ry-Melin, M.L., and Dreher, J.C. (2010). Separate valuation subsystems for delay and effort decision costs. J. Neurosci. 30, 14080–14090.
Procyk, E., Tanaka, Y.L., and Joseph, J.P. (2000). Anterior cingulate activity during routine and non-routine sequential behaviors in macaques. Nat. Neurosci. 3, 502–508.
Quilodran, R., Rothe´ , M., and Procyk, E. (2008). Behavioral shifts and action valuation in the anterior cingulate cortex. Neuron 57, 314–325.
Rangel, A., and Hare, T.A. (2010). Neural computations associated with goaldirected choice. Curr. Opin. Neurobiol. 20, 262–270.
Reynolds, J.R., and O’Reilly, R.C. (2009). Developing PFC representations using reinforcement learning. Cognition 113, 281–292.
Reynolds, J.R., O’Reilly, R.C., Cohen, J.D., and Braver, T.S. (2012). The function and organization of lateral prefrontal cortex: a test of competing hypotheses. PLoS ONE 7, e30284.
Ribas-Fernandes, J.J., Solway, A., Diuk, C., McGuire, J.T., Barto, A.G., Niv, Y., and Botvinick, M.M. (2011). A neural signature of hierarchical reinforcement learning. Neuron 71, 370–379.
Ridderinkhof, K.R., Ullsperger, M., Crone, E.A., and Nieuwenhuis, S. (2004). The role of the medial frontal cortex in cognitive control. Science 306, 443–447.
Ridderinkhof, K.R., Nieuwenhuis, S., and Braver, T.S. (2007). Medial frontal cortex function: an introduction and overview. Cogn. Affect. Behav. Neurosci. 7, 261–265.
Rothe´ , M., Quilodran, R., Sallet, J., and Procyk, E. (2011). Coordination of high gamma activity in anterior cingulate and lateral prefrontal cortical areas during adaptation. J. Neurosci. 31, 11110–11117.
Rougier, N.P., Noelle, D.C., Braver, T.S., Cohen, J.D., and O’Reilly, R.C. (2005). Prefrontal cortex and ﬂexible cognitive control: rules without symbols. Proc. Natl. Acad. Sci. USA 102, 7338–7343.
Rushworth, M.F.S., Walton, M.E., Kennerley, S.W., and Bannerman, D.M. (2004). Action sets and decisions in the medial frontal cortex. Trends Cogn. Sci. 8, 410–417.
Rushworth, M.F.S., Behrens, T.E.J., Rudebeck, P.H., and Walton, M.E. (2007). Contrasting roles for cingulate and orbitofrontal cortex in decisions and social behaviour. Trends Cogn. Sci. 11, 168–176.
Rushworth, M.F.S., Noonan, M.P., Boorman, E.D., Walton, M.E., and Behrens, T.E. (2011). Frontal cortex and reward-guided learning and decision-making. Neuron 70, 1054–1069.
Rushworth, M.F.S., Kolling, N., Sallet, J., and Mars, R.B. (2012). Valuation and decision-making in frontal cortex: one or many serial or parallel systems? Curr. Opin. Neurobiol. 22, 946–955.
Sakai, K. (2008). Task set and prefrontal cortex. Annu. Rev. Neurosci. 31, 219–245.

Scimeca, J.M., and Badre, D. (2012). Striatal contributions to declarative memory retrieval. Neuron 75, 380–392.
Seeley, W.W., Menon, V., Schatzberg, A.F., Keller, J., Glover, G.H., Kenna, H., Reiss, A.L., and Greicius, M.D. (2007). Dissociable intrinsic connectivity networks for salience processing and executive control. J. Neurosci. 27, 2349–2356.
Shackman, A.J., Salomons, T.V., Slagter, H.A., Fox, A.S., Winter, J.J., and Davidson, R.J. (2011). The integration of negative affect, pain and cognitive control in the cingulate cortex. Nat. Rev. Neurosci. 12, 154–167.
Shah, A.K., and Oppenheimer, D.M. (2008). Heuristics made easy: an effortreduction framework. Psychol. Bull. 134, 207–222.
Shenhav, A., and Greene, J.D. (2010). Moral judgments recruit domain-general valuation mechanisms to integrate representations of probability and magnitude. Neuron 67, 667–677.
Sheth, S.A., Mian, M.K., Patel, S.R., Asaad, W.F., Williams, Z.M., Dougherty, D.D., Bush, G., and Eskandar, E.N. (2012). Human dorsal anterior cingulate cortex neurons mediate ongoing behavioural adaptation. Nature 488, 218–221.
Shiffrin, R.M., and Schneider, W. (1977). Controlled and automatic information processing: II. Perceptual learning, automatic attending, and a general theory. Psychol. Rev. 84, 127–190.
Shima, K., and Tanji, J. (1998). Both supplementary and presupplementary motor areas are crucial for the temporal organization of multiple movements. J. Neurophysiol. 80, 3247–3260.
Singer, T., Critchley, H.D., and Preuschoff, K. (2009). A common role of insula in feelings, empathy and uncertainty. Trends Cogn. Sci. 13, 334–340.
Snyder, H.R., Banich, M.T., and Munakata, Y. (2011). Choosing our words: retrieval and selection processes recruit shared neural substrates in left ventrolateral prefrontal cortex. J. Cogn. Neurosci. 23, 3470–3482.
Sohn, M.-H., Albert, M.V., Jung, K., Carter, C.S., and Anderson, J.R. (2007). Anticipation of conﬂict monitoring in the anterior cingulate cortex and the prefrontal cortex. Proc. Natl. Acad. Sci. USA 104, 10330–10334.
Sridharan, D., Levitin, D.J., and Menon, V. (2008). A critical role for the right fronto-insular cortex in switching between central-executive and defaultmode networks. Proc. Natl. Acad. Sci. USA 105, 12569–12574.
Stuss, D.T. (2011). Functions of the frontal lobes: relation to executive functions. J. Int. Neuropsychol. Soc. 17, 759–765.
Stuss, D.T., and Alexander, M.P. (2007). Is there a dysexecutive syndrome? Philos. Trans. R. Soc. Lond. B Biol. Sci. 362, 901–915.
Sutton, R.S., and Barto, A.G. (1998). Reinforcement Learning: An Introduction (Cambridge, MA: MIT Press).
Taren, A.A., Venkatraman, V., and Huettel, S.A. (2011). A parallel functional topography between medial and lateral prefrontal cortex: evidence and implications for cognitive control. J. Neurosci. 31, 5026–5031.
Todd, M.T., Niv, Y., and Cohen, J.D. (2008). Learning to use working memory in partially observable environments through dopaminergic reinforcement. In Advances in Neural Information Processing Systems, Volume 20 (Cambridge: MIT Press), pp. 1700–1707.
Tomlin, D., Nedic, A., Prentice, D.A., Holmes, P., and Cohen, J.D. (2013). The neural substrates of social inﬂuence on decision making. PLoS ONE 8, e52630.
Totah, N.K.B., Kim, Y.B., Homayoun, H., and Moghaddam, B. (2009). Anterior cingulate neurons represent errors and preparatory attention within the same behavioral sequence. J. Neurosci. 29, 6418–6426.
Touroutoglou, A., Hollenbeck, M., Dickerson, B.C., and Feldman Barrett, L. (2012). Dissociable large-scale networks anchored in the right anterior insula subserve affective experience and attention. Neuroimage 60, 1947–1958.
Tsuchida, A., and Fellows, L.K. (2009). Lesion evidence that two distinct regions within prefrontal cortex are critical for n-back performance in humans. J. Cogn. Neurosci. 21, 2263–2275.

Neuron 79, July 24, 2013 ª2013 Elsevier Inc. 239

Neuron
Review

Ullsperger, M., Harsay, H.A., Wessel, J.R., and Ridderinkhof, K.R. (2010). Conscious perception of errors and its relation to the anterior insula. Brain Struct. Funct. 214, 629–643.
van Maanen, L., Brown, S.D., Eichele, T., Wagenmakers, E.-J., Ho, T., Serences, J., and Forstmann, B.U. (2011). Neural correlates of trial-to-trial ﬂuctuations in response caution. J. Neurosci. 31, 17488–17495.
Venkatraman, V., and Huettel, S.A. (2012). Strategic control in decision-making under uncertainty. Eur. J. Neurosci. 35, 1075–1082.
Venkatraman, V., Rosati, A.G., Taren, A.A., and Huettel, S.A. (2009). Resolving response, decision, and strategic control: evidence for a functional topography in dorsomedial prefrontal cortex. J. Neurosci. 29, 13158–13164.
Vincent, J.L., Kahn, I., Snyder, A.Z., Raichle, M.E., and Buckner, R.L. (2008). Evidence for a frontoparietal control system revealed by intrinsic functional connectivity. J. Neurophysiol. 100, 3328–3342.
Vogt, B.A., Berger, G.R., and Derbyshire, S.W.G. (2003). Structural and functional dichotomy of human midcingulate cortex. Eur. J. Neurosci. 18, 3134–3144.
Vogt, B.A., Hof, P.R., and Vogt, L.J. (2004). Cingulate gyrus. In The Human Nervous System, G. Paxinos and J. Mai, eds. (Amsterdam: Elsevier), pp. 915–949.
Wallis, J.D., and Kennerley, S.W. (2011). Contrasting reward signals in the orbitofrontal cortex and anterior cingulate cortex. Ann. N Y Acad. Sci. 1239, 33–42.
Walton, M.E., Devlin, J.T., and Rushworth, M.F.S. (2004). Interactions between decision making and performance monitoring within prefrontal cortex. Nat. Neurosci. 7, 1259–1265.
Walton, M.E., Rudebeck, P.H., Bannerman, D.M., and Rushworth, M.F.S. (2007). Calculating the cost of acting in frontal cortex. Ann. N Y Acad. Sci. 1104, 340–356.
Wang, C., Ulbert, I., Schomer, D.L., Marinkovic, K., and Halgren, E. (2005). Responses of human anterior cingulate cortex microdomains to error detection, conﬂict monitoring, stimulus-response mapping, familiarity, and orienting. J. Neurosci. 25, 604–613.

Weissman, D.H., Gopalakrishnan, A., Hazlett, C.J., and Woldorff, M.G. (2005). Dorsal anterior cingulate cortex resolves conﬂict from distracting stimuli by boosting attention toward relevant events. Cereb. Cortex 15, 229–237.
Wessel, J.R., Danielmeier, C., Morton, J.B., and Ullsperger, M. (2012). Surprise and error: common neuronal architecture for the processing of errors and novelty. J. Neurosci. 32, 7528–7537.
Westbrook, A., Kester, D., and Braver, T.S. (2013). What is the subjective cost of cognitive effort? Load, trait, and aging effects revealed by economic preference. PLoS ONE.. http://dx.doi.org/10.1371/journal.pone.0068210.
Weston, C.S.E. (2012). Another major function of the anterior cingulate cortex: the representation of requirements. Neurosci. Biobehav. Rev. 36, 90–110.
Wiecki, T.V., and Frank, M.J. (2013). A computational model of inhibitory control in frontal cortex and basal ganglia. Psychol. Rev. 120, 329–355.
Womelsdorf, T., Johnston, K., Vinck, M., and Everling, S. (2010). Theta-activity in anterior cingulate cortex predicts task rules and their adjustments following errors. Proc. Natl. Acad. Sci. USA 107, 5248–5253.
Woolgar, A., Hampshire, A., Thompson, R., and Duncan, J. (2011). Adaptive coding of task-relevant information in human frontoparietal cortex. J. Neurosci. 31, 14592–14599.
Wunderlich, K., Rangel, A., and O’Doherty, J.P. (2009). Neural computations underlying action-based decision making in the human brain. Proc. Natl. Acad. Sci. USA 106, 17199–17204.
Yeo, B.T., Krienen, F.M., Sepulcre, J., Sabuncu, M.R., Lashkari, D., Hollinshead, M., Roffman, J.L., Smoller, J.W., Zo¨ llei, L., Polimeni, J.R., et al. (2011). The organization of the human cerebral cortex estimated by intrinsic functional connectivity. J. Neurophysiol. 106, 1125–1165.
Yeung, N., Botvinick, M.M., and Cohen, J.D. (2004). The neural basis of error detection: conﬂict monitoring and the error-related negativity. Psychol. Rev. 111, 931–959.
Yeung, N., Cohen, J.D., and Botvinick, M.M. (2011). Errors of interpretation and modeling: a reply to Grinband et al. Neuroimage 57, 316–319.
Yu, A.J., Dayan, P., and Cohen, J.D. (2009). Dynamics of attentional selection under conﬂict: toward a rational Bayesian account. J. Exp. Psychol. Hum. Percept. Perform. 35, 700–717.

240 Neuron 79, July 24, 2013 ª2013 Elsevier Inc.

