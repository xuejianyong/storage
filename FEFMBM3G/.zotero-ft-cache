硕士学位论文

基于神经网络的自主情境特征提取研究

作者姓名： 指导教师：

秦赛男 余山 研究员 中国科学院自动化研究所

学位类别： 学科专业： 培养单位：

工程硕士 计算机技术 中国科学院自动化研究所

2021 年 6 月

Autonomous Contextual Feature Extraction with Neural Networks
A thesis submitted to the University of Chinese Academy of Sciences
in partial fulﬁllment of the requirement for the degree of
Master of Engineering in Computer Technology
By Sainan Qin Supervisor: Professor Shan Yu
Institute of Automation, Chinese Academy of Sciences
June, 2021

中国科学院大学 学位论文原创性声明
本人郑重声明：所呈交的学位论文是本人在导师的指导下独立进行研究工 作所取得的成果。尽我所知，除文中已经注明引用的内容外，本论文不包含任 何其他个人或集体已经发表或撰写过的研究成果。对论文所涉及的研究工作做 出贡献的其他个人和集体，均已在文中以明确方式标明或致谢。本人完全意识 到本声明的法律结果由本人承担。
作者签名： 日 期：

中国科学院大学 学位论文授权使用声明
本人完全了解并同意遵守中国科学院大学有关保存和使用学位论文的规定， 即中国科学院大学有权保留送交学位论文的副本，允许该论文被查阅，可以按 照学术研究公开原则和保护知识产权的原则公布该论文的全部或部分内容，可 以采用影印、缩印或其他复制手段保存、汇编本学位论文。
涉密及延迟公开的学位论文在解密或延迟期后适用本声明。

作者签名： 日 期：

导师签名： 日 期：

摘要
摘要
生物体能够根据变化的目标、 环境及内部状态等组合成的不同情境对同 一 刺 激 做 出 不 同 的 反 应， 这 种 动 态 响 应 环 境 的 能 力 即 为 情 境 学 习 （Contextual Learning，CL）。在人工智能（Artiﬁcial Intelligence，AI）领域，情境学习并未引 起广泛的关注，但其实这种能力是通用人工智能的必备能力之一。目前的人工 神经网络（Artiﬁcial Neural Network，ANN）的函数映射较为刻板，缺乏在动态 变化环境中灵活修改规则的能力，面临无法连续学习和灾难性遗忘等问题。其 实，诸多任务中包含许多关键的情境信息，这些信息对于决策和判断有着直接 或间接的影响，神经网络往往隐式地学习该类知识，使得网络的学习能力和容 量受到限制。如果网络能自主显式地提取情境信息实现根据情境转换映射规则， 则会大大提升其灵活性。灵长类生物的前额叶皮层（Prefrontal Cortex，PFC）和 海 马 体 （Hippocampus， HPC） 负 责 情 境 信 号 的 提 取 和 转 化， 可 以 根 据 情 境 信 息调控信息处理的流程，灵活处理不同的任务。本文受 PFC、HPC 和互补学 习系统（Complementary Learning System，CLS）原理的启发，结合实际应用场 景，提出了一种新的通用计算架构，设计了包含三个子模块的复合情境处理模 块（Context Processing Module，CPM）。该模块能自主地通过端到端学习，有效 提取关键情境信息，并将这一信息融入基准网络中从而实现高效的情境化信息 处理。
本文首先通过强化学习的实验证实，CPM 能够有效提升基准网络的性能并 加速训练，子模块间相互配合，协同合作，分别承担着不同的功能。实验证明， 在包含复杂情境信息的 Pacman 游戏中，CPM 能显式学习提取判别与任务相关 的重要情境信号，增大了游戏中情境元素表征之间的类间距离，并通过与基准 网络所学习到的规则信息的有效融合，达到了缩短训练时长、节省计算资源的 目的，改变了之前算法中智能体必须隐式学习情境信息的现状。通过对不同特 征表征分布的研究，证实了 CPM 各子模块对于整体情境化信息处理的作用，并 初步验证了其中一些子模块的功能机理，表明了本文所提出的类脑模块的有效 性。为了深入研究 CPM 的作用原理与机制，本文设计了新颖的情境图像分类 任务，使得输入图像中的情境信息和其他信息具有明确的定义。实验结果表明，
I

基于神经网络的自主情境特征提取研究
我们提出的网络架构实现了对于这两种重要特征信息的解耦，降低了任务复杂 度，并最终提升了分类的效果。进一步的分析表明，网络能够跟据各种类别信 息的相对复杂程度，自主优化资源配置，实现情境信息的有效处理。
本研究结合神经科学的重要启发与机器学习的网络设计，提出并验证了能 够通过端到端学习，自主地提取环境中的重要情境信息，并使之与其他信息的 处理有效整合，从而提高系统性能的网络结构，并初步阐明了其作用机制。利 用脑启发的网络结构，实现情境化信息处理与现有深度网络的有效结合，是面 向通用人工智能的积极探索，也为研究人脑处理复杂信息的机制提供了新的思 路，具有重要的理论和实际意义。 关键词： 前额叶皮层，海马体，互补学习系统，情境处理模块
II

Abstract
Abstract
Organisms can make diﬀerent responses to the same stimulus according to diﬀerent contexts combined with changing goals, environments and internal states. Such ability of dynamic response to the environment is contextual learning (CL). In the ﬁeld of artiﬁcial intelligence (AI), contextual learning has not attracted much attention, but in fact, this kind of ability is one of the essential abilities for general artiﬁcial intelligence. The function mapping of artiﬁcial neural network (ANN) is rigid and ANNs lack the ability to modify the rule ﬂexibly in the dynamic changing environment, resulting in facing the problems such as failure to learn continuously, catastrophic forgetting and so on. In fact, many tasks include critical contextual information, which often has a direct or indirect inﬂuence on the decision making and judgment. ANNs often implicitly learn such knowledge, which limits the learning ability and capacity of the network. If the network can autonomously and explicitly extract context information to realize conversion of the mapping rules according to the contexts, it will greatly enhance ﬂexibility of the network. The prefrontal cortex (PFC) and hippocampus (HPC) of the primates, are responsible for the context signals extraction and conversion and can regulate and control the process of information processing according to the contextual information so that ﬂexibly handle diﬀerent tasks. Inspired by the principles of PFC, HPC and the complementary learning system (CLS), and combined with practical application scenarios, this paper proposed a new computing architecture, and designed the composite context processing module (CPM) with three sub-modules. Through autonomously end-to-end learning, this module can eﬀectively extract key contextual information, and integrate this information into the backbone network to achieve eﬃcient contextual information processing.
Firstly, through reinforcement learning experiments, this paper conﬁrms that the CPM can eﬀectively improve the performance of the backbone network and accelerate training, and the three sub-modules cooperate with each other and play diﬀerent roles. Experimental results show that in the game of Pacman with complex contextual infor-
III

基于神经网络的自主情境特征提取研究
mation, CPM can explicitly learn to extract and discriminate the important task-related contexts, increase the distance between classes of important contextual elements representation in the game. And through the eﬀective integration of the rule information learned from the backbone network, the training time is shortened and computing resources are saved, which changes the situation that the agent must learn the contextual information implicitly in the previous algorithms. Through the research on the characterization distribution of diﬀerent features, the eﬀect of each sub-module of CPM on the overall contextual information processing is conﬁrmed, and the functional mechanism of some of the sub-modules is preliminarily veriﬁed, which demonstrates the eﬀectiveness of the brain-inspired module proposed in this paper. In order to further study the function principle and mechanism of CPM, a novel contextual image classiﬁcation task is designed in this paper so that the contextual information and other information in the input images can be clearly deﬁned. The experimental results show that the proposed network architecture achieves decoupling of the two important categories of information, reduces the task complexity and ﬁnally improves the eﬀectiveness of classiﬁcation. Further analysis shows that the network can automatically optimize the allocation of resources according to the relative complexity of various types of information and realize the eﬀective processing of contextual information.
This study combines the important inspiration of neuroscience with the network design of machine learning, proposes and veriﬁes the network structure that can autonomously extract important contextual information in the environment through endto-end learning, and eﬀectively integrate it with other information processing to improve the system performance. Using brain-inspired network structure to realize the eﬀective combination of contextual information processing and existing deep neural network is an promising attempt for general artiﬁcial intelligence, and also provides a new idea for studying the mechanism of complex information processing in human brain, which has important theoretical and practical signiﬁcance.
Keywords: Prefrontal Cortex, Hippocampus, Complementary Learning System, Context Processing Module
IV

目录
目录
第1章 绪论 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 1
1.1 研究背景 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 1 1.2 本文研究的主要内容 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 2 1.3 本文的组织结构 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 3
第2章 相关研究综述 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 5
2.1 情境学习 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 5 2.1.1 计算神经科学研究现状 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 5 2.1.2 机器学习研究现状 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 10
2.2 深度强化学习 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 11 2.2.1 基于值函数的深度强化学习 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 12 2.2.2 基于策略梯度的深度强化学习 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 13 2.2.3 基于搜索与监督的深度强化学习 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 14
2.3 本章小结 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 15
第3章 情境处理模块（CPM） · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 17
3.1 模式分离模块 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 17 3.2 模式补全模块 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 20 3.3 模式整合模块 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 21 3.4 情境信息与感观数据结合 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 22 3.5 本章小结 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 24
第4章 CPM 在强化学习中的自主情境信息提取· · · · · · · · · · · · · · · · 25
4.1 网络设计 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 25 4.2 性能测试 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 27
4.2.1 多层感知机 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 27 4.2.2 模式分离模块 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 28 4.2.3 模式补全模块 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 30 4.2.4 模式整合模块 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 32 4.3 CPM 情境特征提取分析 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 35 4.4 网络参数 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 40 4.5 本章小结 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 41
V

基于神经网络的自主情境特征提取研究
第5章 CPM 在情境图像分类中的自主情境信息提取 · · · · · · · · · · · 43
5.1 Contextual MNIST· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 43 5.1.1 性能比较 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 44 5.1.2 CPM 作用分析 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 46
5.2 Contextual CIFAR10 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 52 5.2.1 性能比较 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 52 5.2.2 CPM 作用分析 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 53
5.3 细粒度图像分类 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 58 5.4 数据集和网络参数 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 59
5.4.1 数据集 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 59 5.4.2 网络参数 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 59 5.5 本章小结 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 60
第6章 总结与展望 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 63
6.1 研究内容总结 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 63 6.2 展望 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 65
参考文献 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 67 作者简历及攻读学位期间发表的学术论文与研究成果 · · · · · · · · · · 73 致谢 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 75
VI

图形列表
图形列表
1.1 本文的组织结构 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 3
2.1 情境实例 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 6 2.2 情境网络模型[1] · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 7 2.3 啮齿类前额叶皮层与海马体之间直接和间接的通路[2] · · · · · · · · · · · · · · · · 8 2.4 CLS 示意图[3] · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 9 2.5 基于情境信号的机器学习网络结构示意图[4] · · · · · · · · · · · · · · · · · · · · · · · · · 10 2.6 情境依赖处理模块示意图[5] · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 11 2.7 强化学习示意图 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 12 2.8 DQN 算法示意图 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 13 2.9 AlphaGo 蒙特卡洛树搜索计算过程[6] · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 14
3.1 扩展稀疏联合编码原理示意图。（A）相似度变化比较，（B）REMERGE模 型，（C）模式输入输出重叠度变化曲线，（D）升维效果。 · · · · · · · · · · · 18
3.2 PS 模块设计架构 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 19 3.3 PC 模块原理与结构示意图。（A）DG 模式分离效果，（B）CA3 模式
补全效果，（C）PC 模块网络架构，（D）补全效果图 · · · · · · · · · · · · · · · · 21 3.4 PI 模块结构图 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 22 3.5 感官特征与情境信号结合示意图 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 23
4.1 Pacman 地图与基准网络加入 CPM 结构示意图 · · · · · · · · · · · · · · · · · · · · · · 26 4.2 简单 MLP 作为 CPM 的网络示意图（A）及在 Pacman 游戏性能上的
表现。（B）平均最大 Q 值，（C）平均得分，（D）平均胜率，其中淡 蓝色和淡红色颜色区域表示 95% 的置信区间。 · · · · · · · · · · · · · · · · · · · · · · 26 4.3 加入 PS 模块的 CPM 示意图（A）及在 Pacman 游戏性能上的表现。（B） 平均最大 Q 值，（C）平均得分，（D）平均胜率。 · · · · · · · · · · · · · · · · · · · 29 4.4 PC 模块示意图（A）及在 Pacman 游戏性能上的表现。（B）平均最大 Q 值，（C）平均得分，（D）平均胜率，其中淡蓝色、淡红色和淡绿色 颜色区域表示 95% 的置信区间。 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 31 4.5 PI 模块示意图（A）及在 Pacman 游戏性能上的表现。（B）平均最大 Q 值，（C）平均得分，（D）平均胜率，其中淡蓝色、淡红色和淡绿色 颜色区域表示 95% 的置信区间。 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 32 4.6 PC 和 PI 模块有效性对比实验。（A）平均得分，（B）平均胜率。 · · · · 33 4.7 融合位置变动对性能的影响。（A）变动融合位置后的网络结构，（B） 平均最大 Q 值，（C）平均得分，（D）平均胜率，其中淡蓝色和淡红 色颜色区域表示 95% 的置信区间。 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 34
VII

基于神经网络的自主情境特征提取研究
4.8 关于豆子数量的特征空间分布研究及类间散度分析 · · · · · · · · · · · · · · · · · · 36 4.9 关于胶囊、恐惧鬼数量的特征空间分布研究及最大类间散度统计 · · · · 37 4.10 PS（A）、PC（B）、PS+PC（C）和 PS+PC+PI（D）模块提取的情境
特征关于豆子数量的空间分布分析 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 38 4.11 PS 模块前后模式平均欧氏距离分析 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 38 4.12 FC（A）、PS（B）、PC（C）、PI（D）模块提取的情境特征关于豆子
数量的空间分布分析 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 39
5.1 Contextual MNSIT 任务示意图 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 43 5.2 Contextual MNIST 图像分类任务 CPM 结构图 · · · · · · · · · · · · · · · · · · · · · · · · · 44 5.3 CPM 在Contextual MNIST 任务上的表现。（A）20 分类损失函数值、训
练准确率和测试准确率，（B）20 分类至 90 分类任务最终损失函数 值、训练准确率和测试准确率，（C）NetC 网络架构，（D）CCNet 网 络架构，（E）4 种网络平均最终测试准确率。 · · · · · · · · · · · · · · · · · · · · · · · 45 5.4 Contextual MNIST 关于不同标签的特征空间分布分析。（A） 感知特 征，（B）情境特征，（C）旋转特征，其中每列标记点颜色依次代表 不同的标记位置、原始标签和真实标签。 · · · · · · · · · · · · · · · · · · · · · · · · · · · 47 5.5 Contextual MNIST中CNN线性层关于不同标签的特征空间分布分析。（A） 20 分类，（B）30 分类，（C）90分类，其中每列标记点颜色依次代表 不同的标记位置、原始标签和真实标签。 · · · · · · · · · · · · · · · · · · · · · · · · · · · 48 5.6 不同分类任务中感知特征关于标记位置和情境特征关于原始标签的 空间分布研究。（A）30分类，（B）40 分类，（C）70 分类，（D）80 分 类，（E）90 分类。 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 49 5.7 不同分类任务中情境特征关于标记位置和感知特征关于原始标签的 空间分布研究。（A）70 分类，（B）80 分类，（C）90 分类。 · · · · · · · · · 50 5.8 CIFAR10 数据集[7] · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 52 5.9 CPM 在 Contextual CIFAR10 任务上的表现。（A）20 分类损失函数值、 训练准确率和测试准确率，（B）20 分类至 90 分类任务最终损失函 数值、训练准确率和测试准确率，（C）4 种网络平均最终测试准确 率，（D）3 种网络平均最终测试准确率减去 CNN 平均最终测试准确 率的差值比较。 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 54 5.10 Contextual CIFAR10 关于不同标签的特征空间分布分析。（A）感知特 征，（B）情境特征，（C）旋转特征，其中每列标记点颜色依次代表 不同的标记位置、原始标签和真实标签。 · · · · · · · · · · · · · · · · · · · · · · · · · · · 56 5.11 Contextual CIFAR10 中 CNN 线性层关于不同标签的特征空间分布分 析。（A）20 分类，（B）30 分类，（C）90分类，其中每列标记点颜色 依次代表不同的标记位置、原始标签和真实标签。 · · · · · · · · · · · · · · · · · · 57 5.12 CUB_200_2011 数据集[8] · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 58
VIII

表格列表
表格列表
4.1 CPM 在 Pacman 中性能的量化统计 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 30 4.2 CPM 位置变化在 Pacman 中性能的量化统计 · · · · · · · · · · · · · · · · · · · · · · · · · 34 4.3 网络参数配置 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 40 4.4 Pacman 游戏得分规则 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 41 5.1 CNN 在 MNIST 10 分类和位置标签分类任务中的测试准确率 · · · · · · · · · 51 5.2 CPM 在 CUB_200_2011 上的性能 · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · 59
IX

基于神经网络的自主情境特征提取研究 X

符号列表

符号列表

字符

Symbol Description

Unit

Mselect

select matrix

1

算子

Symbol

Description element-wise product

缩写
CL AI ANN PFC HPC CLS CPM DL RL DNN PS PC PI DG vHPC Re

Contextual Learning Artiﬁcial Intelligence Artiﬁcial Neural Network Prefrontal Cortex Hippocampus Complementary Learning System Context Processing Module Deep Learning Reinforcement Learning Deep Neural Networks Pattern Separation Pattern Completion Pattern Integration Dentate Gyrus Ventral Hippocampus Reuniens

XI

mPFC ERC CDP OWM DRL MDP MCTS DQN DRQN RNN MLP ReLU

基于神经网络的自主情境特征提取研究
Medial Prefrontal Cortex Entorhinal Cortex Context-dependent Processing Orthogonal Weights Modiﬁcation Deep Reinforcement Learning Markov Decision Process Monte Carlo Tree Search Deep Q-Network Deep Recurrent Q-Network Recurrent Neural Network Multilayer perceptron Rectiﬁed Linear Units

XII

第1章 绪论
第1章 绪论
1.1 研究背景
情境学习（Contextual Learning，CL），作为高水平智能的标志之一，使得 生物体能够根据变化的目标、环境及内部状态等组合成的不同情境对同一刺激 输入做出不同的反应，实现对环境的动态响应[1, 9–13]。灵长类动物大脑中的前 额叶皮层（Prefrontal Cortex，PFC）[13–16]和海马体（Hippocampus，HPC）[17– 19]系统，是完成该项能力的重要生物基础。情境学习的能力也将是通用人工智 能必须具备的重要能力之一。虽然神经科学对情境学习的研究由来已久[20–22]， 但是在人工智能（Artiﬁcial Intelligence，AI）领域，情境学习能力的研究尚不够 充分。目前的深度神经网络（Deep Neural Networks，DNN）[23]十分擅长从原始 感知数据中提取高级特征并进行模式分类、检测、分割等任务，在复杂映射规 则学习方面十分优秀。但在大多数 DNN 中，输入-输出之间的映射相当刻板，输 出完全由输入决定，缺乏足够的灵活性来应对复杂的环境变化，无法根据情境 灵活修改映射规则。现阶段的深度学习（Deep Learning，DL）[23]大多通过样本 中隐含的先验知识来估计给定输入-输出的函数，从先验中概化看不见的样本。 而在先验中还包含了一些不能只考虑函数及其输入输出来表示的知识，但这些 知识又对任务的学习十分有用，这就是我们希望能提取的情境信息。利用这一 信息，可以形成与目标函数相关的先验。整合这些先验知识可以使学习规范化， 从而提高泛化能力。相反，缺乏相应的情境提取能力，实际上限制了网络的学 习能力，导致网络在诸多任务中面临训练依赖大量样本、灾难性遗忘[24, 25]等 困境，造成样本利用率低和训练耗时耗资源的情况。本文设计了一种新的受到 灵长类脑网络结构和功能启发的类脑智能网络架构，实现了自主端到端的学习 自主提取环境中与任务相关的重要情境信息。这些提取的情境信息与感知信息 融合之后再送入下游网络进行进一步训练。本文结合生物领域的知识体系和机 器学习领域的网络设计，为类脑算法设计提供了一定的借鉴思路，是对通用人 工智能的进一步探索，也为解释人脑机制提供了新的思路启示，具有重要的理 论价值和实际意义。
1

基于神经网络的自主情境特征提取研究
1.2 本文研究的主要内容
受前额叶皮层、海马体功能连接和互补学习系统（Complementary Learning System，CLS）原理[3, 21, 26]的启发，结合实际应用场景，本文融合认知科学 和计算神经科学中已有的体系结构，提出一种相对通用的计算架构，设计了相 应的复合情境处理模块（Context Processing Module，CPM），包含三大子模块： 模式分离（Pattern Separation， PS）模块、模式补全（Pattern Completion，PC） 模块和模式整合（Pattern Integration，PI）模块。该复合模块能有效判别和提取 重要的情境信息，将其加入基准网络中用于调制神经网络的信息处理过程，使 得人工神经网络（Artiﬁcial Neural Networks，ANN）能在复杂环境中有效识别 情境信号，并快速响应和修改原有的“刺激-响应”关联，以适应动态变化的环 境。通过该模块的学习，ANN 具备了强大的情境学习能力，其灵活性和适应性 得到了大幅度的提升。
本文以深度强化学习基础网络 DQN[27]为基准网络，具有复杂情境的 Atari 2600 游戏 Pacman 为测试任务进行实验。实验结果显示 CPM 能帮助智能体根据 环境信息有效选择、学习最优的输入刺激-动作响应组合，以适应变化的环境， 缩短训练时长并提升训练性能（如胜率，最终得分等）。然后，我们进行了消 融实验，依次验证了三个子模块的有效性，并通过对感知层输出的感知特征、 CPM 提取的情境特征和两者融合之后的旋转特征进行 PCA 降维，研究其表征的 具体情境信息并进行了类间散度的定量计算，探索每个子模块的功能意义和编 码变化。
为了进一步探索 CPM 的功能机制，本文设计了一个新的情境图像分类任 务，通过在常规数据集中增加区块标记的方式，显式化对真实类别起决定性作 用的两种重要元素，深入研究 CPM 在网络中扮演的角色及作用机理。实验表 明，CPM 能有效提升分类性能。通过对感知特征、情境特征和旋转特征降维后 的三维空间分布进行可视化，发现该网络架构能够实现两种信息编码任务的解 耦，并能根据信息的复杂度自动分配网络进行训练，降低了任务的复杂度，从 而网络性能有了明显的提升。该结果给我们提供了一种新的网络设计思路。
综上所述，本文设计了一种新的类脑智能网络架构，自主端到端提取重要 情境信息，将提取的情境信息与感知信息融合之后再送入下游网络进行训练。 本研究在深度强化学习游戏和图像分类任务上进行了实验，得到了良好的效果，
2

第1章 绪论
并通过 PCA 降维后的特征空间分布研究探索了 CPM 的作用机制。本文结合生 物领域的知识体系和机器学习领域的网络设计，为类脑算法设计提供了一定的 借鉴思路，是对通用人工智能的进一步探索，也为解释人脑机制提供了新的原 理启示，具有重要的理论和实际意义。
图 1.1 本文的组织结构 Figure 1.1 The Organization of this article
1.3 本文的组织结构 本文总共六个章节，图 1.1 为整体的组织结构，各个章节的内容具体如下： 第一章：绪论。主要介绍本文的研究背景和研究意义，简略介绍研究内容
及文章的总体架构。 第二章：相关研究综述。主要介绍情境学习在神经科学与机器学习领域的
国内外研究工作、互补学习系统原理以及深度强化学习的主流方法。重点介绍 了情境学习与互补学习系统的原理概念。
第三章：情境处理模块。详细阐述了三个子模块，包括模式分离模块、模 式补全模块和模式整合模块的设计来源、原理及网络设计，阐明了在神经网络 中如何将情境信号与感知特征融合并形成完整的网络架构体系。
3

基于神经网络的自主情境特征提取研究
第四章：CPM 在强化学习中的自主情境信息提取。选择 Pacman 作为基准 游戏任务，展示了依次加入各个功能子模块后与基线 DQN 算法的性能对比。通 过对感知层输出的感知特征、CPM 输出的情境特征和两者融合后的旋转特征进 行 PCA 降维后的空间分布可视化，并采用类间散度作为量化指标，探索 CPM 的作用机制。
第五章：CPM 在情境图像分类中的自主情境信息提取。新设计了情境图像 分类任务，在该任务中加入 CPM 的网络性能比基线网络有了明显的提升，证 明了 CPM 的有效性。通过另外设计的两种网络架构，比较分析其性能，排除网 络扩容因素影响。通过对感知特征、CPM 情境特征和旋转特征进行 PCA 降维 后在三维空间中的分布情况的分析，提出网络解耦合设计更有助于性能的提升。 另外，该章节进行了在细粒度分类数据集上的测试，验证其在常规任务上的性 能。
第六章：总结与展望。总结回顾全文内容，阐明了本文的研究意义，探讨情 境处理模块可能的应用场景，提出了未来的研究方向和可能的实际应用价值。
4

第2章 相关研究综述
第2章 相关研究综述
情境学习能力，是灵长类生物灵活应对复杂多变环境的必备能力之一。而 人工神经网络由于刻板的映射规则，缺乏这种根据环境中关键情境信息灵活修 改输入输出映射的能力。关键的情境信息对行为决策有着至关重要的影响，能 够辅助网络进行自适应学习，也是连续学习和多任务学习的突破口之一。这种 情境决定行为的现象存在于诸多深度学习任务中，尤其以强化学习任务为代表， 如游戏、博弈等任务中一个细微的差别往往导致完全不同的行为。作为机器学 习的重要分支之一的强化学习，是更符合灵长类实际学习的方式。借鉴行为主 义心理学，智能体通过与环境的交互学习解决问题的策略，根据滞后的奖励动 态自适应调整政策，达到学习根本模式或潜在规则的目的。大多数强化学习使 用的搜索算法需要大量的经验和试错，导致训练耗时耗资源。而在这个过程中， 环境中往往存在着复杂多变的情境，对决策起着至关重要的作用。网络拥有显 式的情境学习能力可以减少训练试错次数及降低实际学习的复杂度，提升训练 性能。接下来本章将从情境学习和深度强化学习两个方面，介绍与本研究相关 的国内外研究现状及发展趋势。
2.1 情境学习
高级智慧生命拥有动态响应环境的能力，即为情境学习能力，指智能体根 据自身的目标和当前环境，灵活选择正确的情境信号调制信息处理流程[1, 14– 16]，并触发正确的动作行为来实现目的的学习机制，而在神经认知科学中，根 据变化的情境对同种刺激呈现不同反应被定义为认知控制[16]。情境学习在计 算神经科学与机器学习中都有相关的探索，接下来我们将围绕这两方面展开综 述。 2.1.1 计算神经科学研究现状
人类和动物模型的研究表明，前额叶皮层和海马体在情境记忆的组织过程 中 起 着 关 键 作 用。 前 额 叶 通 过 抑 制 竞 争 性 的、 错 误 的 情 境 记 忆 与 海 马 体 互 动， 实现正确情境相关记忆的检索[2]。从 HPC 直接发送到 PFC 的信号与当前事件 的整体信息有关。PFC-HPC 相互的作用，实现了记忆检索和区分初始学习环境
5

基于神经网络的自主情境特征提取研究
的目的。HPC 和 PFC 相辅相成，在情境记忆中起到了至关重要的作用。 2.1.1.1 前额叶皮层与海马体
前额叶皮层可以根据环境的不同，快速调制输入到输出的映射规则，达到 灵活响应环境变化的目的[14, 16]，在情境依赖行为中起着重要作用，是情境学 习功能的关键生物基础。例如，屏幕上的蓝色汉字“红”，在颜色的条件下判为 “蓝”，而在汉字本身含义上判为“红”；又如一个孩子恰巧在母亲任教的班级 上课，则在教室的环境下，对于孩子而言女子的身份是“老师”，而其他场景中 则为“母亲”（图 2.1）。这种根据不同情境信号灵活决策选择以应对的能力，即 为情境学习。相关的人类认知实验表明，PFC 受损的受试者丧失了对任务高度 相关而强度较弱的刺激信号的反应能力，对刺激的响应主要取决于感觉输入的 强度[20]。另外，即使已学到的既定规则在某种情况下已不再适用，无法带来预 期效果，往往受试者还是顽固地遵循着这些规则。这也意味着他/她们失去了根 据情境动态调整输入和输出之间映射的能力[21, 22]。PFC 是情境学习的关键， 其神经元可以表征各种与情境相关的信息，该结论不仅可以在 PFC 受损的人类 患者的相关实验中得到证实，也可在非人类灵长类动物的许多电生理学研究进 行证实[21]。诸多研究表明，认知控制大大增强了灵长类动物灵活应对复杂、不 确定、不可穷举的环境变化的能力。
图 2.1 情境实例 Figure 2.1 Examples of contexts
2013 年斯坦福大学 Mante[1]分析了猕猴在根据情境信号选择任务中前额叶 皮层的脑电活动，认为选择和整合是在同一 PFC 回路中单个动态过程的两个方
6

第2章 相关研究综述
面的体现，将 PFC 类比蓄水池网络（Reservoir Network）[28]，内部是随机、非 线性的全连接神经元，据此提出了神经系统整合信息和选择决策的新机制及情 境处理的通用计算框架（图 2.2）。
图 2.2 情境网络模型[1] Figure 2.2 The network module of context[1]
此外，人类和动物模型的研究表明，海马体在情境记忆的组织过程中也起 着关键作用[17–19, 29, 30]。海马结构包括齿状回（Dentate Gyrus，DG）、CA1CA3 部位、以及脑下脚，是人类及脊椎动物脑中的最古老的部分之一，担当着 短期记忆、长期记忆，以及空间定位等作用[31–34]。海马体可以将经历的事件 形成情景记忆或自传性记忆，部分学者将海马视作内侧颞叶记忆系统的一部分， 该系统可以形成一般的陈述性记忆[31]。
前额叶皮层通过抑制竞争性的、错误的情境记忆与海马体互动，实现正确 情境相关记忆的检索[2]。HPC 与 PFC 相互作用的途径之一是从海马体腹侧部 （Ventral Hippocampus，vHPC）到 PFC 的直接投射，另一个间接途径是通过丘 脑和皮层中间通路的双向连接[2, 35, 36]。vHPC 中投射到 PFC 的神经元表现出 空间和情境编码。从 HPC 直接发送到 PFC 的信号与当前事件的整体信息有关。 丘脑联络核（Reuniens，Re）可以很好地连接内侧前额叶皮层（Medial Prefrontal Cortex，mPFC）、海马和相关区域，形成的双向连接支持信息的传递，而这些信 息是认知过程中相互作用的基础[2, 36]。进一步的研究证据表明，PFC 和 HPC 相互作用是通过两个区域神经活动的振荡同步来调节的[2, 35, 36]。vHPC 向 PFC 传递任务有关的情境信息，PFC 通过皮层通路对 HPC 进行自上而下的控制，而 振荡同步是由 Re 介导的（图 2.3）。这些相互作用有助于在记忆处理的不同阶
7

基于神经网络的自主情境特征提取研究
段利用当前环境指导情景记忆检索。Re 对记忆编码的特异性产生一般的调节影 响。Re 的间接通路表明，PFC-HPC 相互作用在记忆检索和区分初始学习环境中 是很重要的。在新情境下，Re 刺激引起兴奋导致冻结增加，反之 Re 刺激引起 抑制导致冻结减少[2]。总而言之，HPC 和 PFC 的相互作用，相辅相成，在情境 记忆中起到了至关重要的作用。
图 2.3 啮齿类前额叶皮层与海马体之间直接和间接的通路[2] Figure 2.3 The indirect and direct pathways between prefrontal cortex and hippocampus of
rodent[2]
2.1.1.2 互补学习系统 自从人类学习和记忆的 CLS 理论[37]提出以来，已经过去了 20 年，这个理
论本身根植于 Marr[26]和其他人的早期思想。根据这一理论，有效的学习需要 两个互补的系统（如图 2.4）[3]:一个位于新皮层，作为逐渐获得有关环境的结 构化知识的基础，而另一个以海马体为中心，快速学习实例和经验的细节。经 过多年研究，海马体是哺乳类动物的中枢神经系统中的脑的部分(大脑皮质)中被 最为详细研究过的一个部位，是海马区的一部分，其重要作用是将经历的事件 形成新的记忆。认知科学和神经科学认为，大脑通过以下两种策略的不同程度 组合实现情境学习的目的[38]：一是目标导向，即对抽象知识巧妙应用，并加以 周密的推理运算对问题找到解决方案，一是习惯导向，即通过不断的训练自动 建立感官刺激和行为响应之间的复杂关联。前者非常接近于人工智能领域的符 号主义，后者则更接近于连接主义。然而，人工智能的发展过程中往往将符号
8

第2章 相关研究综述
主义与连接主义对立起来[39, 40]，顾此失彼。事实上，人类的大脑其实兼顾这 两种方法论的特征。我们既可以学习到刺激输入到行为响应的复杂映射（更接 近连接主义），又可以对周围的世界进行抽象而进行符号推理和运算（更接近符 号主义）。
图 2.4 CLS 示意图[3] Figure 2.4 The schematic diagram of CLS[3]
在 CLS 理论中，海马体的 DG 和 CA3 是快速学习系统的核心。DG 是针对 每个经验选择一个不同的神经活动模式，即使两种经验非常相似，这一过程称 为模式分离[38–42]。CA3 增强参与神经元之间的连接权重以稳定一种经验的活 动模式，并从部分提示中支持模式的重新激活。在重新激活期间，被激活模式 的一部分存储可以激活其他模式，这个过程被称为模式补全[42–44]。内嗅皮层 （Entorhinal Cortex，ERC）和 CA1 之间的连接变化相对缓慢，以使 CA1 和 ERC 模式之间保持稳定的对应关系。ERC 和新皮层区域之间的稳定连接将重新激活 的 ERC 模式传播到新皮层，这一过程称为模式恢复[45]。具体而言，DG 实现模 式分离，即使两种高度相似的模式在通过扩展稀疏合取编码之后，重叠也会大 大降低；CA3 实现模式补全，即使是缺失或是扭曲的记忆也能填充补全成相应 的完整和正确的模式[3]。此外，CA1 与 ERC 的双向连接负责短期-长期记忆的 转换。海马将短期的记忆传到新皮层，完成系统级巩固，并通过重放将学习到 的新信息整合传入新皮层，实现短期记忆到长期记忆的转换[3]。即海马组织是
9

基于神经网络的自主情境特征提取研究
一个暂存系统，当接触到一种信息，便被存于海马，然后大脑会定期检查信息 有没有被再次使用，如果在某一个时期内这个信息被连续多次使用，则判定信 息有用，把信息转存到新皮层以固化形式永久保存，但如果一段时间内没有使 用，就会自行“删除”。该理论为我们设计高效情境信息的存储和调用机制提供 启示。 2.1.2 机器学习研究现状
除了神经科学领域对情境信号研究颇多颇深， 机器学习领域近几年也对 此有一定的研究，尤其是连续学习和多任务学习领域。Google 团队的 Vaswani 等[4]提出的基于情境信号（指令密码）的机器学习，该框架是一个通用计算模 型，主要包含编码模块、卷积层、注意层、稀疏门混合专家层和解码模块（图 2.5），实现了完成不同性质任务的目标，诸如图像分类、模态转换、机器翻译 等，且效果不逊色于单任务最好的结果。在这个系统中，区分不同任务的就是 这个指令密码，也就是情境信号，不同的任务对应于不同的情境信号。在训练 某项任务时情境信号一直存在，辅助进行不同任务的识别，测试时不同的情境 信号也对解码器的输出有着至关重要的作用。
图 2.5 基于情境信号的机器学习网络结构示意图[4] Figure 2.5 The schematic diagram of machine learning network based on context signals[4]
受到 Vaswani 等提出的指令密码和前额叶皮层功能启发，自动化研究所余山 团队的曾冠雄等人[5]提出了情境依赖处理（Context-dependent Processing，CDP） 模块，包括将人为给定的情境信息转化为控制信号的编码器模块和利用控制信
10

第2章 相关研究综述
号对特征进行处理的操作， 实现了同时感知感官信息和情境信息的目的 （图 2.6）。文章中利用正交权重修改（Orthogonal Weights Modiﬁcation，OWM）算 法和 CDP 模块实现了连续多任务学习，比 Vaswani 的网络精简许多的同时也能 实现一套系统多任务学习且性能良好的目的。
图 2.6 情境依赖处理模块示意图[5] Figure 2.6 The schematic diagram of context-dependent processing module[5]
2.2 深度强化学习 深度强化学习（Deep Reinforcement Learning，DRL）是深度学习的一大重
要分支，采用一种通用的形式将深度学习的感知能力与强化学习的决策能力相 结合，通过端到端的学习方式实现从原始输入到输出的直接控制[46]，是人工 智能领域的一个新的研究热点。智能体，即执行强化学习算法的实体，和环境 之间不断进行交互，经过一系列的搜索和试错后产生延迟奖励，从而获取更多 的累积奖励和更可靠的估计[46]（图 2.7A）。举例来说，围棋中的智能体需要根 据当前棋局决定在哪个位置摆放棋子才能最大可能赢得棋局，游戏中智能体需 要根据当前游戏界面环境决定执行何种操作才能获胜或是得分最多，自动驾驶 中智能体需要根据路况信息决定如何安全驾驶至目的地等等。不同于连接主义 学习中的监督学习，强化学习主要表现在强化信号上，由环境提供的强化信号 是对产生动作的好坏作一种评价（通常为标量信号），而不是告诉强化学习系统 如何去产生正确的动作[46]。该过程可以被抽象为马尔科夫决策过程（Markov Decision Process，MDP），用四元组 {, , ,  } 表示，其中  表示状态集合， 表示动作集合， 表示奖励函数， 表示状态转移函数，如  (, ,  ) 表示在当 前状态  ∈  采取动作  ∈  进入状态  ∈  的概率，其核心是状态价值函数和
11

基于神经网络的自主情境特征提取研究
动作价值函数，即贝尔曼方程（Bellman Equation）。深度强化学习分为基于模型 和无模型强化学习，包括基于值函数、基于策略梯度和基于搜索与监督的 3 种 主流方法（图 2.7B）。
自深度强化学习提出以来，在许多需要感知高维度原始输入数据和决策控 制的任务中，DRL 已经取得了实质性的突破。在 DRL 发展的最初阶段，算法主 要被应用于 Atari 2600 平台中的各类 2D 视频游戏中[27, 47]。随后，研究人员分 别从算法和模型两方面对 DRL 进行了改进，使得智能体在 Atari 2600 游戏中的 平均得分提高了 300%，并在模型中加入记忆和推理模块，成功地将 DRL 应用 场景拓宽到 3D 场景下的复杂任务中[46]。AlphaGo [6]围棋算法结合深度神经网 络和蒙特卡洛树搜索（Monte Carlo Tree Search，MCTS），成功地击败了围棋世 界冠军震惊了众人，将 AI 推至人前，成为人口相传的经典成绩。此外，DRL 在 机器人控制、计算机视觉、自然语言处理和医疗等领域的应用也都取得了一定 的成就。
图 2.7 强化学习示意图 Figure 2.7 The schematic diagram of reinforcement learning
2.2.1 基于值函数的深度强化学习 绝大多数强化学习算法都离不开价值函数的计算。价值函数是状态（或状
态与动作二元组）的函数，目的是评估智能体在当前状态（或当前状态与动作）
12

第2章 相关研究综述
下的未来预期奖励，也可称为回报的期望值[46]。深度神经网络先学习动作价 值函数，然后根据估计的动作价值函数选择动作，这就是基于值函数的方法。 DRL 领域的开创性工作，是卷积神经网络与传统强化学习中的 Q 学习算法相结 合的深度 Q 网络（Deep Q-Network，DQN）[27]模型（图 2.8），用于处理基于 视觉感知的控制任务。之后陆续出现了一系列对 DQN 模型的改进，大多工作 选择向原有网络中添加新的功能模块。例如，向 DQN 模型中加入循环神经网络 结构，使得模型拥有时间维度的记忆能力，如竞争深度 Q 网络（Dueling Deep Q-Network）[48]和深度循环 Q 网络（Deep Recurrent Q-Network， DRQN）[49]。 DRQN 在部分状态可观察的情况下比 DQN 有更好的性能，故而适用于普遍存 在部分状态可观察问题的复杂任务。深度双 Q 网络（Double Deep Q-Network） [50]算法通过解耦目标 Q 值动作的选择和目标 Q 值的计算这两步，来消除 Q 值 过度估计的问题，能更准确的估计 Q 函数值，其训练算法和训练得到的策略更 为稳定[46]。
图 2.8 DQN 算法示意图 Figure 2.8 The schematic diagram of DQN algorithm
2.2.2 基于策略梯度的深度强化学习 策略，是状态到每个动作的选择概率之间的映射，即  (|) 含义为  = 
时，  =  的概率。然而策略往往是依赖动作价值函数的，如果没有动作价值 函数的估计，策略也就不存在了。参数化的策略则解决了这一问题，动作选择 不再直接依赖价值函数。价值函数仍然可以用于学习策略的参数，但对于动作
13

基于神经网络的自主情境特征提取研究
选择就非必须了。2000 年，Sutton 等人提出了策略梯度法的概念，之后一系列 工作随之展开，包括自然梯度法[51–57]、确定性策略梯度[58]、蒙特卡洛策略 梯度如 REINFORECE[59]、“行动器-评判器”方法[60, 61]等。从原理上说，策 略梯度方法是一种直接使用逼近器来近似表示和优化策略，通过优化策略的期 望总奖励最终得到最优策略的方法。策略梯度方法能够直接优化策略的期望总 奖励，并以端到端的方式直接在策略空间中搜索最优策略，省去了繁琐的中间 环节，其适用范围更广，策略优化的效果也更好，往往是求解 DRL 问题时的第 一选择。 2.2.3 基于搜索与监督的深度强化学习
基于搜索与监督的深度强化学习通过增加额外的人工监督来促进策略搜索 的过程。而蒙特卡洛树搜索作为一种经典的启发式策略搜索方法，仅仅需要经 验，即状态、动作、奖励序列，而不需拥有完备的环境知识。MCTS 通过平均 样本的回报来解决问题，被广泛用于游戏博弈问题中的行动规划。因此在基于 搜索与监督的 DRL 方法中，策略搜索一般是通过 MCTS 来完成的。例如著名 的 AlphaGo[6]围棋机器人将深度神经网络和 MCTS（图 2.9）相结合，先使用监 督学习从人类专家的棋局中预测人类的走子行为，再用策略梯度方法针对赢得 围棋比赛的真实目标进行精细的策略参数调整。之后的 AlphaGo Zero[62]则是在 AlphaGo 的基础上，采用了简化版本的 MCTS 在整个自我对局强化学习期间进 行走子[46]，区别于 AlphaGo 只在在线对局时采用 MCTS。
图 2.9 AlphaGo 蒙特卡洛树搜索计算过程[6] Figure 2.9 The caculation process of Monte Carlo Tree Search in AlphaGo[6]
14

第2章 相关研究综述
2.3 本章小结 本章主要介绍情境学习在神经科学与机器学习领域的研究工作和互补学习
系统原理，以及深度强化学习的主流方法及经典算法，重点介绍了情境学习与 互 补 学 习 系 统 的 原 理 概 念。 目 前 主 流 的 强 化 学 习 算 法 依 赖 大 量 的 搜 索 和 试 错， 往往需要较长的训练时间，且十分消耗计算资源。然而，其实在情境复杂的任 务如游戏中，算法往往忽略了情境信号的作用。本文将在第三章在详细阐述本 研究提出的情境处理模块，介绍各个子模块的理论基础和设计思路，并给出相 应的网络架构。
15

基于神经网络的自主情境特征提取研究 16

第3章 情境处理模块（CPM）
第3章 情境处理模块（CPM）
本章节将针对如何自主提取任务中关键的情境信号提出相关解决方案并进 行原理概念阐述。该方案受互补学习系统中 PFC 与 HPC 相互作用及功能的启 发，设计了一个复合模块，即情境处理模块，主要包含三个子模块，依次为模 式分离模块、模式补全模块和模式整合模块。通过模块间的合作实现自主提取 情境信号辅助网络决策的目的，该模块可以有效地提升深度强化学习的学习效 率并在情境图像分类中有良好的性能。
3.1 模式分离模块
模式分离作为脑区的关键功能之一，能辅助小脑皮层、DG 等神经回路分离 来自感觉和运动信息的重叠模式，而区分相似的神经元活动模式对大脑识别外 部世界的细微变化至关重要。这个概念最初由 Marr 受少量苔藓纤维投射到大量 稀疏活跃的颗粒细胞而神经元间重叠度大大降低的生物现象启发提出[26]。实际 上，HPC 的容量限制及其有限的概括能力，无法支持单一的海马系统，因此使 用模式分离编码相关经验而不是相对密集的基于相似性的编码方案，可能在某 些情况下自适应更强[3]。在经典海马体三突触回路系统中，DG 的功能便是在 记忆存储于海马之前分离 ERC 的输入模式，在整个学习过程中起着至关重要的 作用。病变和基因缺失的研究表明，DG 对环境的微小变化高度敏感，对于辨别 类似环境是必要的[49, 63–65]。此外，DG 损伤会严重影响动物在两种非常相似 的环境中做出不同反应的能力，而保留在两个不相似的环境中做出不同反应的 学习能力[65]。
从神经生物学角度，DG 通过扩展重编码、稀疏编码加高阶联合的神经元连 接，可以找出环境中细微但重要的差异，实现了将两种即使十分相似的模式区 分识别并转化为更清晰不同输出模式的功能，以达到降低输出重叠的目的。DG 的独特功能和解剖特性研究结果表明，DG 中的每个神经元只有在多个输入神经 元同时激活的条件下才会做出反应，类似合取编码，支持了高度稀疏、连接表 征的形成，减少了相似输入模式之间的重叠[38, 39, 65]，增加存储容量，并减少 它们之间的干扰。例如，两种相似模式（6 个神经元表征）可以通过扩展稀疏
17

基于神经网络的自主情境特征提取研究
联合编码，重叠度从 67% 下降至 50% （图 3.1A）。REMANGE[66] 模型将 HPC 多阶段回路抽象简化为功能层和联合层（图 3.1B），分别对应 ERC 和 HPC，反 映了一种互相激活竞争的模型[10]和记忆范式[67–69]。联合层的局部编码反映 了理想化的 DG/CA3 稀疏分布的模式分离编码，如激活 A 和 C 可以激活 AB 和 BC，AB 和 BC 共同激活 B，进而进一步激活 AB 和 BC，进而抑制其他涉 及 A 和 C 的连接。特征层和联合层之间的双向连接，类似 HPC 和新皮层区域 （如 ERC）之间的循环连接，网络的输出作为系统再循环的后续输入，有助于 发现出现在一系列相关的事件中的高阶结构。与 CA3 减少低重叠输入模式的重 叠而增加输入模式高重叠的重叠不同，DG 是对所有输入模式降低其重叠度（图 3.1C）。Albus 提出将每个活动模式视作活动空间中的一个点[70]，每个维度则 对应一个不同的神经元活动，同时认为小脑输入层的发散结构在扩展的活动空 间中重新标记输入模式，从而增加了输入模式的线性可分性（图 3.1D）。
图 3.1 扩展稀疏联合编码原理示意图。（A）相似度变化比较，（B）REMERGE模型，（C） 模式输入输出重叠度变化曲线，（D）升维效果。
Figure 3.1 The schematic diagram of the principle of the extended sparse joint coding. (A) Similarity change comparison, (B) REMERGE model, (C) the change curve of input and output pattern’s overlap, and (D) dimension increase eﬀect.
18

第3章 情境处理模块（CPM）

图 3.2 PS 模块设计架构 Figure 3.2 The design architecture of PS module

受扩展重编码、稀疏编码和联合编码的启发，我们设计了相应的模式分离 模块（图 3.2）。假设第 L 层为 PS 模块，第 L-1 层输出特征为 FL−1 = [ 0, 1, · · · , −1] ∈ Rm，输入权重矩阵为 WL = [wL0 , wL1 , · · · , wLn−1] ∈ Rm×n，其中 wLi ∈ Rm×1。PS 模块层的公式可以总结为：

YL = ( (MLselect) (WL) FL−1)

. . . (3.1)

其中，g 为 ReLU（Rectiﬁed Linear Units）激活函数，即  = max(0, )，MLselect

是结合稀疏和联合编码设计的选择矩阵，具体为 MLselect = [mL0 , mL1 , · · · , mLn−1] ∈

Rn×n，公式中 mLi ∈ Rn×1。根据扩展编码思想，第 L 层神经元数大于第 L-1 层

神经元数（m<n），此处

     −1

=

4， 

表示第 L 层的神经元数。每个

L-1

层的神经元与第

L

层的所有神经元连接，即

 


=

(FL−1)TwLi ，其中

wLi

是第

L 层权重矩阵的第 i 列， 表示第 L 层中的第 i 个神经元的中间输出。第 L 层 



中的第 i 个神经元的最终输出为  = ( 

  )  , 

。选择矩阵

MLselect

是

0-1

矩

 =1

阵，0 和 1 的比例取决于重要超参：稀疏度 ，即如果  为 0.8，则选择矩阵中

80% 为 0，20% 为 1，这也与生物神经元只与部分神经元的突触相连而非与整

个脑区的神经元都有直接的传导关系的事实相符。选择矩阵在网络训练前给定，

在训练和测试过程中固定不变，稀疏的 0-1 矩阵可视作最终输出层每个神经元

固定的选择其中的某些中间输出层神经元的结果综合后进行输出，类似联合编

19

码的原理。

基于神经网络的自主情境特征提取研究

3.2 模式补全模块

CA3 是 CLS 理论中快速学习系统的核心区域之一，有着极其重要的的功 能作用。在上一小节的介绍中，DG 的功能是模式分离，如马、驴和斑马即使 输入模式极其相似，通过 DG 区域可以将其模式的重叠度大大降低（图 3.3A）， 而 CA3 则是希望能将不同形态的马同一识别为同一类别，即使身体花纹、姿 态不同或是模式不完整有遮挡（图 3.3B），依旧可以检索识别并进行补全。模 式补全可以根据片段或扭曲的模式， 填充剩余特征， 即激活的部分模式可以 重新激活其余的模式，或者参考与熟悉模式相似的模式，使其更加相似。计算 模拟分析中， 中高度重叠模式存储至原有记忆， 而低重叠模式则创建新的记 忆[42, 71, 72]。例如，感知输入在 ERC 中生成的模式与以前的模式类似时，CA3 输出更接近以前用于该 ERC 输入模式的模式[73, 74]。相反，模式与先前存储的 模式重叠较低时，DG 在 CA3 中产生一个新模式。除了 ERC 和 DG 的模式权衡， CA3 输入与自身循环输入对称连接构成的自联想网络，即 DG 输入 CA3 与 CA3 输入 CA3 的权重相同，促进了记忆和决策。
受 CA3 功能连接的启发，PC 模块利用网络前几层输出模式，综合前一 时刻的自身输出，可视作以前存储记忆的模式，权衡相加后输出补全后的模式 （图 3.3C）。PC 模块也可解释为一种循环神经网络（Recurrent Neural Network， RNN），它的输出不仅取决于当前的输入，还受到前一时刻输出的影响。PC 模 块当前的输入又分为前一层的输出和原始层的输出。设第 0 层 t 时刻的输出为 Y0t ∈ Rk，第 L-1 层 t 时刻的输出为 YtL−1 ∈ Rn，第 L 层即 PC 层 t-1 时刻的输出 为 YLt−1 ∈ Rp，则第 L 层的输出为：

YLt = ( (Ww) ℎ( (Wu) Y0t + (Wv) YLt −1 + (Wv) YLt−1)))

. . . (3.2)

其中，h 为 tanh 激活函数，g 为 sigmoid 激活函数，Ww、Wu、Wv 分别是不同 的权重矩阵。由于 PC 模块加在 PS 模块后面，经过 PS 模块后的输出模式是稀疏 扩展后的模式，模式之间的重叠度大大降低的同时也使得同类模式之间的相似 处被忽略，因此选择最前层的未经处理的原始模式作为参考，结合分离后的模 式，同时查看存储记忆中的以前模式，即前一时刻的自身输出，最后得到补全 后的输出模式。如图 3.3D 中举例，每个 PC 中的神经元都对原始层、前一层和

20

第3章 情境处理模块（CPM）
记忆层中的部分神经元权衡相加后得到自己的输出。在游戏这类时序关系极为 重要的任务中，循环神经网络能综合前时刻的局面和当前环境，考虑更多的前 后依赖关系，更有全局性，同时也可将它前一时刻的输出视为另一种记忆存储， 根据权衡相加后的输出给出更好更稳定的决策。
图 3.3 PC 模块原理与结构示意图。（A）DG 模式分离效果，（B）CA3 模式补全效果，（C） PC 模块网络架构，（D）补全效果图
Figure 3.3 The schematic diagram of principle and structure of PC module. (A) Eﬀect of DG’s pattern separation, (B) Eﬀect of CA3’s pattern completion, (C) network architecture of PC module, and (D) eﬀect diagram of completion.
3.3 模式整合模块 前两个小节所介绍的 PS 和 PC 模块分别对应着不同的功能，同时也对应着
截然相反的目的，即分离和补全、降低相似度和归纳总结。经过这两个模块的 最终输出与原始模式存在着较大的差异。而真实的情况往往需要综合考虑原始 模式和特异化的模式，将信息整合后进行输出，这样才不会出现过于功能化的 情况。因此，我们在两大功能模块后加入 PI 模块，在功能模式和原始模式权衡 后给出最终的输出（图 3.4）。设第 0 层的输出为 Y0 ∈ Rk，第 L-1 层的输出为
21

基于神经网络的自主情境特征提取研究

YL−1 ∈ Rp，第 L 层的输出为：

YL = ( (Ws) YL−1 + (WT) Y0)

. . . (3.3)

其中，g 为 ReLU 激活函数，Ws、Wt 为权重矩阵。该模块接受 PC 模块输出的 归纳模式，将较为粗糙的归纳模式与当前状态的原始模式进行综合，输出更适 用于当前状态的综合模式，更精准地辅助网络进行决策。

图 3.4 PI 模块结构图 Figure 3.4 The structure diagram of PI module
3.4 情境信息与感观数据结合
在 CLS 理论中，海马和新皮层系统共同参与许多任务的执行和许多不同类 型的记忆。任务和记忆类型被看作是一个连续体，对两种学习系统有不同程度 的依赖。海马体和新皮层网络共同促进了检索，共同介导背景联想知识。根据 前额叶皮层与海马体的功能连接特性，我们设计了相应的结合算法（图 3.5）， 连续卷积层作为特征提取器，提取出来的特征流向两个支流网络模块，下层是 感知信息编码器即简单的线性全连接层，上层是情境信息编码器即 CPM。CPM 接受来自最后一层卷积的特征输入，输出到一层全连接层进一步提取特征，此 时的特征为原始模式，再送入一层线性层，之后进行功能化提取，即依次经过 PS 模块、PC 模块和 PI 模块，最后输入维度线性全连接层进行升降维操作生成 与下层输出维度一致的情境特征。然后情境信息与下层网络线性层的感知输出 进行点乘融合，类似 PFC 将 HPC 整合之后送入其他区域，实现根据情境信息将 感知特征在参数空间上进行旋转的目的，调控信息流，在改变感知特征的同时 保留关键信息。最后网络将融合感知和情境信息的特征传入后续分类器或逻辑 回归层进行下游任务训练最终输出相应计算结果。
22

第3章 情境处理模块（CPM）
图 3.5 感官特征与情境信号结合示意图 Figure 3.5 The schematic diagram of combination of sensory features and contextual signals
设 CPM 提取得到的情境信息为 C = [1, 2, · · · , ] ∈ Rk，感知特征为 F = [ 1, 2, · · · , −1] ∈ Rk，则两者结合后的输出为 Ycombine = F C，然后网络 将 Ycombine 送入下游网络进行进一步处理。综上，算法可总结为：
步骤 S1：连续卷积层特征提取。利用连续卷积层提取输入数据（图片或状 态矩阵）中的重要特征。
步骤 S2：感知全连接层。简单的线性全连接层进一步提取连续卷积层最终 输出的感知特征。
步骤 S3：CPM 提取情境信息。连续卷积层提取的特征依次流向线性层、PS 模块、PC 模块和 PI 模块，最终由升降维编码器生成与下层感知特征维度一致的 情境特征。此处，每张图片或是状态矩阵都有与此一一对应的情境特征向量。
步骤 S4：融合情境信息和感知信息。将上层 CPM 提取的情境信息与下层 感知信息点乘融合，将感知信息在特征空间上进行“旋转”，得到融合后的综合 特征。
步骤 S5：下游任务。将融合后的综合特征送入下游网络进行进一步处理， 如图像分类则对应分类器，逻辑回归则对应逻辑回归层。经过上述操作，每个 样本的最终输出不仅取决于感知输入，还取决于情境信息，是两者的综合。
本文工作的主要贡献在于，CPM 能自主从原始输入中提取与当前任务相关 重要的情境特征，并通过端到端训练实现情境特征与感知特征融合、辅助决策 的效果，相较于前人的工作如 CDP 模块而言，不再需要人为给定情境信号向
23

基于神经网络的自主情境特征提取研究
量，改进了前人的工作，实现了自动化。 3.5 本章小结
本章详细阐述了情境处理模块的三个子模块：PS、PC 和 PI 模块，从生物神 经学和功能特性的角度解释了每个模块的设计理念和灵感来源，给出了相应的 网络架构和数学计算公式，将三大模块与线性层和维度编码器串接，形成完整 的复合模块 CPM。CPM 对每个输入样本都可以自主提取其对应的情境信息，并 将 CPM 模块和感知特征进行融合，送入下游网络进行下一步任务相关的处理， 构成了完整的网络架构体系。该架构适用于连续学习、多任务学习和情境相关 的任务。总的来说，本章设计了专门用于情境信号的无监督提取的网络模块。
24

第4章 CPM 在强化学习中的自主情境信息提取

第4章 CPM 在强化学习中的自主情境信息提取

本章重点阐述了 CPM 模块在强化学习方面的应用。目前大部分深度强化学 习算法依赖大量的试错和搜索，导致训练耗时耗资源，所以在强化学习算法领 域探索尽可能少的训练样本就能达到良好的性能以节省训练时间的研究具有极 大的意义。因此，我们将 DQN 和 CPM 相结合，利用情境信号加速网络的训练。 实验证明，在 Pacman 游戏上加入 CPM 的网络有明显的性能提升且训练速度明 显加快。与此同时，通过研究感知特征、情境特征和旋转特征的编码信息，我 们探索了各子模块的功能意义。

4.1 网络设计
本小节将介绍 DQN 与 CPM 的具体网络架构以及游戏任务 Pacman 的具体 规则。基准网络是两层卷积层加三层全连接线性层，网络的输入是游戏状态矩 阵，输出是经网络计算后选择每个动作所能得到的未来预期累积奖励，也可称 为奖励的期望，此处即为 DQN 算法中的 Q 值，计算公式为：

  (, ) =  (+1 +   (+1, +1) | = ,  = )

. . . (4.1)

其中，+1、+1、+1 依次是 t+1 时刻的奖励、状态和动作， 、 是 t 时刻的 状态和动作， 是折扣系数，  表示在 t 时刻 s 状态下采取 a 动作的预期回报， 是动作良好性的体现。DQN 中采用两个网络来进行训练和参数更新，具体算法 为：
步骤 S1：初始化参数，并收集随机游戏的经验集 ( ,  ,  , +1) 填充重放记 忆（Replay Memory）单元；
步骤 S2：按照 -贪婪算法选择动作，即选择目标网络（TargetDQN）输出 的最大 Q 值对应的动作或以  概率随机选择动作；
步骤 S3：执行动作并得到新的状态和当前动作的奖励，将得到的经验存入 记忆单元；
步骤 S4：从记忆单元中随机抽小批量数据训练主网络（MainDQN），并每 隔固定 C 轮复制 MainDQN 的参数到 TargetDQN 中进行更新；

25

基于神经网络的自主情境特征提取研究
图 4.1 Pacman 地图与基准网络加入 CPM 结构示意图 Figure 4.1 The map of Pacman and the structure diagram of baseline network joining CPM
图 4.2 简单 MLP 作为 CPM 的网络示意图（A）及在 Pacman 游戏性能上的表现。（B）平均 最大 Q 值，（C）平均得分，（D）平均胜率，其中淡蓝色和淡红色颜色区域表示 95% 的置信区间。
Figure 4.2 The network diagram of simple MLP as CPM and its performance on Pacman. (B) Average maximum Q value, (C) average score, and (D) average winning percentage, in which the light blue and light red color regions represent conﬁdence intervals of 95%.
26

第4章 CPM 在强化学习中的自主情境信息提取
步骤 S5：循环步骤 S2-S4，直至完成规定的训练轮数。 在基准 DQN 算法的基础上，我们在卷积层之后接入 CPM 模块，和下层网 络中的第一层全连接层并行计算，形成两条支路，其对应的计算结果点乘之后 送入下游网络继续执行计算任务（图 4.1B）。针对 Pacman 游戏而言，网络接受 游戏状态的输入，经过连续卷积层的特征提取，将结果分别同时送入 CPM 和下 层感知线性层，两条支路产生的情境特征和感知特征点乘融合之后继续经过下 游两层线性层，最终计算给出每个动作的 Q 值。 在该章节中，我们选取较为简单的 Pacman 游戏作为测试任务，游戏界面如 图 4.1A 所示，该游戏规则明确，元素总计 5 种。Pacman 是雅达利公司于 1982 年推出的 Atari 2600 中其中一款较为经典流行的游戏。游戏包含几大元素：吃 豆人、胶囊、豆子、鬼和围墙。只要吃豆人吃完局面中所有存在的豆子并且不 被鬼碰到，就算游戏胜利。吃豆人每吃一个豆子会有相应的得分，吃掉局中的 胶 囊 则 会 有 一 个 较 大 的 得 分， 而 且 此 时 彩 色 的 正 常 鬼 会 变 色， 进 入 恐 惧 状 态， 加之行动速度变慢为正常的一半，此时吃豆人可以反过来吃恐惧鬼以获得更大 的得分。被吃掉的恐惧鬼则会回到起点复生恢复正常状态。但是，如果吃豆人 在这一步中未得到任何分数，则相应会有一个步数惩罚扣掉相应的分数。游戏 终止出现在两种情况：一是吃豆人顺利躲开鬼并吃完了所有的豆子；二是吃豆 人没有避开正常鬼直接死亡。在这个游戏中，存在较为少量且明确的情境因素， 方便我们进行情境特征的研究和测试。本章选取该游戏作为任务，进行性能方 面定性和定量比较，并从特征类别角度探究各模块的编码内容，详细内容将在 下面小节中阐述。
4.2 性能测试 4.2.1 多层感知机
在测试实验设计的三大子模块的效果之前，本文使用 4 层全连接层构成的 多层感知机（Multilayer perceptron，MLP）作为 CPM 加入基准网络中，研究其 性能表现作为参照组。本文选择三个数值指标作为比较参照，分别是平均最大 Q 值（Max_Q）、游戏平均得分（S），游戏平均胜率（W），其中最大 Q 值即为 一局游戏中网络所有输出的 Q 值的全局最大值，而平均最大 Q 值即为选取 50 局 游戏为间隔单位，计算每 50 局游戏的平均最大 Q 值，同理平均得分是每 50 局
27

基于神经网络的自主情境特征提取研究
的平均游戏得分，平均胜率是每 50 局的胜局数目除以局数 50 所得的平均胜率。 本文选取的指标均为平均值，是出于强化学习训练结果的不稳定性以及结果振 荡剧烈的因素的考虑，也同时是出于对结果的简洁展示的考虑，慎重选择之后 决定的。网络架构如图 4.2A 所示，连续卷积层之后分两个支路，上层为 MLP 组 成的 CPM，下层为一层线性层组成的感知层，两者融合后的特征送入下游两层 网络执行计算。图 4.2B-D 依次为平均最大 Q 值、平局得分和平均胜率的结果展 示，其中蓝色实线代表基准网络 DQN 的指标随训练局数的变化，红色表示加入 CPM 后的表现，图中均分别绘制了 95% 的置信区间。无论是参考指标最终达到 稳定的局数，还是其上升和稳定的速度以及胜局刚开始出现的初始局数，三个 指标均表明单纯的 MLP 作为 CPM 在 Pacman 上已有较为明显的性能优势。
4.2.2 模式分离模块
强化学习中的诸多任务，例如棋类博弈、Atari 2600 或是机器人操纵等，都 普遍存在一种现象，即状态空间庞大，其中许多状态的相似度极高，但其在某 些条件下相似状态又对应着不同的最佳决策。例如，智能体采取行动的前后两 个状态普遍相似度极高，但状态间的细微差别很可能对整个任务的执行起着决 定性的作用，尤其在游戏和棋类博弈中较为显著。以五子棋为例，三子同色一 线，第四子同色或是异色对整个棋局有着完全不同的意义，而在 Pacman 游戏 中，接近吃豆人的鬼的颜色将决定着智能体采取躲避还是吃鬼的行为。细节决 定成败在强化学习的诸多任务中往往有着深刻的体现。如何让网络学会根据状 态中某些重要细节将相似状态进行区分，就显得极为重要。
上一小节结果显示简单的 MLP 已经能够带来网络性能的提升，而我们希望 在此基础上继续改进。在本小节中，我们将应用设计的 PS 模块取代 MLP 中第 三个线性层，同时为了说明 PS 模块的作用，我们保证了 4 层线性层维度的不变 性，即每层全连接层神经元的个数与之前一致，具体的 CPM 网络架构如图 4.3A 所示。图 4.3B-D 依次为平均最大 Q 值、平局得分和平均胜率的结果展示。比较 显示，加入稀疏选择编码（ > 0.0）的 CPM 比原始 MLP（ = 0.0，即选择矩 阵此时为全 1 矩阵）的性能有更进一步的提升，但是由于图示较难完整显示其 具体细微差别，为此本文设计了一些定量化的指标以数值形式进行比较。首先 是三大指标，考虑到即使经过平均后的数据仍存在细微振荡，如果仅仅看最后 一个数值结果对实际数值层面的比较有较大的影响且不公平，故而我们在平均
28

第4章 CPM 在强化学习中的自主情境信息提取
图 4.3 加入 PS 模块的 CPM 示意图（A）及在 Pacman 游戏性能上的表现。（B）平均最大 Q 值，（C）平均得分，（D）平均胜率。
Figure 4.3 The schematic diagram of CPM with PS module (A) and its performance on Pacman. (B) Average maximum Q value, (C) average score, and (D) average winning percentage.
的基础上再进行平均，选取最后 10 个数值取其平均值，得到的结果作为最后的 比较指标，其结果可视为最后 500 局游戏的平均值，可靠度和公平性得到了进 一步的保障。除此以外，我们设计了稳定点（ ）和起胜点（ ）两大指标， 分别针对 S 和 W 进行计算。稳定点，即平均得分中某点与最后一点连线的斜率 小于某个阈值  的第一个数值点的横坐标，即局数，此处设定  为 0.3。起胜 点，即平均胜率中第一个非 0 点的横坐标，也就是首次出现胜局的局数。
数值统计结果如表 4.1 所示，据此分析可得结论，单纯的 MLP（稀疏度 = 0.0）相较于原始基准网络在训练速度和性能指标均有明显提升，而加入 PS 模 块（稀疏度  > 0.0）的网络较 MLP 均有更为显著的提升，且稀疏度较大的比稀 疏度较小的性能更佳。其中以  为 0.8 时表现最佳，Q 值从基准网络的 228.8673 提升至 230.4255，平均得分提升至 1053.8，平均胜率则提升了 6.11%，稳定点提 前了 950 局，起胜点则提前了 1000 局，综合各指标的性能提升可见其有效性。 此处相比于前一小节的 MLP 只加入了固定非可训练的选择矩阵，并无网络容量 的增加，所以排除了相应的扩容因素，确定是稀疏选择的作用才导致了良好的 表现，证实了 PS 模块的有效性。
29

基于神经网络的自主情境特征提取研究

表 4.1 CPM 在 Pacman 中性能的量化统计 Table 4.1 Quantitative statistics of performance of CPM in Pacman

DQN DQN + PS( = 0.0) DQN + PS( = 0.1) DQN + PS( = 0.2) DQN + PS( = 0.3) DQN + PS( = 0.4) DQN + PS( = 0.5) DQN + PS( = 0.6) DQN + PS( = 0.7) DQN + PS( = 0.8) DQN + PS + PC DQN + PS + PC + PI

Q 228.8673 231.7121 230.9806 228.4003 232.1148 230.3839 231.6661 230.3952 230.7528 230.4255 227.7222 231.6010

S 940.7 1001.3 1014.8 990.6 1029.1 1002.0 1012.9 1019.8 1013.5 1053.8 1027.7 1141.7

St 3400 3200 2850 3100 2600 2500 2450 2800 2250 2450 2350 2750

W(%) 39.69 41.75 43.12 42.29 44.36 41.91 42.82 43.65 43.18 45.80 43.20 50.04

Wstart 2050 1350 850 1050 1100 1200 1050 1050 850 1050 1350 1450

4.2.3 模式补全模块
在上一小节中，PS 模块能显著提升训练效果，但 PS 模块只一味地将所有 的模式都降低重叠度的做法是有所欠缺的。在实际任务中，存在状态之间相似 度较低但仍属于同一情境的情况。以围棋为例，无论棋局如何多变，只差一颗 棋子就能完成围困对手棋子的诸多局面中最佳决策几乎只有一种选择，就是将 棋子放在围子的对应位置，这个决策始终能达到吃子的最佳效益，往往是不变 的。又例如 Pacman 中，智能体在四周围绕豆子的情况下总是选择吃豆行为，而 面临彩色鬼的围追堵截时，总是选择与鬼背道的路线，这些情况可以总结为几 种条件情境，不同的条件情境又包含着诸多不同的状态，但其对应的最佳行为 决策是相同的。所以，将所有的状态完全区分是片面的，我们还需要网络学会 将所有的状态进行总结归纳，如此才能学会其根本和潜在的规则，这就是 PC 模 块期望的功能。
PC 模块接受三部分的输入，分别是来自 PS 模块分离后的输出、CPM 第一 层线性层输出的原始模式和上一时刻 PC 模块自身的输出，相当于参考当前分 离后的模式、最初的原始模式和前一时刻自身输出的模式（即当前状态的上一 状态的输出），综合权衡后将模式补全为较为普适的归纳模式，达到总结主要规 则知识的效果。这样的设计有三大优势：防止 PS 模块过度分离导致的复杂化； 结合了时序信息，不再是当前状态决定全部，更有全面性，鲁棒性更强；结合

30

第4章 CPM 在强化学习中的自主情境信息提取
原始模式补全分离稀疏模式，归纳总结更具意义。我们将 PC 模块加在 PS 模块 后，网络结构如图 4.4A 所示。图 4.4B-D 是加入 PC 模块的 CPM 在 Pacman 游 戏上的性能变化，其中蓝色实线代表基准网络 DQN 的指标随训练局数的变化， 红色表示加入只加入 PS 模块的 CPM 的性能表现，黄色表示加入 PS 和 PC 模块 的指标随训练局数的变化情况，图中均分别绘制了 95% 的置信区间，其中稀疏 度  均为 0.8。从图中可以看出，加入 PC 模块后网络的稳定速度更快，尤其是 平均得分和平均胜率达到稳定后的一段时间内，性能表现更佳。从数值指标角 度（表 4.1），稳定点提前至 2300，此时在此基础上再进行优化就有了更好的基 础点，在下一小节中将有后续证明。
图 4.4 PC 模块示意图（A）及在 Pacman 游戏性能上的表现。（B）平均最大 Q 值，（C）平 均得分，（D）平均胜率，其中淡蓝色、淡红色和淡绿色颜色区域表示 95% 的置信区 间。
Figure 4.4 The schematic diagram of PC module (A) and its performance on Pacman. (B) Average maximum Q value, (C) average score, and (D) average winning percentage, in which the light blue, light red and light green color regions represent conﬁdence intervals of 95%.
31

基于神经网络的自主情境特征提取研究
4.2.4 模式整合模块 在上两个小节中，通过加入 PS 和 PC 模块，网络在 Pacman 游戏中的性能
有了显著的提升，但 PS 和 PC 均是功能性模块，且两者目标存在一定的矛盾， PS 模块致力于将所有的模式降低其相似度，模式之间尽可能不重叠，而 PC 模 块则希望将所有的同类模式进行综合，输出补全后的归纳总结模式。因此，我 们在 PC 模块之后加入 PI 模块，希望此模块能将目前的模式进行整合输出。
图 4.5 PI 模块示意图（A）及在 Pacman 游戏性能上的表现。（B）平均最大 Q 值，（C）平 均得分，（D）平均胜率，其中淡蓝色、淡红色和淡绿色颜色区域表示 95% 的置信区 间。
Figure 4.5 The schematic diagram of PI module (A) and its performance on Pacman. (B) Average maximum Q value, (C) average score, and (D) average winning percentage, in which the light blue, light red and light green color regions represent conﬁdence intervals of 95%.
PI 模块接受两部分的输入：PC 模块的输出和 CPM 第一层线性层输出的原 始模式（图 4.5A）。由于 PC 模块本身是综合了三种输出进行的总结归纳，其中 PS 模块的输出和自身上一时刻的输出均与原始模式有较大的差异性，因此 PC
32

第4章 CPM 在强化学习中的自主情境信息提取
模块的输出也与原始模式大相径庭。PI 模块将再次接受原始模式，期望将功能 模块的输出结合原始模式，输出更适合当前状态的综合模式，即特异化的归纳 模式，达到精准辅助的效果。性能如图 4.5B-D 所示，其中蓝色实线代表基准网 络的指标变化，红色表示加入加入 PS 和 PC 模块的 CPM 的性能表现，黄色表 示加入 PS、PC 和 PI 模块的 CPM 在 Pacman 游戏中的指标变化情况，图中均分 别绘制了 95% 的置信区间。由图所示，加入 PI 模块的 CPM 尤其在训练稳定后 期，平均得分和平均胜率均有较大提高，数值层面几乎所有的指标均有显著的 提升（表 4.1），平均得分提升至 1141.7，而平均胜率达到 50.04%，较基准网络 有了 10.35% 的提升，表现相当优异。
为了排除网络扩容因素导致的性能提升，我们用全连接层和 1*1 卷积层依 次取代其中对应的模块进行了对比实验。由于 PS 模块相较于 MLP 只增加了选 择矩阵不存在该问题，这里只对 PC 模块和 PI 模块进行了实验，同样取 10 次实 验的均值，结果如图 4.6 所示。无论是 PC 模块还是 PI 模块，加入之后的效果均 高于单纯的全连接层或 1*1 卷积层，排除了扩容因素。另外，我们针对两种特 征融合的位置进行了比较试验，即三层线性层中在第一层线性层还是第二层线 性层输出后融合（图 4.7A）情境特征。结果（图 4.7B-D）显示在第一层输出后 融合有较好的性能表现，数值结果在表 4.2 中呈现。
图 4.6 PC 和 PI 模块有效性对比实验。（A）平均得分，（B）平均胜率。 Figure 4.6 The contrastive experiments of eﬀectiveness of PC and PI module. (A) Average
score, and (B) average winning percentage.
综合上述结果，PS、PC 和 PI 三个子模块的加入有效提升了网络在 Pacman 游戏上的性能，且排除了容量因素带来的影响。三个模块各司其职，相互配合， 详细论述将在章节 4.3 情境信号分析中展开，此处不进行相关阐述。
33

基于神经网络的自主情境特征提取研究

图 4.7 融合位置变动对性能的影响。（A）变动融合位置后的网络结构，（B）平均最大 Q 值，（C）平均得分，（D）平均胜率，其中淡蓝色和淡红色颜色区域表示 95% 的置信 区间。
Figure 4.7 The impact of fusion position changes on performance. (A) The network structure after changing the fusion position, (B) average maximum Q value, (C) average score, and (D) average winning percentage, in which the light blue and light red color regions represent conﬁdence intervals of 95%.

表 4.2 CPM 位置变化在 Pacman 中性能的量化统计

Table 4.2 Quantitative statistics of performance of CPM position change in Pacman

DQN DQN + CPM(layer1) DQN + CPM(layer2)

Q 228.8673 231.6010 231.7594

S 940.7 1141.7 1091.5

St 3400 2750 3250

W(%) 39.69 50.04 48.38

Wstart 2050 1450 1500

34

第4章 CPM 在强化学习中的自主情境信息提取
4.3 CPM 情境特征提取分析
为了进一步探索复合模块 CPM 的作用，此处的 CPM 包含所有的子模块， 我们将抽提出的特征进行 PCA 降维显示，研究各层特征究竟对游戏状态中的何 种元素进行了编码以及融合前后特征的表征变化。本文选取下层网络全连接线 性层输出的感知特征、CPM 输出的情境特征和两者融合之后的旋转特征作为观 察对象，重点考察 Pacman 游戏中较为重要的三大元素：豆子、鬼和胶囊。我们 以当前状态下豆子的总数、恐惧鬼（即变色后的鬼）的数目以及胶囊的数目为 颜色标签，将特征进行 PCA 降维，进行前三大主元素的空间绘制展示，数据点 的颜色代表着三种不同元素的数目标签。如图 4.8A 所示，同次训练中感知特征 （左上角）、情境特征（右上角）和旋转特征（底层中间）都对当前状态下豆子 的数目有清晰的空间聚类现象，并从相应的类间散度层面出发，能得到较为相 似的结果，整体上旋转特征（红色）的类间散度大于情境特征（蓝色）大于感 知特征（黑色），而类间散度呈现中间低两边高的趋势。这种现象并非个例，在 其他训练组中具有可重复性（图 4.8B）。
同样，本文采用同样的 PCA 降维可视化方法对胶囊数和恐惧鬼数进行了相 关的研究，但由于样本存在较大的数量差异，即一局游戏中大部分状态是两个 胶囊和两个正常颜色的鬼，聚类效果较为单一，因此另外使用 t-SNE 可视化方 法进一步验证了该结果，如图 4.9A-B 所示的情境特征降维后的空间分布效果， 其他特征也较为类似。我们选择类间散度作为统计指标，在 20 次训练中统计每 次训练最大类间散度对应的特征，即横坐标，纵坐标为其频率。例如，在标签 为胶囊数的标签下，旋转特征总共 10 次为三种特征中的最大类间散度，频率为 频率为 0.5，感知特征有 7 次，则为 0.35。此为间接的统计，从一定层面也能 反映出两种标签下，旋转特征的类间散度更大的事实。但综合来看，三大特征 编码豆子的信息最为明显。我们对此给出的解释是，在游戏中恐惧鬼和吃胶囊 属于少数情形，且在这少数情形中又需考虑智能体与目标间的障碍物、距离等 等因素，情境转化导致的直接决策变化更加稀少，故而空间分布的聚类效果较 差。而豆子较为均匀的存在于界面中，豆子的数目一定程度上也反映了局面的 进程，智能体在游戏的过程中更加倾向于吃豆子，属于一种局部决策，更符合 当前的最佳奖励，因此三大特征都对豆子的数目有较为显著的空间聚类。综上 所述，特征对豆子进行了编码，而 CPM 的存在使得融合后的特征类间散度增
35

基于神经网络的自主情境特征提取研究
图 4.8 关于豆子数量的特征空间分布研究及类间散度分析 Figure 4.8 Study on the feature space distribution of the number of beans and analysis of
interclass divergence
36

第4章 CPM 在强化学习中的自主情境信息提取
大，各个类别有更好的区分度。
图 4.9 关于胶囊、恐惧鬼数量的特征空间分布研究及最大类间散度统计 Figure 4.9 Study on the feature space distribution of the number of capsule and scared ghost
and statistics of maximum interclass divergence
由此，我们继续研究三大子模块的作用，分别将只有 PS 模块、只有 PC 模 块、PS 加 PC 模块、PS 加 PC 加 PI 模块的 CPM 提取的情境特征以豆子数目为标 签进行 PCA 降维展示，研究其模块提取的最终特征在空间分布上的聚类效果， 如图 4.10 所示。显而易见，只有 PS 模块的 CPM 降维后的分布（图 4.10A）是 一条扭曲的线，所有的模式都在这条线上，完全看不出任何的聚类现象，重叠 度极低，这也与 PS 模块设计的目标一致，即将所有的模式完全区分。为此，我 们抽取了输入 PS 模块前的模式和对应的 PS 模块处理后的模式，研究前后的相 似度变化。我们随机选取 10 个状态，将变化前后的状态均归一化至 [0,1] 区间，
37

基于神经网络的自主情境特征提取研究
图 4.10 PS（A）、PC（B）、PS+PC（C）和 PS+PC+PI（D）模块提取的情境特征关于豆子 数量的空间分布分析
Figure 4.10 Analysis on spatial distribution of contextual features extracted by PS (A), PC (B), PS+PC (C) and PS+PC+PI (D) module about the number of beans
图 4.11 PS 模块前后模式平均欧氏距离分析 Figure 4.11 Analysis on average Euclidean distance of modes before and after PS module
38

第4章 CPM 在强化学习中的自主情境信息提取
计算每个状态与所有其他状态的欧氏距离之和，除以其他状态的个数，得到该 状态与其他状态的欧氏距离均值，同时计算其标准差，比较 PS 模式的输入和输 出的相似度，得到的结果如图 4-11 所示。数据表明，经 PS 模块处理后的模式欧 式距离有所增加，相似度有所下降，与之前的结论相符。单独 PC 模块的降维效 果则有一定的区分度（图 4.10B），部分同类标签聚在一处，但也存在一定的融 合现象。PS 加 PC 模块的效果比单独的子模块有了更好的表现（图 4.10C），出 现了层次化现象，不再是一条曲线或是离散聚类，且此时展现的聚类效果更加 丰富，数据点的分布更广，也从侧面说明了 PS 和 PC 模块相互配合导致的归纳 更具异质性。而完整的加入 PI 模块的降维展示出更强的聚类效果（图 4.10D）， 此时对豆子的编码具有更大的响应，分块显色更加显著，而且从主分量的数值 层面其特征区分进一步扩大。
图 4.12 FC（A）、PS（B）、PC（C）、PI（D）模块提取的情境特征关于豆子数量的空间分 布分析
Figure 4.12 Analysis on spatial distribution of contextual features extracted by FC (A), PS (B), PC (C) and PI (D) module about the number of beans
为了进一步证实我们的推测，我们抽取了一次训练结束后网络的 CPM 第二 层全连接层（FC）的输出、第二层全连接层流入 PS 模块的输出、PC 模块的输
39

基于神经网络的自主情境特征提取研究
出和 PI 模块的输出，将所有这四种输出的模式进行 PCA 降维，得到对豆子数的 空间分布情况如图 4.12 所示。结果显示，线性层的输出在经过 PS 模块处理后 呈现十分明显的离散分布（图 4.12B），而 PC 模块综合三个输入之后模式呈现 比线性层更为明显的团簇现象（图 4.12C），最后 PI 模块在整合 PC 和原始模式 之后的输出更加贴近 FC （图 4.12A）的形态，同时也对信息有了更进一步的处 理（图 4.12D）。这完全符合我们之前提出的各个模块的功能，展现了各子模块 之间分工合作的有效性。

4.4 网络参数

本研究中 Pacman 地图选用中等地图， 借鉴了阿姆斯特丹大学 Pycho 在 GitHub 上传的代码 （https://github.com/tychovdo/PacmanDQN）， 网络参数如表 4.3 所示，每层参数选用随机初始化，除了 PC 模块中选择先用 tanh 激活函数 后用 sigmoid 激活函数，其他所有层的激活函数选择 ReLU 激活函数。PS 模块 若无特殊指明，一般令稀疏度  为 0.8。研究中输入矩阵为简化后的状态位置矩 阵，分别是围墙位置矩阵、吃豆人位置矩阵、正常鬼位置矩阵、恐惧鬼位置矩 阵、豆子位置矩阵和胶囊位置矩阵，每一个矩阵都是地图大小的 0-1 矩阵，相应 元素所在的位置标 1，其余标 0。表 4.4 列出了本章中 Pacman 的游戏得分规则。

表 4.3 网络参数配置

Table 4.3 Conﬁguration of network’s parameters

Params Replay memory size RMS delay RMS episodes Batch size Discount rate Learning rate Training start  start  steps  ﬁnal Context size

settings 100000
0.99 10 − 6
32 0.95 0.0002 10000 1.0 100000 0.1 256

40

第4章 CPM 在强化学习中的自主情境信息提取

表 4.4 Pacman 游戏得分规则

Table 4.4 Scoring rules in Pacman

Action Eat ghost Eat dot Loss (Collision with a ghost) Time punishment Won (All dots eaten)

Score 200 10 −500 −1 500

4.5 本章小结
本章节展示了本文的核心工作之一，CPM 在强化学习任务中自主提取情境 特征，选取存在较为少量且明确情境因素的 Pacman 游戏作为任务指标。本章依 次选择 MLP、PS、PS+PC 和 PS+PC+PI 作为 CPM 进行对比实验，并对情境特 征和感知特征融合的位置进行了研究，从定性和定量两个层面对性能进行了系 统的比较。结果表明，CPM 实现了较大的性能提升并减少了达到训练稳定所需 的局数。
本研究同时探索了 CPM 的功能作用，从降维后特征针对不同的元素类别的 空间分布的角度研究了各模块的编码内容。本节中选取感知特征、情境特征和 旋转特征作为比较对象，将特征进行 PCA 降维后三维可视化，并利用类间散度 作为定量指标研究其变化，得出结论：CPM 能有效地对某一元素进行编码，实 际达到扩大类间距的效果，增加了区分度。同时，该研究也证实了 PS 子模块具 有分离模式降低重叠度的作用、PC 子模块具有归纳融合补全模式的效果，进一 步证实了我们提出的类脑模块的功能和有效性。

41

基于神经网络的自主情境特征提取研究 42

第5章 CPM 在情境图像分类中的自主情境信息提取
第5章 CPM 在情境图像分类中的自主情境信息提取
本章主要研究了 CPM 复合模块的作用机制，探索 CPM 对情境信息的编码 工作。针对前一章节游戏中情境信号复杂难定的问题，本章设计了新的情境图 像分类任务。该图像分类任务具有两种与真实标签相关的元素：原始标签和标 记区块位置，由两种信号共同决定最终标签。简单明了的两种信息方便我们进 行 CPM 具体编码了何种情境信号的探索，以及研究情境特征与感知特征融合前 后的差别。我们通过情境图像分类任务的性能比较和特征空间分布探索，研究 了网络解耦两种信息的可能，以及解耦目标的效果。
5.1 Contextual MNIST 为了进一步研究情境处理模块，我们将之运用到图像分类领域，设计了一
个新的图像分类任务 Contextual MNIST。具体操作为在 MNIST[75] 常规手写数 字数据集中，对每个批次（batch）的数据随机抽取一半进行图像标记，即在左 上角（1）、左边中间（2）、左下角（3）、中间上（4）下（5）以及右上（6）、 右中（7）、右下（8）共 8 个位置选择其一打上 3*3 的灰色区块（图 5.1），最终 真实标签的计算公式为 Label = 10 ∗ loc + Label。若无区块标记则判定 为原始类别，也可将无标签视作位置为 0。该任务不仅要区分图片中的具体的 实际数字，还要在此基础上根据区块位置给出不同的判定结果。例如，20 类图 像分类任务包含原始 0-9 类以及左上角有灰色区块的 10-19 类，以此类推。
图 5.1 Contextual MNSIT 任务示意图 Figure 5.1 The diagram of Contextual MNIST task
43

基于神经网络的自主情境特征提取研究
Contextual MNIST 研究中底层网络采用两层卷积层、两层线性层和一层输 出层的配置，而 CPM 相较于强化学习任务中的设置少了 PC 层，只包含两层线 性层、PS 子模块、PI 子模块和维度升降编码器。考虑到图片间不存在时序关 系，删去自身循环连接的 PC 模块与 PI 模块架构相同，因此删去了 PC 模块。最 终的网络结构如图 5.2 所示。
图 5.2 Contextual MNIST 图像分类任务 CPM 结构图 Figure 5.2 The structure diagram of CPM in Contextual MNIST image classiﬁcation task
5.1.1 性能比较 本小节将底层网络，即无 CPM 的两层卷积层、两层全连接层和一层输出层
构成的底层网络称为基准网络，以卷积网络（CNN）代称，而将一层全连接层 作为感知网络并上 CPM 的网络命名为情境网络（Context Network，CNet）。图 5.3A 展示了 20 类（即选择左上角标记位置或者不选）有无 CPM 的分类结果。 经过 20 次训练，每次训练 50 轮（epoch），将所有 20 次训练的结果做平均，以 平均损失函数值（loss）、平均训练准确率（Train Accuracy）和平均测试准确率 （Test Accuracy）为指标研究其性能表现，其中黑色虚线表示 CNN，彩色实线代 表不同稀疏度  的 CNet。显而易见，CNet 的最终 loss 值低于 CNN，且训练准 确率和测试准确率均高于基准网络 CNN，说明 CPM 能更有效的帮助网络进行 判别。从稀疏度  的角度出发， 为 0.0 的性能较其他值普遍逊色，说明稀疏 合取编码能更有效地辨别不同的情境，尤其是在复杂情境中。然后，我们拓展 类别数，即位置选取个数由 1 个增加至全部的 8 个，也由此产生了 20 类到 90 类的不同难度的任务，结果如图 5.3B 所示，横坐标代表类别数，纵坐标代表最 后得到的平均损失函数值、平均训练准确率和平均测试准确率，蓝色三角图例
44

第5章 CPM 在情境图像分类中的自主情境信息提取
代表 CNN ，绿色方框图例代表 CNet 。这些均值是在平均 20 次训练结果后再次 对最后 5 个 epoch 的结果做平均计算所得的数据。结果显示，CNet 在所有类别 数的实验中性能相比较于 CNN 有显著的提升，能达到更低的损失和更高的准确 率，说明在 Contextual MNIST 任务中，CNet 有很高的普适性，可以覆盖不同难 度的情境信息。
图 5.3 CPM 在Contextual MNIST 任务上的表现。（A）20 分类损失函数值、训练准确率 和测试准确率，（B）20 分类至 90 分类任务最终损失函数值、训练准确率和测试准确 率，（C）NetC 网络架构，（D）CCNet 网络架构，（E）4 种网络平均最终测试准确率。
Figure 5.3 The performance of CPM on the contextual MNIST task. (A) The loss function value, training accuracy and test accuracy in 20 classiﬁcation task, (B) the ﬁnal loss function value, training accuracy and test accuracy in 20 to 90 classiﬁcation tasks, (C) network architecture of NetC, (D) network architecture of CCNet, (E) the average ﬁnal test accuracy of the four networks.
45

基于神经网络的自主情境特征提取研究
为了排除网络容量带来的性能提升，我们重新设计了一个网络结构，删除 上层 CPM，将 CPM 取代下层感知网络即一层全连接层（图 5.3C），称之为 NetC，另一种网络架构则保留上层 CPM 的同时用一个相同的 CPM 取代感知层 （图 5.3D），称之为 CCNet。图 5.3E 展示了四种网络在所有类别数中的最终平均 测试准确率，CNet 性能均高于 NetC，说明性能的提升不只是网络容量的因素， 更有 CPM 本身网络设计的功劳。这个结论也可在图 5.3A 中的 NetC 代表的蓝 色虚线和 CNet 代表的彩色实线对比以及图 5.3B 中 NetC 代表的粉色星型图例 和 CNet 代表的绿色方框图例的对比中得出。而 CCNet 更进一步说明了这个问 题，即使网络比 CNet 更为复杂，但其对性能反而有损害，高于 NetC，但均弱 于 CNet，可能存在过拟合的问题。
5.1.2 CPM 作用分析
本节中，Contextual MNIST 设计两种信息，一种为原始标签，另一种为标记 位置。为了进一步研究感知层和情境模块的编码内容，以及融合后特征的表征 内容，本研究选取感知层输出的感知特征、CPM 输出的情境特征和融合后的旋 转特征作为研究对象，以标记位置、原始标签和真实标签为信号标签区分，将 三种特征进行 PCA 降维，在三维立体图中显示相应标签的聚类情况。图 5.4A-C 分别展示了 20 类分类任务中同一次训练下感知特征、情境特征和旋转特征的 PCA 降维后前三大主分量关于三种信号标签在空间中的分布情形。图中的第一 列标记点颜色表示不同的区块标记位置，如 0 的深蓝色表示无标记，1 的黄色 表示左上角有灰色区块标记，第二列散点颜色为原始标签，第三列不同的颜色 则代表不同的真实标签。由图可知，感知层对灰色区块的标记位置在空间中分 布聚类效果最为明显，两种情况分割成两团，情境层对原始标签聚类最为明显， 对其他却并无任何聚类表征，呈现混乱的状态，而融合后的旋转特征对三者都 有了明显区分，在有效区分标记位置和原始标签的基础上，对真实标签的区分 更加显著。对比感知特征和融合特征的真实标签的空间分布中，我们发现感知 层的团状分布混合被拉成独立分割的纤长表征，每一个类别相较于感知层都有 了更好的分类聚集情况。根据这种现象，我们推断上下层网络将标记位置和原 始标签两种决定最终标签的因素进行了解耦操作，上层复杂的 CPM 负责编码原 始标签信息，下层感知层负责灰色区块标记位置的表征，旋转特征将两者融合， 保留两种信息的同时也对最终的真实标签进行了区分编码，故而能实现更好的
46

分类。

第5章 CPM 在情境图像分类中的自主情境信息提取

图 5.4 Contextual MNIST 关于不同标签的特征空间分布分析。（A）感知特征，（B）情境特 征，（C）旋转特征，其中每列标记点颜色依次代表不同的标记位置、原始标签和真实 标签。
Figure 5.4 Distribution analysis of feature on diﬀerent labels in Contextual MNIST. (A) Perceptual feature, (B) contextual feature, and (C) rotation feature, in which the color of each column of mark points represents diﬀerent mark position, original label and real label in turn.
为了探究 CNet 优于 CNN 的原因，我们提取 CNN 中某层全连接层的输出进 行与上述研究方式相同的 PCA 降维空间分布展示，结果如图 5.5 所示。前两列 分别是对标记位置和原始标签的空间分布聚类效果，最后一列是主分量针对真 实标签的空间分布展示。在 CNN 的该线性层中，同时对标记位置和原始标签进
47

基于神经网络的自主情境特征提取研究
行了编码。值得注意的是，图 5.5A 的 20 分类任务中在不同的标记位置对应的 团状中有一一对应的原始标签聚类团簇，即在位置 0 的团簇中分别有 0-9 对应 的小团簇，在位置 1 的簇中也有 0-9 对应的小团簇，且这两个位置团簇中关于每 一个原始标签的团簇呈现上下位置对应的关系。据此，我们可以理解为该线性 层是根据位置数分成几个大团簇，而每个大团簇中对应的 0-9 原始标签的小团 簇在大团簇中的空间位置一一对应，类似复制一个位置大团簇的效果，综合后 再给出最终的真实标签。但是，在 30 分类（图 5.5B）至 90 分类（图 5.5C）任 务中，并没有相似的情况，而是类似 CNet 的解耦操作，但线性层需要同时对两 种信号进行了编码，综合后给出最终的类别，相对来说任务难度大于单独信号 的分类，这也是 CNN 较 CNet 差的原因之一。
图 5.5 Contextual MNIST中CNN线性层关于不同标签的特征空间分布分析。（A） 20 分 类，（B）30 分类，（C）90分类，其中每列标记点颜色依次代表不同的标记位置、原 始标签和真实标签。
Figure 5.5 Distribution analysis of feature of one linear layer in CNN on diﬀerent labels in Contextual MNIST. (A) 20 classiﬁcation, (B) 30 classiﬁcation, and (C) 90 classiﬁcation, in which the color of each column of mark points represents diﬀerent mark position, original label and real label in turn.
48

第5章 CPM 在情境图像分类中的自主情境信息提取
图 5.6 不同分类任务中感知特征关于标记位置和情境特征关于原始标签的空间分布研 究。（A）30分类，（B）40 分类，（C）70 分类，（D）80 分类，（E）90 分类。
Figure 5.6 Research on the spatial distribution of perceptual features related to the location of labels and contextual features related to the original labels in diﬀerent categories tasks. (A) 30 classiﬁcation, (B) 40 classiﬁcation, (C) 70 classiﬁcation, (D) 80 classiﬁcation, and (E) 90 classiﬁcation.
49

基于神经网络的自主情境特征提取研究
根据上述 CNet 和 CNN 的特征分析，我们推断 CNet 上下层网络将标记位置 和原始标签这两种信息进行了解耦，一个负责标记位置，只需判别 2 到 9 种情 况，一个只负责原始标签，需要判别 10 种手写数字特征，融合的旋转特征则负 责结合两种信息实现最终分类。而 CNN 则需要同时判别两种信息。解耦的实际 优势在于两层网络分别判别标记位置以及 10 类数字，是加法关系，如 20 类分 类任务中 2 种标记加 10 个数字，而不是 CNN 的乘法关系，大大降低了网络的 识别难度。分工明确条理清晰，任务难度的下降，直接影响了网络的分类性能， 这也就是 CNet 优于 CNN 的原因。
图 5.7 不同分类任务中情境特征关于标记位置和感知特征关于原始标签的空间分布研 究。（A）70 分类，（B）80 分类，（C）90 分类。
Figure 5.7 Research on the spatial distribution of contextual features related to mark location and perceptual features related to original labels in diﬀerent categories tasks. (A) 70 classiﬁcation, (B) 80 classiﬁcation, and (C) 90 classiﬁcation.
50

第5章 CPM 在情境图像分类中的自主情境信息提取

同时，我们对 20 类至 90 类分类任务的所有空间分布进行了统计分析研究， 发现在 90 类分类任务中，网络的编码情况出现了反转，即 CPM 编码了标记位 置信息，感知层编码了原始标签信息。首先，我们观察了 20 类至 90 类分类中 的两层网络预期的编码情况，即感知层编码标记位置，CPM 编码数字特征。图 5.6A-C 分别展示了 30 类、40 类和 70 类感知层对标记位置的空间分布和 CPM 对原始标签的空间分布，情况还是与 20 类任务中的结论相符的，而图 5.6D 在 80 类任务的情况下已经有点开始模糊的趋势，但还是能辨别一定的位置和原始 标签。但在 90 类分类任务中（图 5.6E）情况出现了完全的逆转，感知层完全不 能辨别标记位置，CPM 对原始标签也出现了较为明显的混乱情形。

表 5.1 CNN 在 MNIST 10 分类和位置标签分类任务中的测试准确率 Table 5.1 Test accuracy of CNN in MNIST 10 classiﬁcation and location mark classiﬁcation
tasks

Task MNIST LOC_2 LOC_3 LOC_4 LOC_5 LOC_6 LOC_7 LOC_8 LOC_9

ACCU ± STD 99.1611 ± 0.0963
100 ± 0.0000 100 ± 0.0000 100 ± 0.0000 99.9947 ± 0.0165 99.9996 ± 0.0012 99.9989 ± 0.0031 88.5063 ± 2.7044 88.0628 ± 8.5626

针对这种现象，我们进一步研究了感知层对原始标签和 CPM 对标记位置 的编码情况。结果显示，在 70 类的时候 CPM 就对标记位置有了一定的判别性 （图 5.7A），随着类比数的增多即标记位置的增加（图 5.7B和C），CPM 对标记 位置的编码越来越清晰，相比之下感知层对原始标签则有着明显编码区分行为。 在这种情况下，两个同步子网络的功能出现了对调，编码信息呈现了转换。对 于网络的这种情况，我们推断是位置标记数的增多增大了判别位置的难度，最 终该子任务难度大于 MNIST 原始标签 10 分类子任务的难度，网络自动将难度 高的任务分配给具有更高复杂度和更大网络容量的 CPM，而感知层相对而言较 简单，则负责相应容易的任务。为了进一步证实该推断，我们将 MNIST 的十分 类任务和单独的位置分类任务，即忽略 MNIST 原始标签只根据包括无标记类别
51

基于神经网络的自主情境特征提取研究
为 0 其余位置如前定义的位置标签进行分类，进行了测试。总计 10 个任务，同 样经过 20 次训练，每次训练 50 轮，利用 20 次训练后的测试准确率结果计算平 均值和标准差，结果如表 5.1 所示。标记位置的增多导致任务的准确率出现下 滑，直至判别 8 个位置和 9 个位置的情况下准确率低于 MNIST 十分类的准确 率。这也就证明了我们关于网络自动根据任务难易程度分配子网络各自功能的 推测。 5.2 Contextual CIFAR10
类似情境图像分类任务 Contextual MNIST 的设计，Contextual CIFAR10 就 是在 CIFAR10 数据集（图 5.8）中，对每个 batch 的数据随机抽取一半进行图像 标记，即在左上角（1）、左边中间（2）、左下角（3）、中间上（4）下（5）以 及右上（6）、右中（7）、右下（8）共8个位置选择其一打上3*3的灰色区块，最 终真实标签计算公式也为 Label = 10 ∗ loc + Label。同样，网络在区分 图片的具体实际类别的同时，还要在此基础上根据区块位置给出不同的最终类 别判定结果。
图 5.8 CIFAR10 数据集[7] Figure 5.8 CIFAR10 datasets[7]
5.2.1 性能比较 同 Contextual MNIST 的网络配置，Contextual CIFAR10 将底层网络，即无
CPM 的三层卷积层、两层全连接层和一层输出层构成的底层网络为基准网络，
52

第5章 CPM 在情境图像分类中的自主情境信息提取
以卷积网络（CNN）代称，而将一层全连接层为感知网络并上 CPM 的网络命名 为情境网络（CNet）。图 5.9A 展示了 20 类（即选择左上角位置或者不选）任务 中有无 CPM 的分类结果。经过 20 次训练，每次训练 50 轮，将所有 20 次训练 的结果做平均，以平均损失函数值（loss）、平均训练准确率（Train Accuracy） 和平均测试准确率（Test Accuracy）为指标研究其性能表现，其中黑色虚线表示 CNN，彩色实线代表不同稀疏度的 CNet。显而易见，CPM 能更有效的帮助网 络进行判别，CNet 的最终 loss 值低于 CNN，且训练准确率和测试准确率均高于 基准网络。从稀疏度  的角度出发， 为 0.0 的性能较其他值普遍逊色，说明稀 疏合取编码能更有效地辨别不同的情境，在 CIFAR10 的任务中同样适用。然后， 我们拓展类别数，即位置选取个数由 1 个增加至全部的 8 个，也由此产生了 20 类到 90 类的不同难度的任务，结果如图 5.9B 所示，横坐标代表类别数，纵坐标 代表最后得到的平均损失函数值、平均训练准确率和平均测试准确率，这些均 值是在平均 20 次训练结果后再次对最后 5 个 epoch 的结果平均后的数据。结果 显示，CNet 在性能上相比较于 CNN 有显著的提升，说明在 Contextual CIFAR10 上，CNet 有很高的普适性，可以覆盖不同难度的情境信息。
为了排除网络容量带来的性能提升，我们也重新设计了两个网络结构，删 除上层 CPM，将 CPM 取代下层感知网络即全连接层，称之为 NetC，另一种网 络架构保留上层 CPM 的同时用一个相同的 CPM 取代感知层，称之为 CCNet。 图 5.9C 展示了四种网络在所有类别数中的最终平均测试准确率，CNet 性能大部 分情况下高于 NetC，排除了性能的提升只是网络容量增大的因素所带来的的效 益的可能，更有其本身网络设计的原因。在这个实验中，CCNet 的性能是四种 网络中最佳的，考虑到 CIFAR10 数据集图片信息十分丰富，需要更复杂的网络 来进行区分，这也是可以理解的。由于柱状图中部分性能比较接近，无法准确 比较相应高低，尤其是 NetC 和 CNet。为了进一步显式化其性能差距，我们将 后三种网络的平均测试准确率减去基准 CNN 的准确率，绘制了图 5.9D，清晰展 示了在两者较为接近的 20 类、60 类和 70 类中CNet略优于 NetC，而 CCNet 几 乎始终保持着遥遥领先的地位。
5.2.2 CPM 作用分析
类似 Contextual MNIST，Contextual CIFAR10 也同样设计了两种信息，一种 为原始标签，另一种为标记位置。为了进一步研究感知层和情境模块的编码内
53

基于神经网络的自主情境特征提取研究
图 5.9 CPM 在 Contextual CIFAR10 任务上的表现。（A）20 分类损失函数值、训练准确率 和测试准确率，（B）20 分类至 90 分类任务最终损失函数值、训练准确率和测试准确 率，（C）4 种网络平均最终测试准确率，（D）3 种网络平均最终测试准确率减去 CNN 平均最终测试准确率的差值比较。
Figure 5.9 Performance of CPM on the contextual CIFAR10 task. (A) The loss function value, training accuracy and test accuracy in 20 classiﬁcation task, (B) the ﬁnal loss function value, training accuracy and test accuracy in 20 to 90 classiﬁcation tasks, (C) the average ﬁnal test accuracy of the four networks, (D) comparison of the diﬀerence between the average ﬁnal test accuracy of the three networks minus the average ﬁnal test accuracy of CNN.
54

第5章 CPM 在情境图像分类中的自主情境信息提取
容，以及融合后特征的表征情况，本研究同样选取网络中感知层输出的感知特 征、CPM 输出的情境特征和融合后的旋转特征作为研究对象，以标记位置、原 始标签和真实标签为信号标签区分，将三种特征进行 PCA 降维，在三维立体图 中显示相应标签的聚类分布情况。图 5.10A-C 分别展示了 20 类任务中同一次训 练下感知特征、情境特征和旋转特征 PCA 降维后的前三大主分量关于三种信号 的空间分布，第一列数据点颜色表示不同的标记位置，第二列散点颜色为原始 标签，第三列不同的颜色代表不同的真实标签。由图可知，感知层对标记位置 聚类最为明显，两种情况分割成两团，情境层对原始标签聚类分布明显，对其 他并无表征，而融合后的旋转特征对三者都有了明显区分，在有效区分位置和 原始标签的基础上，对真实标签的区分更加显著。从最终的真实标签的空间分 布情况来看，感知层的不同标签的团状混合分布在旋转特征中被拉成独立分割 的完整表征，每一个类别相较于感知层都有了更清晰的分类聚集情况。该现象 进一步证实了前面的推断，上下层网络将标记位置和原始标签两种决定最终标 签的因素进行了解耦操作，上层复杂 CPM 负责编码原始标签信息，下层感知层 负责灰色区块标记位置的表征，旋转特征将两者融合，保留两种信息的同时也 对最终的真实标签进行了区分编码，故而能实现更好的分类。
为了探究 CNet 优于 CNN 的原理，我们同样提取了 CNN 中全连接层的输出 进行相同的 PCA 降维展示，如图 5.11 所示。图 5.11A 至 C 分别是 20 类、30 类和 90 类分类任务，三列依次是对标记位置、原始标签和真实标签的分析。在 CNN 的该线性层中，同时对标记位置和原始标签进行了编码。类似 Contextual MNIST 的结果，在不同的标记位置对应的团状中有一一对应的原始标签聚类团簇，即 在位置 0 的团簇中分别有 0-9 对应的小团簇，在位置 1 的簇中也有 0-9 对应的 小团簇，且这两个位置团簇中关于每一个原始标签的团簇呈现上下位置对应的 关系。据此，我们可以理解为该线性层是根据位置数分成几个大团簇，而每个 大团簇中对应的 0-9 原始标签的小团簇在大团簇中的空间位置一一对应，类似 复制一个位置大团簇的效果，综合后再给出最终的真实标签。但由于 CIFAR10 的图片信息远比 MNIST 复杂，空间分布的聚类效果比 MNIST 较差，团簇状的 分布清晰度更差。不同于 Contextual MNIST 的是，CNN 始终是乘法关系（图 5-11B-C），即几个大团簇包含一一对应的小团簇，并没有出现两者关系的完全 解耦，即类似 CNet 的现象。据此，我们推测是由于 CIFAR10 的图片信息更复
55

基于神经网络的自主情境特征提取研究
杂，导致线性层无法完成乘法的解耦，只能较为基础地将每个类别单独分析。
图 5.10 Contextual CIFAR10 关于不同标签的特征空间分布分析。（A）感知特征，（B）情 境特征，（C）旋转特征，其中每列标记点颜色依次代表不同的标记位置、原始标签和 真实标签。
Figure 5.10 Distribution analysis of feature on diﬀerent labels in Contextual CIFAR10. (A) Perceptual feature, (B) contextual feature, and (C) rotation feature, in which the color of each column of mark points represents diﬀerent mark position, original label and real label in turn.
根据上述 CNet 和 CNN 的特征分析，证实了 CNet 上下层网络将标记位置 和原始标签这两种信息进行了解耦，分别负责标记位置和负责原始标签的编码， 融合的旋转特征则负责结合两种信息实现最终分类。CNN 则需要同时判别两种 信息，为每个位置生成一个大团簇再在内部类似复制形成原始标签的小团簇。 由于 CIFAR10 图片信息的分类难度较大，始终高于标记位置判别，故而在该数 据集上并未出现上下层编码任务的反转情况。网络解耦将原本的乘法关系改为 加法关系，降低了任务难度，提升了网络的分类性能。
56

第5章 CPM 在情境图像分类中的自主情境信息提取
图 5.11 Contextual CIFAR10 中 CNN 线性层关于不同标签的特征空间分布分析。（A）20 分 类，（B）30 分类，（C）90分类，其中每列标记点颜色依次代表不同的标记位置、原 始标签和真实标签。
Figure 5.11 Distribution analysis of feature of one linear layer in CNN on diﬀerent labels in Contextual CIFAR10. (A) 20 classiﬁcation, (B) 30 classiﬁcation, and (C) 90 classiﬁcation, in which the color of each column of mark points represents diﬀerent mark position, original label and real label in turn.
57

基于神经网络的自主情境特征提取研究
5.3 细粒度图像分类 CPM 在新设计的情境图像分类任务的两个数据集上具有优异的表现，发
现上下层网络可以实现两种信息解耦并融合的功能。接下来本小节希望能扩展 CPM 的实用性，将之运用到普通的图像分类任务。针对 PS 模块和 PI 模块的功 能特性，本文选取了细粒度分类任务作为测试数据集，验证 CPM 是否对此类任 务有性能上的提升。我们选取 ResNet50 作为基准网络，在 ResNet50 中增加了一 层感知层，即全连接线性层。CPM 同样是两层线性层、PS 模块加 PI 模块，最 后接一层维度编码层，保证情境特征维度与感知特征维度的一致性。此处稀疏 度  经测试设定为 0.5。本研究中选择 CUB_200_2011 （图 5.12）作为测试数据 集，该数据集包含 200 中不同类别的鸟，需要网络判别各种属类鸟的细微差别， 符合设定的预期目标。
图 5.12 CUB_200_2011 数据集[8] Figure 5.12 CUB_200_2011 datasets[8]
我们在基准网络，即加入一层线性层的 ResNet50 网络上测试了细粒度数据 集 CUB_200_2011 的分类测试准确率（表 5.2），有无 CPM 形成两个对照组，两 组实验均进行了 10 次，取其平均值并计算标准差。实验证实，加入 CPM 的网 络性能从原始网络的 80.2037% 提升至 80.3516%。数据显示，加入 CPM 的网 络分类性能有了提高的趋势，但不是很显著，说明 CPM 在这类细粒度分类中也 可能起到一定的作用，如何利用 CPM 提升网络的性能还需要进一步的探索和研 究。这让我们对其适用领域有了一定的信心，CPM 可能拥有更大的适用空间。
58

第5章 CPM 在情境图像分类中的自主情境信息提取

表 5.2 CPM 在 CUB_200_2011 上的性能 Table 5.2 Performance of CPM on CUB_200_2011

Network ResNet50 ResNet50+CPM

ACCU ± STD 80.2037 ± 0.3861 80.3516 ± 0.1629

5.4 数据集和网络参数 5.4.1 数据集
本研究中共涉及三个通用数据集，分别是 MNIST 手写数字数据集、CIFAR10 数据集和细粒度图像分类数据集 CUB_200_2011。
MNIST[75] 数据集是美国国家标准与技术与研究所 （National Institute of Standard and Technology，NIST）收集发布的开源数据集，包含 60000 张训练 图片和 10000 张测试图片，共计 70000 张，主要内容为 0-9 手写体数字，共计 10 类，图片为黑白灰度图片，尺寸为 28*28。
CIFAR10[7] 数据集是 Alex Krizhevsky 和 IIya Sutskever 整理发布的识别普适 物体的小型数据集，10 类 RGB 彩色图片包含狗、马、飞机、汽车等物体，总计 60000 张，其中每一类别训练集 5000 张，测试集 1000 张，尺寸为 32*32*3。相 比于灰度图像的 MNIST，CIFAR10 存在噪声大、物体比例和特征大相径庭的问 题，识别难度大于 MNSIT。
CUB_200_2011[8] 数据集是加州理工学院于 2010 年提出的细粒度数据集， 共计 11788 张 RGB 彩色图像，其中 5994 张训练图片，5794 张测试集，包含 200 种鸟类子类。
5.4.2 网络参数
Contextual MNIST 采用两层卷积层、两层线性层和一层输出层的基准底层 网络。第一层卷积层滤波器数为 16，卷积核尺寸为 5*5，边界填充（padding） 为 2，第二层卷积层滤波器数为 32，卷积核尺寸为 5*5，采用 2 的边界填充， 两层卷积层步长均为 1。在每层卷积之后紧接 ReLU 激活函数和大小为 2 的最大 池化层。两层线性层维度均为 128，输出层为类别数，根据实际情况灵活变动。 CPM 依次采用 256、128、512、256 和 128 个神经元构成的线性层组合，其中

59

基于神经网络的自主情境特征提取研究
512 和 256 个神经元对应的线性层依次对应 PS 模块和 PI 模块，每个线性层之后 使用 ReLU 激活函数增加其非线性，稀疏度  定为 0.8，网络权重参数均采用随 机初始化。
Contextual CIFAR10 采用三层卷积层、两层线性层和一层输出层的基准底层 网络。第一层卷积层滤波器数为 32，卷积核尺寸为 5*5，采用 2 的边界填充， 第二层卷积层滤波器数为 64，卷积核尺寸为 5*5，采用 2 的边界填充，第三层 卷积层滤波器数为 96，卷积核尺寸为 3*3，边界填充为 2，三层步长均为 1。在 每层卷积之后紧接 ReLU 激活函数和大小为 2 的最大池化层。两层线性层维度 依次为 256 和 128，输出层为类别数，根据实际情况灵活变动。CPM 依次采用 256、128、512、256 和 256 个神经元构成的线性层组合，其中 512 和紧接着的 256 个神经元对应的线性层依次对应 PS 模块和 PI 模块，每个线性层之后使用 ReLU 激活函数增加其非线性，稀疏度  定为 0.8，网络权重参数均采用随机初 始化。
CUB_200_2011 任务选择使用 ResNet50 作为基准网络，情境特征维度为 256，因此在 ResNet 最后线性层之前加入 256 个神经元的全连接层作为感知 层，CPM 每层维度则依次为 256、128、512、256 和 256，网络权重参数均采用 kaiming 初始化，稀疏度  定为 0.5。
5.5 本章小结
本章节展示了本文核心工作之一，CPM 在图像分类方面的应用，新设计了 Contextual MNIST 和 Contextual CIFAR10 情境图像分类作为任务指标，通过灰 色小区块标记和新的最终标签计算方式使得一张图片的类别融入了两种关键信 息，便于我们进行特征编码研究分析。本章选择两层线性层、PS+PI 模块和维度 编码层作为 CPM 和无 CPM 的底层基准网络 CNN 进行对比实验，从结果可以 看出，CPM 实现了较大的性能提升。
本研究同时探索了 CPM 的功能作用，从特征表征类别标签角度的探究各模 块的编码内容。本节中选取感知特征、情境特征和旋转特征作为比较对象，将 特征进行 PCA 降维后三维显示研究其融合前后变化，得出结论：针对两种信号， 有 CPM 的网络能实现两种信息的解耦，即上下层网络各负责一种信息编码，融 合后进行真实类别区分。这种目标信息的解耦实现了将乘法关系转变为加法关
60

第5章 CPM 在情境图像分类中的自主情境信息提取
系，降低了网络识别任务的难度，有效提升了性能，且这种解耦会根据任务难 易程度由网络自动分配编码任务，进一步证实了我们提出的类脑模块的功能性 和有效性。
为了进一步扩展其实用性，我们选取 ResNet50 为基准网络，CUB_200_2011 鸟类细粒度数据集为基准任务，测试发现加入 CPM 后网络性能有一定的提升趋 势，说明在普适任务中，CPM 可能也有着一定的发挥余地，而这需要进一步的 探索和研究。
61

基于神经网络的自主情境特征提取研究 62

第6章 总结与展望
第6章 总结与展望
6.1 研究内容总结
本研究以类脑算法创新和实际应用价值为两大主要目标，受大脑前额叶皮 层和海马体两个系统的启发，借鉴 HPC 生物连接和功能作用的同时结合机器学 习神经网络，设计了相关的类脑模块用于自主端到端提取识别情境信息，即情 境提取模块，将提取的信息加入基准网络中与感知信息融合之后再送入下游网 络进行训练，达到合理融合情境信息与感知信息以调制神经网络信息处理过程 的目的。本研究提出的网络架构系统是一套完整的体系，首先连续卷积层作为 特征提取器提取特征，送入上层 CPM 和下层感知层分别进行信息处理，将两个 支流的特征融合后输入下游网络得到最后的输出，适用于不同的任务，尤其是 情境复杂的任务。
本文实验主要围绕 CPM 复合模块进行，受 HPC 启发设计了三大子模块： PS 模块、PC 模块和 PI 模块。三个子模块分别对应不同的功能，三者相互配合， 互相补充共同辅助网络执行决策判断。PS 模块通过扩展稀疏选择编码将相似模 式的重叠度降低，这在棋类博弈、Atari 2600 游戏等强化学习任务场景中具有重 要意义，上述任务中往往状态相似度极高，而其中的细微差别又对当前最佳决 策和最终任务的完成有着极大的影响。PC 模块可以弥补 PS 模块过度离散化的 情况，将某些即使模式相差较大但最佳决策或类别相同的模式进行补全，形成 归纳总结后的综合模式。PC 模块设计中加入了时序信息，在连续时间任务中如 游戏、博弈等有着更佳的适应性和鲁棒性。PI 模块则是考虑到前两个子模块功 能化导致的输出模式与当前输入模式相差较大的缺点，参考当前状态原始的输 出模式以将 PC 模块的归纳模式进行一定的专一化，更贴近当前输入模式，使得 CPM 最终给出的信息更符合当前状态。
基于 Pacman 游戏，以 DQN 为基准网络，我们依次测试了简单的多层感知 机，加入 PS 子模块，加入 PS 和 PC 子模块，加入 PS、PC 和 PI 子模块后的 CPM 在游戏性能上的表现，结果显示在数据指标上均有相应的提升，实现了加 速并提升训练效果的目的，证实了各子模块的有效性以及 CPM 的实用性。为 了排除网络容量因素带来的性能提升，我们进行了相关的对比实验，将全连接
63

基于神经网络的自主情境特征提取研究
层取代功能模块，结果显示单纯的线性层相较于加入子模块后的网络性能较差， 说明设计的模块确实起到了重要的作用。然后，我们将感知层输出的感知特征、 CPM 输出的情境特征和两者融合后的旋转特征进行 PCA 降维并取前三大主分 量在三维坐标系中进行展示，以 Pacman 中较为重要的豆子、胶囊和鬼的数量作 为指标，标记点的颜色分别代表着其中一个指标的不同数目，研究其空间分布， 同时也采用类间散度做定量化计算。实验结果表明，CPM 主要针对豆子的数量 进行编码且扩大了不同豆子数目的类间差距，不同豆子数相应代表了游戏的不 同阶段，且同时该探索也证实了 PS 子模块具有分离模式降低重叠的作用、PC 子模块具有归纳融合补全模式的效果，进一步证实了我们提出的类脑模块的功 能性和有效性。
另一核心内容是针对新提出的情境图像分类任务展开的研究。针对 Pacman 游戏情境较为复杂不便分析的难题，本文新设计了包含两种信息特征共同决定 图像最终类别的 Contextual MNIST 和 Contextual CIFAR10 任务，通过在常规数 据集上加灰色区块标记的方式显式化两种信号。实验证实加入 CPM 复合模块的 网络能更好地进行分类，且通过 PCA 降维三维坐标展示发现了网络具有解耦两 种信息的潜质，且网络可以根据子任务的难易程度自动分配上下层网络不同的 编码任务，实现资源自动优化。解耦后的网络降低了任务的复杂度并具有更好 的性能，这给我们今后设计神经网络以及网络的连接架构提供了新思路。另外， 我们在细粒度数据集上进行了实验，CPM 的存在使得网络分类性能有了一定的 提升趋势，其适用范围可能需要进一步的研究和探索。
本研究的主要创新点包括： 1）设计了 CPM 并融入基准网络，自主提取情境信息。受前额叶皮层与海 马体结构、功能以及相互作用机制的启发，设计了新的类脑智能网络—— CPM 模块，能从复杂动态的环境中自主端到端地提取情境信号，对得到的情境信号 做有效处理，实现了根据不同情境灵活决策的目的。通过基于强化学习的实验， 证实该架构能高效控制神经网络的信息处理过程以做出正确响应，帮助人工神 经网络有效识别情境信号，从而增强其在动态复杂的环境中工作能力。 2）研究了 CPM 提取的特征分布，探索了其原理和机制。通过设计新的情 境分类任务，深入研究了 CPM 模块与网络其他部分相互作用，从而提取情境信 息的原理和实现机制，证实了面对复杂环境，这一网络能够自主的学习将情境
64

第6章 总结与展望
信息与其他感觉信息分别处理，从而实现了对于复杂输入信息的高效处理。并 通过分析不同子网络参与情境信息处理的情况，初步揭示了在端到端学习过程 中，网络可以根据不同信息处理的相对难易程度，自动地优化资源配置，实现 情境信息的有效处理。
综上，我们设计了一种新的类脑神经网络模块，进行了基于情境特征提取 的深度学习研究，利用额外的情境信号，实现了神经网络加速训练并提升性能 的目的，使得神经网络能有效识别复杂环境中的情境信号，将自主端到端提取 的重要情境信息与感知信息融合之后再送入下游网络进行训练，更好地适应环 境。人工神经网络由此具备了强大的情境依赖学习能力，灵活性和适应性大大 增加。通过对 Pacman 任务中不同特征表征分布的研究，证实了 CPM 各子模 块对于整体情境化信息处理的作用，并初步验证了其中一些子模块的功能机理， 说明了本文所提出的类脑模块的有效性。通过新设计的情境图像分类任务，进 一步阐明了 CPM 作用机制，发现网络不仅能解耦信息而且能够跟据各种类别信 息的相对复杂程度，自主自动的优化资源配置，实现情境信息的有效处理。该 研究可能改变当前人工智能领域的模型范式、数据形式和利用方式，还可能为 认知科学理解人类如何掌握此类能力提供新的思路。
6.2 展望
情境处理模块实现了无监督端到端提取情境信号的功能，在包含复杂情境 的任务中具有广泛的适用场景，例如游戏、博弈棋局等。而连续学习、多任务 学习中不同任务相关的信息也可视作一种关键的情境信号，如果能实现利用一 个网络模块自动提取任务相关信息达到区分任务的目的，将下层基准网络根据 提取到的任务信息进行调整，对这些任务的学习的性能提升将有极大的帮助。 另外，域自适应学习也是一个极好的应用开发场景。本文提出的复合 CPM 网 络只是较为粗浅的尝试，可以进一步地进行优化，另外也可以在其他常规任务 或者更多的数据集上进行探索，研究其实用性和扩展性，探索是否能在其他领 域也有不错的效果。同时，情境学习的重要性也在研究中得到了进一步的证实， 如何让神经网络判别提取诸多元素中重要的情境信息也是一种新的任务，值得 认真探索与研究。
本研究提出的网络架构给类脑智能的设计提供了新思路，借鉴人脑中的功
65

基于神经网络的自主情境特征提取研究
能连接、生理机制或者功能意义设计相应的人工神经网络，可能会得到意想不 到的效果。这扩宽了我们对类脑算法的设计思路，例如 ANN 的神经元设计、卷 积网络的感受野理论、网络注意机制等均来源于生物特性，我们对此可以展开 丰富的探索。人脑的奥秘无穷无尽，我们能得到的启示也将是不计其数。针对 强化学习训练中的明显弊端，我们也可以从其他领域借鉴尝试，如何小样本高 效地学习是一个值得解决的问题，能够极大地提升当前深度学习耗时耗资源的 弊端，具有巨大的实用意义和价值。另外，本文提出的新型图像分类任务给我 们提供了一个新的实验思路。针对目前的数据集，我们可以开发新的模式任务， 做到一个数据集多种任务，充分利用数据集，不再局限于固定常规的任务，这 样能极大提高数据集的利用率，也能对数据集做相对精准的调整，使之更适合 自己的实验目标。这些思想启发着我们，除了进行常规套路的探索和沿前人设 计的赛道任务前行，我们可以还培养发现创造问题、解决问题的能力，跳出僵 化的思维模式，这对今后的学习和工作发展具有重要的意义。
66

参考文献
参考文献
[1] Mante V, Sussillo D, Shenoy K V, et al. Context-dependent computation by recurrent dynamics in prefrontal cortex [J]. nature, 2013, 503(7474): 78-84.
[2] Eichenbaum H. Prefrontal–hippocampal interactions in episodic memory [J]. Nature Reviews Neuroscience, 2017, 18(9): 547-558.
[3] Kumaran D, Hassabis D, McClelland J L. What learning systems do intelligent agents need? complementary learning systems theory updated [J]. Trends in cognitive sciences, 2016, 20 (7): 512-534.
[4] Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need [J]. Advances in Neural Information Processing Systems, 2017: 5998-6008.
[5] Zeng G, Chen Y, Cui B, et al. Continual learning of context-dependent processing in neural networks [J]. Nature Machine Intelligence, 2019, 1(8): 364-372.
[6] Silver D, Huang A, Maddison C J, et al. Mastering the game of go with deep neural networks and tree search [J]. nature, 2016, 529(7587): 484-489.
[7] Krizhevsky A, Hinton G, et al. Learning multiple layers of features from tiny images [J]. 2009. [8] Wah C, Branson S, Welinder P, et al. The caltech-ucsd birds-200-2011 dataset [J]. 2011. [9] Miller G A, Heise G A, Lichten W. The intelligibility of speech as a function of the context of
the test materials. [J]. Journal of experimental psychology, 1951, 41(5): 329. [10] McClelland J L, Rumelhart D E. An interactive activation model of context eﬀects in letter
perception: I. an account of basic ﬁndings. [J]. Psychological review, 1981, 88(5): 375. [11] Desimone R, Duncan J. Neural mechanisms of selective visual attention [J]. Annual review
of neuroscience, 1995, 18(1): 193-222. [12] Fries P. Neuronal gamma-band synchronization as a fundamental process in cortical compu-
tation [J]. Annual review of neuroscience, 2009, 32: 209-224. [13] Siegel M, Buschman T J, Miller E K. Cortical information ﬂow during ﬂexible sensorimotor
decisions [J]. Science, 2015, 348(6241): 1352-1355. [14] Miller E K, Cohen J D. An integrative theory of prefrontal cortex function [J]. Annual review
of neuroscience, 2001, 24(1): 167-202. [15] Passingham R E, Wise S P. The neurobiology of the prefrontal cortex: anatomy, evolution,
and the origin of insight: number 50 [M]. Oxford University Press, 2012. [16] Fuster J. The prefrontal cortex [M]. Academic Press, 2015. [17] Burwell R D, Saddoris M P, Bucci D J, et al. Corticohippocampal contributions to spatial and
contextual learning [J]. Journal of Neuroscience, 2004, 24(15): 3826-3836.
67

基于神经网络的自主情境特征提取研究
[18] Maren S, Anagnostaras S G, Fanselow M S. The startled seahorse: is the hippocampus necessary for contextual fear conditioning? [J]. Trends in cognitive sciences, 1998, 2(2): 39-42.
[19] Maren S, Aharonov G, Fanselow M S. Neurotoxic lesions of the dorsal hippocampus and pavlovian fear conditioning in rats [J]. Behavioural brain research, 1997, 88(2): 261-274.
[20] Dias R, Robbins T W, Roberts A C. Dissociation in prefrontal cortex of aﬀective and attentional shifts [J]. Nature, 1996, 380(6569): 69-72.
[21] Miller E K. The prefontral cortex and cognitive control [J]. Nature reviews neuroscience, 2000, 1(1): 59-65.
[22] Miller E K. The prefrontal cortex: complex neural properties for complex behavior [J]. Neuron, 1999, 22(1): 15-17.
[23] LeCun Y, Bengio Y, Hinton G. Deep learning [J]. nature, 2015, 521(7553): 436-444. [24] McCloskey M, Cohen N J. Catastrophic interference in connectionist networks: The sequential
learning problem [M]//Psychology of learning and motivation: volume 24. Elsevier, 1989: 109-165. [25] Ratcliﬀ R. Connectionist models of recognition memory: constraints imposed by learning and forgetting functions. [J]. Psychological review, 1990, 97(2): 285. [26] Marr D, Thach W T. A theory of cerebellar cortex [M]//From the Retina to the Neocortex. Springer, 1969: 11-50. [27] Mnih V, Kavukcuoglu K, Silver D, et al. Human-level control through deep reinforcement learning [J]. nature, 2015, 518(7540): 529-533. [28] Jaeger H, Haas H. Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication [J]. science, 2004, 304(5667): 78-80. [29] Young S L, Bohenek D L, Fanselow M S. Nmda processes mediate anterograde amnesia of contextual fear conditioning induced by hippocampal damage: immunization against amnesia by context preexposure. [J]. Behavioral neuroscience, 1994, 108(1): 19. [30] Holland P C, Bouton M E. Hippocampus and context in classical conditioning [J]. Current opinion in neurobiology, 1999, 9(2): 195-202. [31] Casanova M F, Sokhadze E, Opris I, et al. Autism spectrum disorders: linking neuropathological ﬁndings to treatment with transcranial magnetic stimulation [J]. Acta Paediatrica, 2015, 104(4): 346-355. [32] Morris R G, Garrud P, Rawlins J a, et al. Place navigation impaired in rats with hippocampal lesions [J]. Nature, 1982, 297(5868): 681-683. [33] Devan B D, White N M. Parallel information processing in the dorsal striatum: relation to hippocampal function [J]. Journal of neuroscience, 1999, 19(7): 2789-2798.
68

参考文献
[34] Pouzet B, Welzl H, Gubler M, et al. The eﬀects of nmda-induced retrohippocampal lesions on performance of four spatial memory tasks known to be sensitive to hippocampal damage in the rat [J]. European Journal of Neuroscience, 1999, 11(1): 123-140.
[35] Preston A R, Eichenbaum H. Interplay of hippocampus and prefrontal cortex in memory [J]. Current Biology, 2013, 23(17): R764-R773.
[36] Sigurdsson T, Duvarci S. Hippocampal-prefrontal interactions in cognition, behavior and psychiatric disease [J]. Frontiers in systems neuroscience, 2016, 9: 190.
[37] Kumaran D, Maguire E A. The human hippocampus: cognitive maps or relational memory? [J]. Journal of Neuroscience, 2005, 25(31): 7254-7259.
[38] McNaughton B L, Morris R G. Hippocampal synaptic enhancement and information storage within a distributed memory system [J]. Trends in neurosciences, 1987, 10(10): 408-415.
[39] O’reilly R C, McClelland J L. Hippocampal conjunctive encoding, storage, and recall: avoiding a trade-oﬀ [J]. Hippocampus, 1994, 4(6): 661-682.
[40] Treves A, Rolls E T. Computational constraints suggest the need for two distinct input systems to the hippocampal ca3 network [J]. Hippocampus, 1992, 2(2): 189-199.
[41] Johnston S T, Shtrahman M, Parylak S, et al. Paradox of pattern separation and adult neurogenesis: A dual role for new neurons balancing memory resolution and robustness [J]. Neurobiology of learning and memory, 2016, 129: 60-68.
[42] Knierim J J, Neunuebel J P. Tracking the ﬂow of hippocampal computation: Pattern separation, pattern completion, and attractor dynamics [J]. Neurobiology of learning and memory, 2016, 129: 38-49.
[43] Knierim J J, Lee I, Hargreaves E L. Hippocampal place cells: parallel input streams, subregional processing, and implications for episodic memory [J]. Hippocampus, 2006, 16(9): 755-764.
[44] Van Strien N, Cappaert N, Witter M. The anatomy of memory: an interactive overview of the parahippocampal–hippocampal network [J]. Nature reviews neuroscience, 2009, 10(4): 272-282.
[45] Ketz N, Morkonda S G, O’Reilly R C. Theta coordinated error-driven learning in the hippocampus [J]. PLoS Computational Biology, 2013, 9(6): e1003067.
[46] 刘全, 翟建伟, 章宗长, 等. 深度强化学习综述 [J]. 计算机学报, 2018, 41(1): 1-27. [47] Mnih V, Kavukcuoglu K, Silver D, et al. Playing atari with deep reinforcement learning [J].
CoRR, 2013, abs/1312.5602. [48] Wang Z, Schaul T, Hessel M, et al. Dueling network architectures for deep reinforcement
learning [C]//International conference on machine learning. JMLR.org, 2016: 1995-2003.
69

基于神经网络的自主情境特征提取研究
[49] Hausknecht M J, Stone P. Deep recurrent q-learning for partially observable mdps [C]// Proceedings of the AAAI Conference on Artiﬁcial Intelligence. AAAI Press, 2015: 29-37.
[50] Van Hasselt H, Guez A, Silver D. Deep reinforcement learning with double q-learning [C]// Proceedings of the AAAI Conference on Artiﬁcial Intelligence: volume 30. AAAI Press, 2016.
[51] Amari S I. Natural gradient works eﬃciently in learning [J]. Neural computation, 1998, 10 (2): 251-276.
[52] Bhatnagar S, Sutton R S, Ghavamzadeh M, et al. Natural actor–critic algorithms [J]. Automatica, 2009, 45(11): 2471-2482.
[53] Grondman I, Busoniu L, Lopes G A, et al. A survey of actor-critic reinforcement learning: Standard and natural policy gradients [J]. IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), 2012, 42(6): 1291-1307.
[54] Kakade S M. A natural policy gradient [J]. Advances in neural information processing systems, 2001, 14: 1531-1538.
[55] Park J, Kim J, Kang D. An rls-based natural actor-critic algorithm for locomotion of a twolinked robot arm [C]//International Conference on Computational and Information Science. Springer, 2005: 65-72.
[56] Peters J, Schaal S. Natural actor-critic [J]. Neurocomputing, 2008, 71(7-9): 1180-1190. [57] Peters J, Vijayakumar S, Schaal S. Natural actor-critic [C]//European Conference on Machine
Learning. Springer, 2005: 280-291. [58] Silver D, Lever G, Heess N, et al. Deterministic policy gradient algorithms [C]//International
conference on machine learning. PMLR, 2014: 387-395. [59] Williams R J. Simple statistical gradient-following algorithms for connectionist reinforcement
learning [J]. Machine learning, 1992, 8(3-4): 229-256. [60] Mnih V, Badia A P, Mirza M, et al. Asynchronous methods for deep reinforcement learning
[C]//International conference on machine learning. PMLR, 2016: 1928-1937. [61] Sutton R S, McAllester D A, Singh S P, et al. Policy gradient methods for reinforcement learn-
ing with function approximation. [C]//Advances in Neural Information Processing Systems: volume 99. Citeseer, 1999: 1057-1063. [62] Silver D, Schrittwieser J, Simonyan K, et al. Mastering the game of go without human knowledge [J]. nature, 2017, 550(7676): 354-359. [63] Gilbert P E, Kesner R P, Lee I. Dissociating hippocampal subregions: A double dissociation between dentate gyrus and ca1 [J]. Hippocampus, 2001, 11(6): 626-636. [64] Goodrich-Hunsaker N J, Hunsaker M R, Kesner R P. The interactions and dissociations of
70

参考文献
the dorsal hippocampus subregions: how the dentate gyrus, ca3, and ca1 process spatial information. [J]. Behavioral neuroscience, 2008, 122(1): 16. [65] McHugh T J, Jones M W, Quinn J J, et al. Dentate gyrus nmda receptors mediate rapid pattern separation in the hippocampal network [J]. Science, 2007, 317(5834): 94-99. [66] Kumaran D, McClelland J L. Generalization through the recurrent interaction of episodic memories: a model of the hippocampal system. [J]. Psychological review, 2012, 119(3): 573. [67] Hintzman D L. " schema abstraction" in a multiple-trace memory model. [J]. Psychological review, 1986, 93(4): 411. [68] Medin D L, Schaﬀer M M. Context theory of classiﬁcation learning. [J]. Psychological review, 1978, 85(3): 207. [69] Nosofsky R M. Choice, similarity, and the context theory of classiﬁcation. [J]. Journal of Experimental Psychology: Learning, memory, and cognition, 1984, 10(1): 104. [70] Albus J S. A theory of cerebellar function [J]. Mathematical biosciences, 1971, 10(1-2): 25-61. [71] Leutgeb J K, Leutgeb S, Moser M B, et al. Pattern separation in the dentate gyrus and ca3 of the hippocampus [J]. science, 2007, 315(5814): 961-966. [72] Moser E I, Moser M B. One-shot memory in hippocampal ca3 networks [J]. Neuron, 2003, 38(2): 147-148. [73] Chaudhuri R, Fiete I. Computational principles of memory [J]. Nature neuroscience, 2016, 19 (3): 394. [74] Wills T J, Lever C, Cacucci F, et al. Attractor dynamics in the hippocampal representation of the local environment [J]. Science, 2005, 308(5723): 873-876. [75] LeCun Y, Bottou L, Bengio Y, et al. Gradient-based learning applied to document recognition [J]. Proceedings of the IEEE, 1998, 86(11): 2278-2324.
71

基于神经网络的自主情境特征提取研究 72

作者简历及攻读学位期间发表的学术论文与研究成果
作者简历及攻读学位期间发表的学术论文与研究成果
作者简历 1995 年 10 月 29 日出生于江苏省南通市。 2014 年 9 月—— 2018 年 7 月，在吉林大学计算机科学与技术学院获得工学
学士学位。 2018 年 9 月—— 2021 年 7 月，在中国科学院自动化研究所攻读计算机技术
硕士学位。 参加的研究项目及获奖情况:
[1] 2020 年 1 月获得 2019 年度泰雷兹集团全球科技挑战赛北京赛区一等奖 [2] 面向复杂情境学习的新型神经网络设计（MENG PO），中法联合项目
73

基于神经网络的自主情境特征提取研究 74

致谢
时光如箭，岁月如梭，毕业论文的结束意味着我的研究生涯即将画上一个 句点。回首硕士三年以来的点点滴滴，心潮难平，感慨良多，但无论如何，或 喜或悲，这份经历毫无疑问将是我人生中绚丽的一笔。在短短三年里我成长了 很多，也收获了很多，在此对求学过程中给予我支持和帮助的各位老师和同学 表示真挚的感谢，当然最要感谢的是我的父母，是他们的支持和关爱才让我坚 持努力走到了今天，他们是我人生最好的导师！
这次的毕业设计从开始到结束，我真的学到了很多新知识。我在此要特别 感谢中国科学院自动化研究所的余山研究员，感谢老师在课题和生活上的帮助 和关心，一步一步见证了我的成长。余山导师的诸多先进思想和理论使我受益 匪浅，其对科研的严谨态度对我影响深远，对人生的感悟理解也让我的思想不 再局限，开拓了视界。在这里，我要特别感谢胡古月师兄这段时间的帮助和照 顾，答疑和指导细致耐心，不厌其烦地教导我，并介绍了很多实用学习资源。 我也要感谢崔波师兄、张金鹏师兄、牛威昆师兄、华娇娇师姐、何媛师姐、姜 玉莹师姐和韩新勇师兄的真诚帮助和指导，感谢祝贺、曹盛浩、江洁和刘民颂 在日常生活中的陪伴和帮助，是你们让我的科研生活充满了温暖和乐趣。当然， 我要感谢脑网络组的所有师兄师姐们这段时间对我的照顾，如同一个大家庭一 般的温暖。
所有帮助和关心过我的人们，尽管与你们为我付出的一切相比，所有的言 语都显得苍白无力，我仍要真诚地说声：谢谢你们！
75

基于神经网络的自主情境特征提取研究 76

