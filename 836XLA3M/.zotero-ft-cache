implies that there are variations of some in- the pen in my hand and the marks on the Mastering the Laws

ternal states. One could object to the claim sheet confirm my action. It is in a phenom- of Feedback Contingencies

that the propagation of the gradient during enal domain that has no relation to the sense

the stabilization of the network could be of the sentence that I write.

Is Essential to Constructivist

seen as a variation of some internal states.

« 14 »  In the same way, my feeling of Artificial Agents

To this I would reply that gradient propa- the pen in my hand is not in the same do-

Artificial Intelligence Synthesis in Second-Order Cybernetics

gation aims at stabilizing the system in a non-autonomous dynamic state, because after the convergence of the propagation algorithm, if the inputs do not change, the

main as the neural activities of my brain that generate this feeling. The first domain (my hand feeling my pen) needs the second (my nervous system with neurons and elec-

Olivier L. Georgeon & Mathieu Guillermin
Université de Lyon, France ogeorgeon/at/univ-catholyon.fr

system will not vary or evolve. Yet, an au- trochemical reactions), as is the case for the
tonomous system is changing in time be- relations between different abstract levels, Mathieu Guillermin

cause these changes allow for an evaluation previously addressed. The point is that if we LBG UMRS 449, Université

of its internal states and particularly its level try to simulate what happens in a phenom- Catholique de Lyon, France

of degradation. The dynamic of the system is always changing: it is an organization that

enal domain, we certainly have to address how to simulate the interfaces that exist be-

meguillermin/at/univ-catholyon.fr

can disappear because it evolves. This is why tween two different phenomenal domains in
some researchers interested in the simula- order to make their causal links possible. I > Upshot • We support Füllsack’s claim

tion of autonomous systems are using mod- wonder whether the use of neural networks that contingency is essential in the con-

els such as recurrent and temporal neural can cover this point? (Q3)

ception of artificial constructivist agents.

networks, which have their own internal dy-

« 15 »  As my final point, let me em- Linking this claim to O’Regan and Noë’s

namic (Manetti & Caiani 2011) and which phasize that I consider a more challenging theory of sensorimotor contingencies,

can adopt different operating regimes, i.e., program that of reflexivity. The capacity of we argue that artificial constructivist

different sensorimotor behavioral regulari- an agent to observe itself internally, i.e., in a agents should master the laws of feed-

ties. Inputs become perturbations of these phenomenal domain, to move not only from back contingencies. In particular, artificial

regularities, as do other agents and the en- a low abstract level to a high abstract one but constructivist agents should process in-

tire environment of the system.

also vice versa, from a high abstract level to put data as feedback from their actions

« 12 »  My arguments seem to be in line a low abstract one. In my opinion, it is the rather than as percepts representing the

with Füllsack, who prefers talking about “ir- more challenging issue in the process of ob- environment.

ritation” (§§9f) rather than “external inputs.” taining a genuine constructivist agent, i.e., a

However, for the reasons mentioned above, I genuinely autonomous system that governs

« 1 »  Manfred Füllsack argues that mul-

think that the proposition of minimal artifi- itself without the need to predefine its goals tiple contingency counts among the essen-

cial constructivist agents as systems based on by external causes. It is able to determine its tials for conceiving artificial constructivist

feed-forward neural networks, even if they behavior not only based on the behaviors agents. Yet, is it not the purpose of all ar-

are linked together, does not implement the in lower phenomenal domains that help to tificially intelligent (AI) agents to adapt to

autonomous dynamic as presented by Varela maintain its existence but also based on the contingencies during their interaction with

300 with the notion of organization as agency. behaviors in the phenomenal domain that their environment? Indeed, all AI agents

In an enactive perspective, how to deal with phenomenal domain separation and reflexivity?

reflect on its existence as a system. For that, it needs to know that it exists.
Pierre De Loor is Professor in Computer Sciences at

should be able to cope with some uncertainty, that is, to handle the contingent nature of the data that they receive from their environment. Many AI agents may also develop

« 13 »  The most difficult question is cer- Brest National Engineering School (ENIB). He develops contingent behaviors depending on their

tainly that of phenomenal domains. While

his research at the Lab-STICC (French CNRS Lab) contingent experience interacting with mul-

this notion could be seen in various ways I

and is the Co-Head of the team “Human System tiple other agents. Yet, we would not argue

prefer referring to a kind of “universe of con- Interaction” (IHSEV). His research focuses on the links that all AI agents are constructivist. So, what

tents” that has a meaning for a certain point

between artificial intelligence, interactive systems kind of contingency exactly makes an artifi-

of view. In the same way that an agent is seen

and cognitive sciences. More precisely, he works on cial agent constructivist, and why?

as an agent by an external observer (§20),

the self-adaptation of virtual environments to users,

« 2 »  We argue that there is something

there are different levels of phenomenal do-

non-verbal interactions between humans and virtual special in how Füllsack’s agents handle con-

mains in the agent, each with a specific na-

agents, modeling and simulation of autonomy, as tingencies that makes them constructivist,

ture and without shared sense. For instance,

well as all the properties linked with the enactive namely their ability to handle a particular

if I write on a sheet with a pen, I not only use

field. Web page: http://www.enib.fr/~deloor. kind of contingency we call feedback con-

my hand and my fingers for writing but also

tingency. Indeed, as implemented by Füll-

my gaze for checking whether the shape of

Received: 7 February 2018 sack, the agent’s input data (the payoffs, §27)

my writing respects handwriting rules. I feel

Accepted: 25 February 2018 come as feedback resulting from the agent’s

Constructivist Foundations vol. 13, N°2

Second-Order Cybernetics
Laws of Feedback Contingencies Olivier L. Georgeon & Mathieu Guillermin

actions (cooperate or defect, §28). The agent

« 6 »  In short, Füllsack seems to com-

develops contingent behaviors (i.e., behav- mit to an ‹effector → sensor› paradigm iors that could have developed differently) whereas most AI scientists commit to the

Feedback take-off

depending on contingent feedback received ‹sensor → effector› paradigm. While effector

at an early stage. « 3 »  Feedback contingencies contrast
with the kind of contingency that most AI

data and sensor data are sent and received alternately in an infinite loop, these paradigms differ in the way sensor data is gener-

Compensator Subtractor

Effector

Output

agents deal with. For example, Peter Russell ated by the experimental settings and pro-

and Stuart Norvig consider the agent’s input cessed by the agent’s algorithm. Figure 4 of Figure 1 • Feedback system of control

data as percepts rather than feedback: “the Füllsack’s article, as often in the AI literature, (adapted from Wiener 1948: 112).

problem of AI is to build agents that receive does not highlight which paradigm is imple-

percepts from the environment and perform actions” (Russell & Norvig 2003: iv). By considering input data as percepts, Russell and

mented. Our Figure 2 suggests a manner of highlighting it.
« 7 »  Füllsack’s claim that contingency is

0 1 0 Sensors

Norvig designed algorithms that rest upon essential to artificial constructivist agents is the assumption that the agent’s input data in line with Kevin O’Regan and Alva Noë’s are a direct function of the state of the en- (2001) idea that mastering sensorimotor

0 0 Agent 1

vironment. This assumption, however, is contingencies is important to cognition. not satisfied when the agent’s input data are O’Regan and Noë, however, did not specify

0 1 1 Effectors

feedback from actions. For example, in Füll- in what sense they used the term “sensorim-

sack’s model, the payoff not only depends on otor.” Their statement “[…] the structures Figure 2 • Modification of target article’s

the state of the environment (here, the other of the rules governing the sensory changes Figure 4. The bullet represents the premise of

agents) but also on the agent’s own previous produced by various motor actions, that is, the interaction, i.e., the investment; the arrow

actions. Russell and Norvig did not demon- what we call the sensorimotor contingencies represents the outcome, i.e,: the payoff..

strate that their agents could handle feed- […]” (O’Regan & Noë 2001: 941) evokes

back data appropriately. We expect that such the ‹effector → sensor› paradigm. On page

demonstration would require a significant 1013, however, the sentence “We agree with laws of feedback contingencies. On the ba-

modification of their agents and a redesign the functionalists, though, that it is the in- sis of the arguments developed above, along

of their experiments.

put/output relations that matter” evokes the with O’Regan and Noë’s, we believe that de-

« 4 »  In computer science, the paternity ‹sensor → effector› paradigm. As an experi- signing artificial agents capable of learning

of the term feedback is usually attributed to mental psychologist and a philosopher of to master complex laws of feedback contin-

Norbert Wiener’s cybernetics (1948). Fig- perception (as they present themselves on gencies constitutes an interesting challenge.

ure 1 illustrates Wiener’s conceptualization page 939), they may have conceived “senso-

of a control system using a perturbation sig- rimotor” in its Piagetian sense that merges

Olivier L. Georgeon is an associate professor at

nal provided as feedback from the system’s sensation and motion in an indivisible

the Catholic University of Lyon and a researcher in

output.

chunk of phenomenological experience. Yet,

computer science at the LIRIS Laboratory (CNRS -

« 5 »  In his paper “Why I Consider My- for a computer scientist, the distinction is

UMR 5205). He has an interdisciplinary background 301

self a Cybernetician,” Ernst von Glasersfeld important since we do not see how we could

with a master of engineering in computer science

(1992) explained the link between con- merge artificial agents’ sensors and effectors.

from the Ecole Centrale de Marseille (1988) and

structivism and cybernetics by comparing Some of O’Regan and Noë’s commentators

a PhD in cognitive psychology from the Université

Wiener’s feedback systems of control with an pointed out the need for clarification. In his

Lumière Lyon 2 (2008). His research focuses on the

organism that manages to “get by the con- commentary entitled “On the Distinction implementation of developmental learning mechanisms

straints set by its environment” (Glasersfeld between ‘Sensorimotor’ and ‘Motorsensory’

and intrinsic motivation in artificial agents.

1992: 22), thereby demonstrating “adapted- Contingencies,” Donald Laming noted that

ness” and “equilibration.” Von Glasersfeld’s “the distinction is essential” because “these

Mathieu Guillermin is an associate professor at

arguments also apply when considering Fül- two sets of contingencies are entirely dis-

the Catholic University of Lyon. He holds a PhD in

lsack’s agents to be constructivist: the agent’s joint” (Laming 2001: 992).

Physics (laser-matter interaction) and a PhD in

input data (the feedback) “has an adaptive

« 8 »  When it comes to designing con-

Philosophy of Science (pragmatist epistemology

function, not a representational one” (ibid: structivist artificial argents, we suggest

for combining incommensurability and context-

23). This differentiates Füllsack’s agents interpreting O’Regan and Noë’s theory ac-

sensitivity with scientific realism). His research

from Russell and Norvig’s whose input data cording to the ‹effector → sensor› paradigm.

focuses upon philosophy and ethics of science and

(percepts considered as a function of the To avoid ambiguity, we propose the expres- technology, especially regarding digital technologies.

state of the environment), although partial sion feedback contingencies. Füllsack’s model

and noisy, do have a representational func- appears to us to be a valuable example of

Received: 26 February 2018

tion.

artificial agents that learn to master simple

Accepted: 28 February 2018

http://constructivist.info/13/2/282.fuellsack

